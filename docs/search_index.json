[["index.html", "АнДан 2021: стартовая программа 1 О курсе", " АнДан 2021: стартовая программа А. Ангельгардт, М. Серветник, Ю. Мартысенко, А. Котликова 1 О курсе Материалы для курса школы Анализа данных: стартовая. Пакеты: install.packages(c(&quot;data.table&quot;, &quot;ggplot2&quot;, &quot;reshape2&quot;, &quot;corrplot&quot;)) "],["знакомство-с-rstudio.html", "2 Знакомство с RStudio 2.1 Знакомство с RStudio 2.2 Горячие клавиши 2.3 Гайды по стилю R 2.4 Рабочая папка 2.5 Открываем файл", " 2 Знакомство с RStudio 2.1 Знакомство с RStudio Запустите RStudio на своих ноутбуках и старайтесь находить и повторять то, что я показываю, у себя =) R Studio выглядит у вас как-то так: Вверху слева у вас находится поле ввода вашего скрипта, который будет сохраняться. Под ним - консоль. Туда можно писать команды. Здесь показывается исполняемый код, который не сохраняется. Терминал - доступ к терминалу (командной строке) из R Studio (нам сейчас это точно не понадобится=)) Ну что, давайте пробовать? a &lt;- &quot;это код, он исполняется&quot; a ## [1] &quot;это код, он исполняется&quot; Введите этот скрипт и нажмите Ctrl+Enter или кнопку Run. Как видите, он появился в консоли. Теперь спуститесь в консоль и в строке ввода нажмите стрелку вверх. Как видите, этот код снова появился. Стрелками вверх-вниз можно вызывать недавние команды. #это комментарий, он не исполняется А теперь введите этот скрипт и снова нажмите Ctrl+Enter. В консоли он появился, но строки вывода нет.Это значит, что он не был исполнен. Для оставления комментариев (неисполняемой части кода) ставьте в начале строки знак хэштэга #. Также можно закомментировать/раскомментировать часть кода, выделив её и нажав Ctrl+Shift+C для Win или Command+Shift+C для macOS. 2.2 Горячие клавиши Ctrl+Enter, что мы нажимали, является одной из горячих клавиш. Она позволяет запустить не весь код (как, например, делает кнопка Run), а только часть его: ту, что выделена или ту строку, на которой стоит курсор. Потренируемся. У вас в файле пока есть три строки: a &lt;- &quot;это код, он исполняется&quot; a ## [1] &quot;это код, он исполняется&quot; #это комментарий, он не исполняется Выделите последние две строки и нажмите Ctrl+Enter. У вас в выводе должна появиться фраза: это код, он исполняется, а в консоли - последние две строки. А теперь поставьте курсор на последнюю строку. Вывода у вас не должно появиться, а в консоли появится последняя строка. Вывод в консоли пишется черным цветом, исполняемые команды - синим. Остальные горячие клавиши можно посмотреть во вкладке Help &gt; Keyboard Shortcuts Help. a&lt;-&quot;это код, он исполняется&quot; a ## [1] &quot;это код, он исполняется&quot; В этом коде мы присвоили переменной a значение и вывели результат на экран. Оператор присваивания в R это &lt;- (допускается использование знака равно =). В R можно использовать и обратный оператор присваивания -&gt;, но это считается плохим тоном, так как плохо считывается визуально. С обратным оператором этот же код выглядел бы так: &quot;это код, он исполняется&quot;-&gt;a a ## [1] &quot;это код, он исполняется&quot; 2.3 Гайды по стилю R Переменные должны обязательно начинаться с буквы (чтобы не было проблем, используйте латинские буквы) и не содержать в себе специальных символов. Есть различные гайды по неймингу переменных, функций и объектов в R. Можете на досуге ознакомиться. 2.4 Рабочая папка Мы работаем с файлами в определенной рабочей папке (директории). R видит то, что в этой папке, и к файлам в ней можно обращаться по имени без указания адреса. Понять, в какой папке мы находимся (и, соотсветственно, путь до данного файла, в котором мы пишем), можно с помощью команды: getwd() ## [1] &quot;C:/Users/serve/Desktop/&quot; Если мы хотим перейти в другую папку, мы можем сделать это во вкладке Sessions &gt; Set working directory. Ну или с помощью кода =) Здесь вы можете прописать адрес, который вам нужен: setwd(&quot;C:/Users/serve/Desktop/andan2021/&quot;) 2.5 Открываем файл Итак! Подготовка закончена. Давайте откроем наш первый документ. Лучше всего вначале открыть файл в текстовом редакторе и понять, какие там разделители. Рекомендуем Notepad++ Пишем команду. Если выделить мышкой слова read.table и нажать F1, то справа внизу во вкладке Help появится окно помощи со справкой по этой команде. Также справку можно вызвать с помощью команд: ?read.table или help(read.table). В некоторых случаях нужно заключать искомое слово в кавычки. Экспериментируйте =) data&lt;-read.table(file = &quot;about_us_eng.csv&quot;) ## Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec, : line 1 did not have 20 elements Опа, ошибка. Ошибку всегда можно погуглить или поискать решение на stackoverflow, но в данном случае расширение файла дает нам подсказку: проблема в разделителях. TSV - tab separated values, CSV - comma separated values. У нас CSV-файл. Нам надо правильно выставить сепаратор: ,. В tsv формате разделителем будет табуляция \\t. \\ - это знак экранирования. О нем я расскажу попозже. data&lt;-read.table(file = &quot;about_us_eng.csv&quot;, sep=&quot;,&quot;) Посмотрите в окошко справа вверху: видите, появилось: data 36 obs. of 15 variables? Кликнем туда и посмотрим, что у нас загрузилось. Это табличка с нашими данными, но вроде всё ещё не совсем то, что надо. Давайте укажем, что первая строка является именами переменных. data &lt;- read.table(&quot;about_us_eng.csv&quot;, sep=&quot;,&quot;, header=TRUE) Тут можно окинуть широким взглядом всю таблицу. Очень удобно. Посмотрите, кстати, что появилось в консоли: View(data). Этой командой можно пользоваться для визуального просмотра данных. Удобно, когда у вас много табличек. В команде выше вы видите основы синтаксиса R. — data —- объект, в который запишется то, что после — read.table() —- функция с набором параметров — file, sep, header —- параметры, перечисляемые через запятую — header=TRUE —- присвоение параметру header значения TRUE — TRUE без кавычек означает TRUE —- значение типа logic, булева переменная (Boolean) — TRUE в кавычках (\"TRUE\") было бы просто словом TRUE, значением типа character Давайте обратим наш взор на окошко вверху справа. Это окно глобального окружения. Все таблицы, переменные, функции и пр. RStudio запоминает и перечисляет там. В глобальном окружении также присутствуют некоторые уже заданные и написанные данные, переменные и функции. Например, число пи: pi ## [1] 3.141593 Или вектор алфавита letters ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; &quot;k&quot; &quot;l&quot; &quot;m&quot; &quot;n&quot; &quot;o&quot; &quot;p&quot; &quot;q&quot; &quot;r&quot; &quot;s&quot; ## [20] &quot;t&quot; &quot;u&quot; &quot;v&quot; &quot;w&quot; &quot;x&quot; &quot;y&quot; &quot;z&quot; Перейдем к знакомству непосредственно с R. "],["введение-в-r.html", "3 Введение в R 3.1 Общее 3.2 Типы данных 3.3 Структуры данных 3.4 Функции и простые действия с данными 3.5 Задания для тренировки", " 3 Введение в R 3.1 Общее R — скриптовый язык. Важно помнить, что код в нем выполняется построчно. Многие функции в нем векторизованы, то есть выполняются ко всему списку объектов, что даются ему на вход. Это вы потом увидите на примерах. В R есть множество пакетов (помните, мы вводили install.packages() при подготовке к школе?), в которых реализованы наиболее эффективные алгоритмы работы с данными, именно поэтому он так удобен для анализа. 3.2 Типы данных С некоторыми типами данных мы уже познакомились выше. Все они, кроме фактора, более-менее стандартны для всех языков программирования. 3.2.1 Целое число — integer Например, в R можно что-нибудь посчитать как на калькуляторе. 6/3 ## [1] 2 Чтобы определить тип данных есть команда typeof(): b &lt;- 6 ** 2 typeof(b) ## [1] &quot;double&quot; Ой, у нас вышло, что эта переменная не целочисленная, а double — число с плавающей точкой. Хранение в памяти такого числа требует больше ресурсов. Можно перевести переменную в integer: b &lt;- 6 ** 2 b &lt;- as.integer(b) typeof(b) ## [1] &quot;integer&quot; 3.2.2 Число с плавающей точкой — double Этот формат — для всех целочисленных и дробных значений. 2.5 + 3.3 ## [1] 5.8 Результат деления всегда будет числом с плавающей точкой, даже если результат целочисленный: c &lt;- b / 2 paste(c) ## [1] &quot;18&quot; typeof(c) ## [1] &quot;double&quot; Основные операторы для арифметических действий: + — сложить - — вычесть * — умножить ** или ^ — возвести в степень %% — получить остаток от деления %/% — получить целочисленную часть от деления sqrt() — извлечь квадратный корень round() — округлить 3.2.3 Комплексные числа — complex Кто знает, тот поймет. 3.2.4 Символьный тип данных (строки) — character s1 &lt;- &quot;Я строка&quot; s2 &lt;- &#39;И я строка&#39; s1 ## [1] &quot;Я строка&quot; s2 ## [1] &quot;И я строка&quot; В кавычках '' или \"\" заключены символьные данные. Следите за тем, чтобы не пропустить открывающие/закрывающие кавычки. s3 &lt;- &quot;Экранирование \\&quot;лишних\\&quot; кавычек&quot; s3 ## [1] &quot;Экранирование \\&quot;лишних\\&quot; кавычек&quot; R (как и другие языки) может читать текст вместе со специальными управляющими символами (такими, например, являются кавычки ' и \" или бэкслэш \\), а может читать просто как текст. Специальные символы можно экранировать, добавив перед ними бэкслэш. Выполнять мат. операции с символьными значениями нельзя. &#39;a&#39; * 3 ## Error in &quot;a&quot; * 3: non-numeric argument to binary operator Для соединения символьных и числовых данных часто необходимо превратить числовое значение в символьное. Соединить две строки помогает функция paste(). Ей через запятую можно передать строки, которые она соединит в одну строку. Стандартный разделитель - пробел \" \". paste(&#39;я&#39;, &#39;люблю&#39;, &#39;людей&#39;) ## [1] &quot;я люблю людей&quot; Сепаратор можно задать и самим: paste(&#39;я&#39;, &#39;люблю&#39;, &#39;людей&#39;, sep=&#39;;&#39;) ## [1] &quot;я;люблю;людей&quot; Если хочешь, чтобы сепаратором стала пустая строка \"\", используй функцию paste0() paste0(&#39;я&#39;, &#39;люблю&#39;, &#39;людей&#39;) ## [1] &quot;ялюблюлюдей&quot; У тебя есть переменная: age - с твоим возрастом. Попробуй вывести на экран с помощью функции paste() фразу “Мой возраст:” и свой возраст. Не забудь превратить число возраста в строку с помощью функции as.character(). 3.2.5 Фактор — factor Ну а что же такое факторы # ://////////++++++++++++++++++++++++++++++++++//////:::::::::::::/::::: # //////////+++++++++++++++++++++++++++++++ossoo++/////++syyo+//:////::: # ///////////++++++++++++++++++++++++++++//:/+shhhhhhddddddddhyo//////:: # ////////////++++/++++++++////+++ooo+++syyyysssyyyhdmmmdddddhhy+//////: # ////////////////+osyhddho:::osshddddhhysyhhyyyyyhysosydmmmmddhy//////: # //////////////+syhdmmmdh+/oyyhdddhhhhhdddhso+++syhhyo+/+shdmdddo/////: # ///////+oyhhhhdmmmmmmhs//shhdhssssysooooo++/+ss//+oooso/::/+yddh/////: # ///osyhmmmmmmmmmmmmho::/osyhyyssoossyyssssyhhy/:/shhhyysso+/:/shs///:: # /+hmddmmmmmmmmmmmds:-::++oys+//sys+//oyooshyyho+oydmdddddddyo+:+hho/:: # +smdmmmmmmmmmmmmh+---::++//+oydmmddsoohsoyhyyhyyyhdmdhhydddddyo/sso/:: # +ohmmmmmmmmmmmds:---::///shdmmdmmmddhhhssyyhhhhyyyyhdy+hdhddddy+/:::-- # ++odmmmmmmmmmd+------::ohddddddhhdmddhhhdddddddddhsssssydhddddh+/:---- # +++odmmmmmmmd+------:/ohhddddddhyyddhhdmdhdhhhdhdddhyssyhdddddho+:---. # ++++ymmmmmmmh:-.--::+shhddmydhddhhysyhmdhhdmhhhddddddhhyyyddddyoo:.... # ++++odmmmmmdy-----:/shhhhddddddhhssshdmddhhdhdyhhhdddddddhhddhs++/.... # ++++++ydddddy----::+yddhhhhhhyyhsoshmddddhhhdhhhddddddddddddhhyo+/:... # /++++++oshhhs-----:/shhyyhdddddyosdmddddhhhhhddhyyhhhddddddddhyys/:-.. # ++++++++++/o+--.-----/+sssyyyhyoydmmddddhhhhhhdmdddddddddddddddhyo::-. # +++++++++/--:-..-+/..-:+osssyyssdmmdddddhhyhdddhyyhdddddddddddddhs//-- # /++++++++/---...-/:.-:+o++/+ssshmdddddddhhhddhhdddddddmdddddddddho//:- # +++++++++/:::-..-:---/ooo+/+ysydmddddddddddmddddddddddmmmddddddds+/::: # ++++++++:-...-....--:+yysoshhhdmmmmmddddddmdddddddddddmmmmmmmdddoo/::: # +++++++/-..`..-...-:/+syyhdddmmddddddddddmmdddmmmmmdddmmmmmmmmdyo/:::: # ++++++/:-.....--.---:/oyhddddddhhdddddmmmmmddmmmmmmdddmmmmmdddyo//:::/ # /+++++/--.--...------:/ohddmmmdddddmmmmmmdmmmmmmmmmmddmmmmmddys+///:/: # //////:....--...-:::::/+shhdddmmmmmmmmdmmmmmmmmmmmdmmmmmmmdhyo//:/::/: # /////:.......--..-:::::/+shddmddmmmmdmmmmmmmmmmmmmmmmmmddhhso////:///: # :///:.``.....---..-::::/+osyhdmmmmmmmmmmmmmmmmddmmmmmdyyyyo+////::/::: # ::::-.```...--::-.------::/+syhdddddddmdddhyyyyhddmmhso+++/:://::::::: # ::::.``````..-:::--..----::/+oossssyhddyo+:://oyhhys+:::/::::/::::::-- # :::-.```````....-:--...------:::::/oso/-----::/++//:--::::://::::---.. # :::-`````````....----....--....-------......--::::::/::::://::::--.... # -::-.````.......--:---......-......------:::/+++++//////:::::---...... Фактор был придуман для облегчения работы с качественными переменными, он может быть представлен как строка, и как число. Например, возьмем последовательность букв алфавита f &lt;- factor(LETTERS) На них можно посмотреть как на строковые данные: as.character(f) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot; &quot;I&quot; &quot;J&quot; &quot;K&quot; &quot;L&quot; &quot;M&quot; &quot;N&quot; &quot;O&quot; &quot;P&quot; &quot;Q&quot; &quot;R&quot; &quot;S&quot; ## [20] &quot;T&quot; &quot;U&quot; &quot;V&quot; &quot;W&quot; &quot;X&quot; &quot;Y&quot; &quot;Z&quot; И как на числовые: as.numeric(f) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## [26] 26 Если нам нужно каждому варианту ответа присвоить код (номер), то это удобно сделать с помощью фактора: dogs &lt;- c(&quot;мопс&quot;, &quot;пудель&quot;, &quot;овчарка&quot;, &quot;йорк&quot;, &quot;мопс&quot;, &quot;мопс&quot;) f_dogs &lt;- factor(dogs) f_dogs ## [1] мопс пудель овчарка йорк мопс мопс ## Levels: йорк мопс овчарка пудель as.numeric(f_dogs) ## [1] 2 4 3 1 2 2 У факторов есть уровни и они сортируются по алфавиту levels(f_dogs) ## [1] &quot;йорк&quot; &quot;мопс&quot; &quot;овчарка&quot; &quot;пудель&quot; str(f_dogs) ## Factor w/ 4 levels &quot;йорк&quot;,&quot;мопс&quot;,..: 2 4 3 1 2 2 Допустим, мы хотим отсортировать уровни по-своему f_dogs2 &lt;- factor(dogs, levels=c(&quot;овчарка&quot;, &quot;мопс&quot;, &quot;йорк&quot;, &quot;пудель&quot;)) f_dogs2 ## [1] мопс пудель овчарка йорк мопс мопс ## Levels: овчарка мопс йорк пудель str(f_dogs2) ## Factor w/ 4 levels &quot;овчарка&quot;,&quot;мопс&quot;,..: 2 4 1 3 2 2 str(f_dogs) ## Factor w/ 4 levels &quot;йорк&quot;,&quot;мопс&quot;,..: 2 4 3 1 2 2 Изменение уровней фактора levels(f_dogs) &lt;- c(&quot;йорк&quot;, &quot;шарпей&quot;, &quot;овчарка&quot;, &quot;пудель&quot;) #меняем мопсов на шарпеев f_dogs ## [1] шарпей пудель овчарка йорк шарпей шарпей ## Levels: йорк шарпей овчарка пудель 3.2.6 Упорядоченный фактор — ordered factor Допустим мы хотим знать, какая собака больше (чуть более реальный пример: размер одежды S-M-L и т.д. как фактор) f_dogs[1] &lt; f_dogs[2] ## Warning in Ops.factor(f_dogs[1], f_dogs[2]): &#39;&lt;&#39; not meaningful for factors ## [1] NA o_f_dogs &lt;- factor(f_dogs, ordered = TRUE, levels = c(&quot;йорк&quot;, &quot;пудель&quot;, &quot;шарпей&quot;, &quot;овчарка&quot;)) o_f_dogs ## [1] шарпей пудель овчарка йорк шарпей шарпей ## Levels: йорк &lt; пудель &lt; шарпей &lt; овчарка o_f_dogs[1] &lt; o_f_dogs[2] ## [1] FALSE При неупорядоченных факторах мы получили NA, при упорядочивании мы получили возможность сравнивать разные уровни. В нашей таблице у нас есть возможность представить строковые значения как факторы с помощью флажка stringsAsFactors = TRUE (по умолчанию он равен FALSE) data &lt;- read.table(file = &quot;about_us_eng.csv&quot;, sep=&quot;,&quot;, header=TRUE, stringsAsFactors = TRUE) data$beard ## [1] no no no no no no yes no no no no no no no no no no no no ## [20] yes no no no no no no no no no no no no no yes no ## Levels: no yes 3.2.7 Логические — boolean Логические данные имеют всего два вида: TRUE либо FALSE. Они часто возникают, когда мы хотим проверить какое-то условие: a == b ## [1] FALSE Операторы сравнения будут те же, что ф вормальной логике: == — равно != — не равно &gt; , &lt; — больше, меньше &gt;= — больше или равно &lt;= — меньше или равно Для объединения условий также есть специальные символы: &amp;&amp; или &amp; — и, ответ правда если оба условия правда ||' или|--- или, ответ правда если хотя бы одно условие правда!` — не, отрицание выражения, смена правды на ложь и наоборот У тебя есть две переменных: d &lt;- 24, e &lt;- 41. Проверьте условие: остаток от деление нацело этих двух переменных больше 0. Кстати, остаток от деления на 2 помогает проверить число на четное или нечетное. С логическими данными можно выполнять мат. операции, тогда TRUE — это 1, FALSE — это 0: c + TRUE ## [1] 19 NB! Допустимо использование вместо TRUE и FALSE сокращенного их вида: T и F. Но помните, что TRUE и FALSE — это служебные слова, эти имена невозможно присвоить, например, переменным. T и F такими не являются. Будьте осторожны с чужим кодом, и сами лучше не давайте такие имена объектам в коде. 3.2.8 Даты В R есть отдельные функции для облегчения работы с датами. Например, можно посчитать сколько дней прошло между двумя заданными датами. Как же их задавать? date1 &lt;- as.Date(&quot;2019-07-24&quot;) date1 ## [1] &quot;2019-07-24&quot; Можно писать другие форматы, но к ним нужны пояснения date2 &lt;- as.Date(&quot;07/24/2019&quot;, format = &quot;%m/%d/%Y&quot;) date2 ## [1] &quot;2019-07-24&quot; date1 ## [1] &quot;2019-07-24&quot; date3 &lt;- as.Date(&quot;24.07.2019&quot;, format = &quot;%d.%m.%Y&quot;) date3 ## [1] &quot;2019-07-24&quot; date1 ## [1] &quot;2019-07-24&quot; date4 &lt;- as.Date(&quot;07/24/19&quot;, format = &quot;%m/%d/%y&quot;) date4 ## [1] &quot;2019-07-24&quot; date1 ## [1] &quot;2019-07-24&quot; Вот так можно посмотреть список всех этих сокращений от даты и от времени (например, большая M — это минуты) `?`(strptime) Мы можем узнать системное время (определяется по твоему компу) и сравнить его с переменной Sys.Date() ## [1] &quot;2021-08-03&quot; date1&lt;Sys.Date() ## [1] TRUE 3.2.9 Пропущенные значения — missing values Часто в данных нам будут попадаться пропущенные значения. В R для них отдельное обозначение: NA. Многие встроенные функции с ними не работают, и тогда нам нужно выбирать: исключить пропущенное значение или заполнить его на основании какого-то предположения. При работе с грязными данными (то есть теми, которые не приведены к общему формату и с которыми неудобно работать) могут возникать ситуации, что вместо NA у вас будут или пустые строки \"\"или пробелы \" \". Их можно заменять на другие значения, в том числе на NA. 3.3 Структуры данных 3.3.1 Вектор Это самая базовая, простая структура. Вектор — это последовательность элементов одного и того же типа. Вектор можно создать командой конкатенации с(): a&lt;-c(1,2,3,3,2,1) a ## [1] 1 2 3 3 2 1 С числовыми векторами можно осуществлять самые разные преобразования. Благодаря векторизованности языка R, нам нет необходимости писать цикл, который будет применять операции к каждому елементу вектора. R это сделает сам. арифметические операции a*2 ## [1] 2 4 6 6 4 2 a*c(1,2,3,4) ## Warning in a * c(1, 2, 3, 4): longer object length is not a multiple of shorter ## object length ## [1] 1 4 9 12 2 2 a-5 ## [1] -4 -3 -2 -2 -3 -4 a^2 ## [1] 1 4 9 9 4 1 a/2 ## [1] 0.5 1.0 1.5 1.5 1.0 0.5 Как видите, чтобы перемножить вектора, они должны быть одинаковой длины: a*c(1,2,3,4,5,6) ## [1] 1 4 9 12 10 6 операции сравнения (важно! = — оператор присваивания! для сравнения используйте ==) a&lt;=1 ## [1] TRUE FALSE FALSE FALSE FALSE TRUE a!=1 ## [1] FALSE TRUE TRUE TRUE TRUE FALSE a==1 ## [1] TRUE FALSE FALSE FALSE FALSE TRUE В результате мы получаем вектор логических значений. Запомним, это пригодится нам далее. Вспомним, что в логических переменных TRUE — это 1, FALSE — это 0 tf = c(TRUE,TRUE,FALSE,TRUE) tf == 1 ## [1] TRUE TRUE FALSE TRUE tf == 0 ## [1] FALSE FALSE TRUE FALSE sum(tf) ## [1] 3 sum(tf == 0) ## [1] 1 Наш датасет, хранящийся в data, имеет 15 столбиков. Каждый столбик — это вектор. Мы можем извлекать их оттуда через знак $: data$height ## [1] 165 180 161 164 180 170 170 173 163 168 165 164 166 NA 173 173 183 170 185 ## [20] 169 185 172 158 185 168 175 162 182 164 167 175 167 168 179 172 У нас в данных есть NA —пропущенное значение: data$height[1:10]==164 ## [1] FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE data$height[1:10] — это выбор первых десяти значений из вектора, которые мы протом проверяем на равенство 164 Мы можем посчитать частоту каждого значения с помощью функции table() table(data$height) ## ## 158 161 162 163 164 165 166 167 168 169 170 172 173 175 179 180 182 183 185 ## 1 1 1 1 3 2 1 2 3 1 3 2 3 2 1 2 1 1 3 Вспомним, что мы можем совершать арифметические действия с логическими переменными и посчитаем, сколько человек выше 175см: sum(c(TRUE,TRUE,FALSE,TRUE)) ## [1] 3 sum(data$height&gt;175) ## [1] NA Опа, посчитать не получилось. Это потому что каждый элемент вектора нужно сравнить с 175, а для пропущенного значения это невозможно. давайте просто не будем его учитывать: sum(data$height&gt;175, na.rm=TRUE) ## [1] 8 Посчитаем среднее количество глаз на каждого из нас: mean(data$eye_number) ## [1] 5.057143 Все понятно, мы — ангелы Гистограмма распределения размеров обуви и самый большой размер: shoes&lt;-data$shoe_size hist(shoes) max(shoes) ## [1] 45 Вектор может быть именованным и к каждому элементу тогда можно обратиться по имени: b&lt;-c(&quot;e&quot;=1,&quot;f&quot;=2,&quot;g&quot;=3) b ## e f g ## 1 2 3 b[&#39;f&#39;] ## f ## 2 names(b) ## [1] &quot;e&quot; &quot;f&quot; &quot;g&quot; А если имени нет? Тогда можно по номеру в последовательности: b[2] ## f ## 2 Или сразу по вектору номеров! NB! В R нумерация элементов начинается с 1, но не в каждом языке программирования так. b[c(1,3)] ## e g ## 1 3 Или по логическому вектору отфильтровать другой вектор: b[c(TRUE,FALSE,TRUE)] ## e g ## 1 3 Мы можем выбрать не одну, а несколько колонок из таблицы с помощью вектора: data[c(&quot;eye_color&quot;,&quot;gorgeous&quot;)] 3.3.2 Матрицы Матрица - такая структура данных, где есть столбики и строки. Вектор может быть превращён в матрицу. Для этого надо сказать, сколько в нём строчек или столбиков. Пока что они нам не пригодятся. 3.3.3 Списки Список (list) - структура, которая может включать в себя набор из данных разного формата, например, вектор и строку, число и матрицу и пр. u0 &lt;- list(&#39;A&#39;, 1) u0 ## [[1]] ## [1] &quot;A&quot; ## ## [[2]] ## [1] 1 Мы можем посмотреть структуру объекта: u &lt;- list(&quot;A&quot;, 1, list (&quot;A&quot;, T)) str(u) ## List of 3 ## $ : chr &quot;A&quot; ## $ : num 1 ## $ :List of 2 ## ..$ : chr &quot;A&quot; ## ..$ : logi TRUE Представим, что список — это мешочек. Функция unlist() вытаскивает предметы из мешочка и просто выставляет их на стол uu &lt;- c(list(&quot;a&quot;,5),list(list(5))) str(uu) ## List of 3 ## $ : chr &quot;a&quot; ## $ : num 5 ## $ :List of 1 ## ..$ : num 5 unlist(u) ## [1] &quot;A&quot; &quot;1&quot; &quot;A&quot; &quot;TRUE&quot; Можно превратить список в другие структуры данных, например, таблицу или матрицу. u &lt;- list(&quot;a&quot;=c(1,2),&quot;b&quot;=c(3,4)) str(u) ## List of 2 ## $ a: num [1:2] 1 2 ## $ b: num [1:2] 3 4 u2 &lt;- as.data.frame(u) u3 &lt;- as.matrix(u2) u4 &lt;- as.matrix(u) Найдите эти переменные в глобальном окружении. Выглядят они похоже, но описания у них в глобальном окружении разные, как и принципы работы с ними. Элементам списка также можно давать имена, а не обращаться к ним по номерам: u &lt;- list(&#39;a&#39;, matrix(c(1, 2))) names(u) &lt;- c(&#39;meow&#39;, &#39;meow_num&#39;) u ## $meow ## [1] &quot;a&quot; ## ## $meow_num ## [,1] ## [1,] 1 ## [2,] 2 Выведем второй элемент списка и посмотрим, какой тип данных он имеет: u[2] ## $meow_num ## [,1] ## [1,] 1 ## [2,] 2 class(u[2]) ## [1] &quot;list&quot; Второй элемент этого списка был превращен из матрицы с одной колонкой в вертикальный список с именем meow_num, состоящий из одного элемента — матрицы. Чтобы нам добраться до самого второго элемента именнованного списка — матрицы — нужно использовать двойные скобки [[x]]. Это особенность синтаксиса. u[[2]] ## [,1] ## [1,] 1 ## [2,] 2 class(u[[2]]) ## [1] &quot;matrix&quot; &quot;array&quot; Либо обратиться не по индексу, а по имени: u$meow ## [1] &quot;a&quot; 3.3.4 Дата фреймы Это наши любимые таблицы. В каждом столбце находятся элементы одного типа. В переменной data находится наш датафрейм. Как и с векторами, есть три базовых способа фильтрации датафреймов: с помощью вектора с адресами (номерами строк) data10_1&lt;-data[1:10,] с помощью вектора с именами data10_1&lt;-data[c(1:5,7:10),c(&quot;soft_drink&quot;,&quot;hot_drink&quot;)] С помощью логического вектора (rep() - функция, генерирующая повторяющиеся значения) data10_1&lt;-data[c(rep(TRUE,10),rep(FALSE,25)),] Подробнее о логической фильтрации будет в следующем уроке. 3.3.5 Другие Есть структуры данных более высокого уровня: функции, циклы, классы (например, класс numeric), объекты. С частью из них мы познакомимся далее. 3.4 Функции и простые действия с данными Для начала мы можем узнать тип данных, из которых состоит вектор. ch &lt;- c(&#39;apple&#39;, &#39;pear&#39;, &#39;banana&#39;, &#39;orange&#39;) ch ## [1] &quot;apple&quot; &quot;pear&quot; &quot;banana&quot; &quot;orange&quot; typeof(ch) ## [1] &quot;character&quot; Сколько уникальных элементов содержится в векторе? ch2 &lt;- c(&#39;apple&#39;, &#39;pear&#39;, &#39;banana&#39;, &#39;orange&#39;, &#39;apple&#39;, &#39;apple&#39;) unique(ch2) ## [1] &quot;apple&quot; &quot;pear&quot; &quot;banana&quot; &quot;orange&quot; sort(ch2) #сортировка объектов ## [1] &quot;apple&quot; &quot;apple&quot; &quot;apple&quot; &quot;banana&quot; &quot;orange&quot; &quot;pear&quot; Фильтруем все, что по алфавиту идет раньше ‘ba’. При этом считается, что ‘ba..’ идет позже просто ‘ba’ ch[ch&gt;&quot;ba&quot;] ## [1] &quot;pear&quot; &quot;banana&quot; &quot;orange&quot; Сколько символов в элементах вектора? length(ch) ## [1] 4 nchar(ch) ## [1] 5 4 6 6 Поиск элементов grep(&#39;b&#39;, ch, value=TRUE) #дает само значение ## [1] &quot;banana&quot; grep(&#39;b&#39;, ch, value=FALSE) #дает порядковый номер элемента ## [1] 3 ch[grep(&#39;b&#39;, ch, value=FALSE)] #определяет значение по порядковому номеру элемента ## [1] &quot;banana&quot; Bывод элемента по номеру ch2[1] ## [1] &quot;apple&quot; Исключение элемента по номеру ch2[-4] ## [1] &quot;apple&quot; &quot;pear&quot; &quot;banana&quot; &quot;apple&quot; &quot;apple&quot; ch[-1] ## [1] &quot;pear&quot; &quot;banana&quot; &quot;orange&quot; ch2[-c(1, 2)] ## [1] &quot;banana&quot; &quot;orange&quot; &quot;apple&quot; &quot;apple&quot; Разбиение по разделителю (пробел) text &lt;- &#39;Ну-ка фрукты встаньте в ряд&#39; strsplit(text, &#39; &#39;) ## [[1]] ## [1] &quot;Ну-ка&quot; &quot;фрукты&quot; &quot;встаньте&quot; &quot;в&quot; &quot;ряд&quot; a &lt;- strsplit(text, &#39; &#39;) typeof(a) ## [1] &quot;list&quot; typeof(a[1]) ## [1] &quot;list&quot; Строка с пропусками вида character и digit sprintf(&quot;%s отправляется в %d часов&quot;, &quot;Электричка&quot;, 12) ## [1] &quot;Электричка отправляется в 12 часов&quot; sprintf(&quot;%s отправляется в %d часов&quot;, rep(&quot;Электричка&quot;, 2), c(12, 13)) ## [1] &quot;Электричка отправляется в 12 часов&quot; &quot;Электричка отправляется в 13 часов&quot; Вытащить кусок строки substr(&quot;Я маленькая лошадка&quot;, start=3, stop=12) ## [1] &quot;маленькая &quot; Заменить кусок внутри строки sub(&quot;маленькая&quot;, &quot;большая&quot;, &quot;Я маленькая лошадка&quot;) ## [1] &quot;Я большая лошадка&quot; sub(&quot;маленькая&quot;, &quot;большая&quot;, &quot;Я маленькая маленькая лошадка&quot;) #заменяет только первое появление подстроки ## [1] &quot;Я большая маленькая лошадка&quot; gsub(&quot;маленькая&quot;, &quot;большая&quot;, &quot;Я маленькая маленькая лошадка&quot;) ## [1] &quot;Я большая большая лошадка&quot; Отбор элементов по номеру позиции (индекс) и по его значению d &lt;- c(1,2,6,4) d&gt;2 ## [1] FALSE FALSE TRUE TRUE d[d&gt;2] #сами элементы ## [1] 6 4 which(d&gt;2) #номера их позиций ## [1] 3 4 Можно проверить, принадлежат ли элементы вектора определенному типу данных int_num&lt;-c(1,2,3,4000) is.integer(int_num) ## [1] FALSE typeof(int_num) ## [1] &quot;double&quot; К целочисленному выражению элементы вектора можно привести несколькими способами: int_num&lt;-as.integer(c(1,2,3,4000)) int_num&lt;-c(1L,2L,3L,4000L) #сохраняет как целые as.integer(214748364.7) ## [1] 214748364 as.integer(2147483648) #слишком большое число, не может хранить ## Warning: NAs introduced by coercion to integer range ## [1] NA as.integer(-2147483647) ## [1] -2147483647 as.integer(-2147483648) ## Warning: NAs introduced by coercion to integer range ## [1] NA Для больших чисел мы вынуждены использовать формат с плавающей точкой, он может хранить больше информации as.double(&quot;10000998843483274893274892374238947273&quot;) ## [1] 1.0001e+37 Включение scientific notation options(scipen=999) 2^64 ## [1] 18446744073709551616 90071992547409923 ## [1] 90071992547409920 options(scipen=0) 2^64 ## [1] 1.844674e+19 90071992547409923 ## [1] 9.007199e+16 Numeric - класс, общее название для числовых данных, включает в себя и double, и integer. Подробнее о форматах можно посмотреть в справке ?double и ?integer. numeric_num&lt;-c(1,2,2.5) is.integer(numeric_num) ## [1] FALSE is.integer(int_num) ## [1] TRUE is.numeric(int_num) ## [1] TRUE is.numeric(numeric_num) ## [1] TRUE str(numeric_num) ## num [1:3] 1 2 2.5 is.double(numeric_num) ## [1] TRUE typeof(numeric_num) ## [1] &quot;double&quot; Объединение векторов с разнымм типами значений n &lt;- c(1,2,3) s &lt;- c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) c(n,s) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;a&quot; &quot;b&quot; &quot;c&quot; Как видите, при объединении числовой формат был переделан в строковый. Как мы узнали ранее, разные форматы можно хранить только в списках и таблицах. 3.5 Задания для тренировки Соедини значение 1 и TRUE в вектор. Что получилось? У тебя есть вектор 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. Создай из него матрицу с заполнением по строкам. Выбери первый столбец. Помни, что при фильтрации в формате vec[x, y], x— это строка, y — это столбец. Список со вложенными списками subjects &lt;- list(list(‘Masha’, 18, list(39, 40)), list(‘Nastya’, 22, 41), list(‘Mitya’, 25, 46)). Выведи второй элемент третьего элемента первого списка. Что это за число? Поэкспериментируй. Не забудь про двойные кавычки [[]]. Определи среднее, сумму, максимальное и минимальное значение в векторе data$hair_length. Нарисуй гистограмму. Выведи вектор, получившийся в результате проверки каждого элемента из data$hair_length на четность/нечетность (используй остаток от целочисленного деления) Из нашей таблицы data выбери элемент, находящийся на 18 строке в 6 столбце и выведи на экран с помощью функции paste() "],["фильтрация-строк-и-столбцов-в-base-r-введение-в-data-table.html", "4 Фильтрация строк и столбцов в base R. Введение в data.table 4.1 Фильтрация строк и столбцов в base R", " 4 Фильтрация строк и столбцов в base R. Введение в data.table library(data.table) 4.1 Фильтрация строк и столбцов в base R Из прошлой главы вы узнали, как вообще выглядит RStudio, какие звери (в смысле, типы и структуры данных) в нём обитают, и даже научились фильтровать элементы векторов и дата.фреймов по индексам и по именам. Но есть ещё один очень важный способ фильтрации - это фильтрация по условию. 4.1.1 Фильтрация вектора по условию Фильтрация по условию нужна, когда вы хотите выбрать только ту часть данных, которая удовлетворяет какое-нибудь (вы не поверите) условие. Например: ваш коллега провёл эксперимент и записал возраста всех ваших испытуемых в вектор. Теперь вы хотите посчитать средний возраст испытуемых, чтобы описать его в методах будущей великой статьи, но вот незадача для исследовательского вопроса вам подходят только те, кому больше 18 и меньше 45, а ваш коллега записывал возраста всех, кто пришёл. Так что надо найти в этом векторе тех, кто слишком млад или слишком стар, и исключить их, а уж потом считать хоть среднее, хоть медиану, хоть дисперсию. Давайте для начала создадим вектор возрастов (я придумала их из головы). ages &lt;- c(25, 69, 23, 27, 32, 45, 21, 16, 19, 17, 20, 55, 27, 18, 16, 39, 14) Чтобы найти, где в нашем векторе люди, которым больше 45, мы можем воспользоваться логическим оператором “больше”: ages &gt; 45 ## [1] FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE ## [13] FALSE FALSE FALSE FALSE FALSE Первый TRUE находится на 2 месте в получившемся логическом векторе, так что мы знаем, что седьмой человек в векторе возрастов старше 45. И правда, ему (или ей) 69 лет: ages[2] ## [1] 69 Но мы же не будем каждый раз вручную искать, где в нашем логическом векторе TRUE? Конечно, не будем! Потому что этот логический вектор можно использовать для фильтрации! Фильтрация с помощью логического вектора работает просто: если на месте элемента в логическом векторе стоит TRUE, мы его включаем, а если FALSE, то не включаем. Если мы используем логический вектор, который получается в результате команды ages &gt; 45, для фильтрации нашего вектора ages, то получим следующий вектор: ages[ages &gt; 45] ## [1] 69 55 Упс, кажется, это не то, чего мы хотели! Мы включили все элементы, которые удовлетворяют нашему условию - то есть те, которые больше 45. А нам-то надо, наоборот, оставить тех, кому меньше 45! Давайте это сделаем: ages[ages &lt; 45] ## [1] 25 23 27 32 21 16 19 17 20 27 18 16 39 14 Ура! Но подростки всё ещё остались. Что делать с ними? Мы можем соединить сочетание двух логических условий с помощью логического оператора “и” - &amp;. Для начала давайте посмотрим на сам логический вектор, который у нас получается: ages &lt; 45 &amp; ages &gt; 18 ## [1] TRUE FALSE TRUE TRUE TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE ## [13] TRUE FALSE FALSE TRUE FALSE Логический оператор &amp; возвращает TRUE, только если удовлетворены оба условия - так что теперь в нашем векторе TRUE получили только те испытуемые, возраст которых нам подходит, так что именно их мы и отберём, если используем этот вектор для фильтрации. Вот так счастье! Вот так радость! Давайте же, наконец-то, узнаем средний возраст наших корректных испытуемых: correctAges &lt;- ages[ages &lt; 45 &amp; ages &gt; 18] mean(correctAges) ## [1] 25.88889 Ура! 4.1.2 Фильтрация дата.фрейма по условию Такую логику фильтрации можно применять не только к векторам, но и к любым табличным данным - например, к матрицам или дата.фреймам. Давайте загрузим наш дата.фрейм в переменную df (не забудьте указать правильную рабочую директорию - папку, в которой лежит файл у вас на компьютере) и посмотрим, как он выглядит: df &lt;- read.csv(&quot;about_us_eng.csv&quot;) str(df) ## &#39;data.frame&#39;: 35 obs. of 15 variables: ## $ height : int 165 180 161 164 180 170 170 173 163 168 ... ## $ eye_color : chr &quot;green&quot; &quot;brown&quot; &quot;blue&quot; &quot;brown&quot; ... ## $ eye_number : int 2 2 2 2 2 2 2 2 2 3 ... ## $ beard : chr &quot;no&quot; &quot;no&quot; &quot;no&quot; &quot;no&quot; ... ## $ soft_drink : chr &quot;coke&quot; &quot;coke&quot; &quot;no thanks&quot; &quot;coke&quot; ... ## $ cats : chr &quot;this is too personal&quot; &quot;1&quot; &quot;0&quot; &quot;0&quot; ... ## $ gorgeous : int 10 10 7 10 6 10 8 8 7 9 ... ## $ siblings : int 1 2 1 0 1 3 2 1 2 0 ... ## $ hair_length: int 25 7 20 20 10 20 30 40 30 30 ... ## $ shoe_size : num 38 43 38 38 42 39 42 41 38 38 ... ## $ guitar : chr &quot;What is a guitar? A giant ukulele?&quot; &quot;I am a portable speaker with an expanded repertoire of Nashe radio&quot; &quot;I can play one song of Tsoy. The one with the four chords.&quot; &quot;I am a portable speaker with an expanded repertoire of Nashe radio&quot; ... ## $ hot_drink : chr &quot;tea&quot; &quot;shall we dance&quot; &quot;shall we dance&quot; &quot;shall we dance&quot; ... ## $ month : chr &quot;February&quot; &quot;June&quot; &quot;July&quot; &quot;November&quot; ... ## $ hogwarts : chr &quot;Hufflepuff&quot; &quot;Gryffindor&quot; &quot;Slytherin&quot; &quot;Slytherin&quot; ... ## $ dream : chr &quot;rock star&quot; &quot;rock star&quot; &quot;Rick from Rick and Morty&quot; &quot;astronaut&quot; ... Ага, прекрасно. Например, у нас в датасете есть колонка eye_number - там был вопрос “Сколько у вас глаз?”. Скорее всего, люди, которые ответили, что у них больше двух глаз, или шутники, или шестикрылые серафимы - так или иначе, давайте исключим их из нашего очень серьёзного опроса. Как мы можем это сделать? Логика здесь совершенно та же, что и в прошлом примере - мы воспользуемся логическим вектором. Для этого нам нужно вспомнить ещё два факта: во-первых, фильтровать дата.фрейм мы можем и по строкам, и по столбцам. Например, вот такая команда выберет только строки с индексами от 1 до 5 (то есть первые пять) и столбцы с индексами от 1 до 10 (то есть первые десять): df[1:5,1:10] Во-вторых, мы можем “вытащить” колонку дата.фрейма и обращаться с ней, как с вектором, с помощью знака доллара, $. Вот такая команда сохранит в переменную eyeNumberVec колонку eye_number наше дата.фрейма df: eyeNumberVec &lt;- df$eye_number eyeNumberVec ## [1] 2 2 2 2 2 2 2 2 2 3 2 2 3 2 2 2 2 2 2 ## [20] 3 2 2 2 2 2 2 2 2 4 104 2 2 2 2 2 Эту вытащенную колонку мы можем проверить на соответствие нашему условию (не больше двух глаз): eyeNumber2Below &lt;- eyeNumberVec &lt;= 2 eyeNumber2Below ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE ## [13] FALSE TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE ## [25] TRUE TRUE TRUE TRUE FALSE FALSE TRUE TRUE TRUE TRUE TRUE Каждая строка нашего дата.фрейма этот ответ одного респондента на все вопросы. Так что, если мы используем этот вектор, чтобы оставить в нашем дата.фрейме только строки, в которых у респондента не больше двух глаз, то и многоглазых респондентов в нашем дата.фрейме не останется. Это может немного запутать в самом начале: условие у нас для колонки (не больше 2 в колонке eye_number), а убираем мы строки. Раз убираем строки, то и используем наше условие в той части квадратных скобок, где строки. То есть - до запятой. dfOnly2Eyes &lt;- df[eyeNumber2Below,] Всё то же самое можно сделать, не создавая промежуточные вектора eyeNumberVec и eyeNumberVecBelow2: dfOnly2Eyes &lt;- df[df$eye_number &lt;= 2,] Часто мы хотим фильтровать данные по нескольким условиям сразу, зачастую достаточно сложным - например, давайте оставим только гриффиндорцев, у которых или очень короткие волосы (короче 10 см) или очень маленький размер ноги (меньше 38). Конечно, это всегда можно сделать в два этапа - сначала выбрать гриффиндорцев, а потом из них выбрать коротковолосых или мелконогих: dfOnlyGr &lt;- df[df$hogwarts == &quot;Gryffindor&quot;,] dfOnlySmallGr &lt;- dfOnlyGr[dfOnlyGr$hair_length &lt; 10 | dfOnlyGr$shoe_size &lt; 38] Но у нас в среде останется этот вспомогательный дата.фрейм dfOnlyGr… Давайте лучше соединим оба условия воедино - а чтобы указать, как они между собой соотносятся, воспользуемся круглыми скобкам: dfOnlySmallGr &lt;- df[df$hogwarts == &quot;Gryffindor&quot; &amp; (df$hair_length &lt; 10 | df$shoe_size &lt; 38),] Красота! Задание: Уберите из дата.фрейма всех подозрительных респондентов - и тех, у кого больше двух глаз, и тех, у кого нереалистичный рост (скажем, меньше, чем 140 см, или больше, чем 220 см), если такие есть, и тех, кто ответил, что они не рождались в вопросе про месяц рождения. Задание: Создайте отдельный дата.фрейм, в котором у нас будут только люди, которые родились зимой или осенью, и попали бы в Хогвартсе или в Слизерин, или в Рейвенкло. 4.1.3 Фильтрация по результату функции Иногда мы хотим отфильтровать значения не по абсолютному условию (все респонденты, у которых больше 1 сиблинга), а по относительному (все респонденты, у которых больше сиблингов, чем в среднем в выборке). Чтобы это сделать, мы можем сравнивать значения вектора или колонки дата.фрейма с результатом какой-нибудь функции, например, mean(). Это можно сделать в две строки, сначала посчитав среднее, а потом использовав его в сравнении: meanSibs &lt;- mean(df$siblings) dfAboveMeanSibs &lt;- df[df$siblings &gt; meanSibs,] dfAboveMeanSibs &lt;- df[df$siblings &gt; mean(df$siblings),] 4.1.4 Фильтрация для группировки Часто мы хотим узнать что-нибудь про разные группы людей, которые есть в наших данных. Например, может быть, мы напоили испытуемых кофе, чаем или водой и ожидаем, что в зависимости от напитка они будут хуже или лучше решать задачи - тогда мы хотим посчитать, сколько задач в среднем решили испытуемые из каждой группы. Здесь нам тоже может пригодиться фильтрация. Давайте узнаем, сколько в средним братьев и сестёр у наших респондентов, которые в Хогвартсе попали бы на разные факультеты. Для этого мы произведём четыре отдельных фильтрации (по одной на каждый факультет), а из колонок выберем только siblings. (Если вы не помните, как пишутся факультеты, то всегда можно проверить с помощью unique(df$hogwarts) - эта команда вернёт все уникальные значения в векторе). siblingsGr &lt;- df[df$hogwarts == &quot;Gryffindor&quot;, &quot;siblings&quot;] siblingsRav &lt;- df[df$hogwarts == &quot;Ravenclaw&quot;, &quot;siblings&quot;] siblingsSl &lt;- df[df$hogwarts == &quot;Slytherin&quot;, &quot;siblings&quot;] siblingsHuff &lt;- df[df$hogwarts == &quot;Hufflepuff&quot;, &quot;siblings&quot;] И теперь можно воспользоваться функцией mean(), чтобы посчитать среднее значение каждого вектора: mean(siblingsGr) ## [1] 1.333333 mean(siblingsRav) ## [1] 1.214286 mean(siblingsSl) ## [1] 0.8333333 mean(siblingsHuff) ## [1] 0.6666667 Задание: Воспользуйтесь функцией max(), чтобы найти самого высокого человека для каждого уровня игры на гитаре. Такой подход, конечно, не самый эффективный - если у вас всего четыре категории, то ничего страшного, но что если у вас их, например, сто? Сразу хочется как-то это дело автоматизировать, и сейчас мы научимся это делать. Но перед этим я хочу дать вам совет: иногда вы не будете помнить, как что-то сделать эффективно (может быть, на хакатоне в субботу у вас будет такая проблема) - и тогда нет никакого зашквара в том, чтобы сделать, как можете. Эффективный код это прекрасно, но самое прекрасное это код, который работает и делает то, что вам нужно :) Эффективность приходит с опытом, так что пока я бы не советовала переживать о ней слишком сильно. 4.1.5 Введение в data.table Дата.фрейм это структура данных, которая по умолчанию встроена в R. Но большинство людей в своей реальной работе с данными используют одну из двух внешних библиотек: или data.table, или dplyr. Обе этих библиотеки имеют свою структуру для табличных данных (собственно, data.table в первой, tibble во второй) с расширенным функционалом. Ходят слухи, что если зайти в чат про R в пятницу вечером, там будут спорить или про R vs. Python, или про data.table vs. dplyr. У каждой библиотеки есть свои сильные и слабые стороны (data.table быстрее и лаконичнее, с dplyr получается более “читаемый” код). Среди организаторов АнДана есть сторонники обеих библиотек (и на Питоне многие из нас тоже пишут, кстати :D). Лично я (Маша) считаю, что важно хорошо знать хотя бы одну - в целом, любую, а со второй, если надо, дальше можно разобраться. В этом курсе мы с вами будем пользоваться data.table. Итак, как же воспользоваться внешней библиотекой? Для этого вам нужно будет выполнить две команды. Во-первых, библиотеку нужно установить с помощью команды install.packages(). Обратите внимание, что имя библиотеки пишется в кавычках: install.packages(&#39;data.table&#39;) Устанавливать библиотеку нужно один раз, и если вы молодечик, то сделали это до школы :) Во-вторых, библиотеку нужно подгрузить (другими словами, активировать) с помощью команды library(). Это нужно делать в начале каждой рабочей сессии - то есть, каждый раз, когда вы открываете RStudio. Обычно принято декларировать все библиотеки, которые вы используете в скрипте, в самом верху скрипта (если вы проскроллите наверх, то увидите, что я так и сделала). Здесь имя библиотеки пишется без кавычек: library(data.table) Создать дата.тейбл с нуля можно так же, как и дата.фрейм, только используя функцию data.table(): dt &lt;- data.table(number = 1:5, name = c(&quot;Masha&quot;, &quot;Sasha&quot;, &quot;Pet&#39;ka&quot;, &quot;Dasha&quot;, &quot;Vladimir Petrovich&quot;)) Превратить имеющийся дата.фрейм в дата.тейбл - с помощью функции as.data.table(): dt &lt;- as.data.table(df) А загрузить csv-документ сразу в дата.тейбл можно с помощью функции fread(): dt &lt;- fread(&quot;about_us_eng.csv&quot;) str(dt) ## Classes &#39;data.table&#39; and &#39;data.frame&#39;: 35 obs. of 15 variables: ## $ height : int 165 180 161 164 180 170 170 173 163 168 ... ## $ eye_color : chr &quot;green&quot; &quot;brown&quot; &quot;blue&quot; &quot;brown&quot; ... ## $ eye_number : int 2 2 2 2 2 2 2 2 2 3 ... ## $ beard : chr &quot;no&quot; &quot;no&quot; &quot;no&quot; &quot;no&quot; ... ## $ soft_drink : chr &quot;coke&quot; &quot;coke&quot; &quot;no thanks&quot; &quot;coke&quot; ... ## $ cats : chr &quot;this is too personal&quot; &quot;1&quot; &quot;0&quot; &quot;0&quot; ... ## $ gorgeous : int 10 10 7 10 6 10 8 8 7 9 ... ## $ siblings : int 1 2 1 0 1 3 2 1 2 0 ... ## $ hair_length: int 25 7 20 20 10 20 30 40 30 30 ... ## $ shoe_size : num 38 43 38 38 42 39 42 41 38 38 ... ## $ guitar : chr &quot;What is a guitar? A giant ukulele?&quot; &quot;I am a portable speaker with an expanded repertoire of Nashe radio&quot; &quot;I can play one song of Tsoy. The one with the four chords.&quot; &quot;I am a portable speaker with an expanded repertoire of Nashe radio&quot; ... ## $ hot_drink : chr &quot;tea&quot; &quot;shall we dance&quot; &quot;shall we dance&quot; &quot;shall we dance&quot; ... ## $ month : chr &quot;February&quot; &quot;June&quot; &quot;July&quot; &quot;November&quot; ... ## $ hogwarts : chr &quot;Hufflepuff&quot; &quot;Gryffindor&quot; &quot;Slytherin&quot; &quot;Slytherin&quot; ... ## $ dream : chr &quot;rock star&quot; &quot;rock star&quot; &quot;Rick from Rick and Morty&quot; &quot;astronaut&quot; ... ## - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; На первый взгляд наш дата.тейбл выглядит совершенно так же, как дата.фрейм. Больше скажу - с ним можно делать всё то же самое, что с дата.фреймом - фильтровать строки и колонки по индексам и обращаться к колонкам с помощью $: dt[1,1] dt[1,] dt[,1] dt[1:3,] dt$height ## [1] 165 180 161 164 180 170 170 173 163 168 165 164 166 NA 173 173 183 170 185 ## [20] 169 185 172 158 185 168 175 162 182 164 167 175 167 168 179 172 Но помимо этого у дата.тейблов есть очень крутой дополнительный функционал со своим специфическим синтаксисом. У дата.фрейма в квадратных скобках две части: df[фильтрация строк, фильтрация столбцов]. У дата.тейбла - три, да ещё и смысл второй поменялся: dt[фильтрация строк, выражение, параметр]. Перед первой запятой мы выбираем, какие строки мы хотим оставить в дата.тейбле - и теперь мы можем обращаться к колонкам напрямую, не используя конструкцию типа df$height, дата.тейбл по умолчанию считает, что внутри квадратных скобок вы можете обращаться к колонкам: dt[height &gt; 165, ] Между первой и второй запятой мы уточняем, что мы хотим сделать с колонками. Мы можем просто выбрать одну колонку и “достать” только её: dt[height &gt; 165, eye_number] ## [1] 2 2 2 2 2 3 3 2 2 2 2 2 3 2 2 2 2 2 2 ## [20] 104 2 2 2 2 2 Можем выбрать колонку и произвести над ней какую-нибудь операцию: dt[height &gt; 165, max(eye_number)] ## [1] 104 В предыдущей команде мы сначала выбрали только те строки (= респондентов), которые выше 165 см, а потом узнали, какое среди них максимальное число глаз. А можем создать новую колонку внутри нашего дата.тейбла. Для этого мы будем использовать новый оператор, := (Владимир Львович Волохонский называет его “приписька”. Живите теперь тоже с этим знанием): dt[, height_meters := height/100] Теперь у нас в дата.тейбле есть колонка height_meters, в которой хранится рост каждого испытуемого в метрах (то есть, 165 см превращается в 1.65 м). Обратите внимание - я не фильтровала строки, перед первой запятой ничего нет. Но поставить её надо, чтобы дата.тейбл понял, что вы пишете код height_meters := height/100 во втором компоненте. Но и это не самое клёвое! Ведь у нас есть третья часть (следите за руками - это часть после двух запятых). В третьей части мы можем указать, по какой колонке сгруппировать данные. Следующая строчка исключит всех респондентов, у которых больше двух глаз, и посчитает среднюю длину волос для каждого факультета: dt[eye_number &lt;= 2, mean(hair_length), by = hogwarts] Задание: Найдите самого высокого человека, родившегося в каждый из месяцев. Тех, кто в вопросе про месяцы указал “Я не рождался(-лась)”, исключите из подсчётов. Подсказка: функция max() выдаст NA для одного из месяцев, потому что кто-то не ответил на вопрос о росте. Исключите NA из подсчётов: max(height, na.rm = TRUE). na.rm значит NA remove - то бишь, убирать ли NA при поиске максимального значения. Задание: С помощью функции sum() узнайте, сколько суммарно братьев и сестёр у всех голубоглазых. А сколько у всех зеленоглазых? Найдите оба ответа одной строчкой кода :) Задание: Какой средний размер обуви у тех, кто выбрал чай (а не кофе или потанцевать)? Если у вас есть вопросы про эту главу, скорее задайте их в канале #day1-afternoon-filter. Если после выполнения заданий у вас остались время и силы, вы можете воспользоваться тем, что мы сегодня прошли, чтобы постараться и найти самые интересные факты о нашем датасете. А если вы устали - идите отдыхать! :) Завтра - больше. "],["cтатистические-критерии-корреляции.html", "5 Cтатистические критерии, корреляции 5.1 Введение 5.2 Goodness-of-fit tests 5.3 Тестирование взаимосвязи между двумя категориальными переменными 5.4 Критерии для порядковых или ненормально распределённых переменных 5.5 Сравнение средних 5.6 Коэффициенты корреляции 5.7 Бонус: визуализация корреляционной матрицы", " 5 Cтатистические критерии, корреляции .spoiler { visibility: hidden; background: #ffffe0 } .spoiler::before { visibility: visible; background: cyan; content: \"Спойлер! Наведите, чтобы увидеть ответ\" } .spoiler:hover { visibility: visible; } .spoiler:hover::before { display: none; } 5.1 Введение Дисклеймер: в этом файле под каждым заданием есть текстовые ответы (без кода), скрытые под синенькой плашкой “спойлер”. Она срабатывает при наведённом на неё курсоре: Если вы случайно проспойлерили себе ответ, не расстраивайтесь, вам всё ещё нужно написать код, который будет выдавать этот ответ :) В этом материале мы разберём некоторые часто используемые статистические критерии (тесты) - базовые инструменты для проверки статистических гипотез. Мы будем использовать датасет, который собрали вместе с вами в опросе перед школой. На всякий случай, ещё раз описание переменных: height рост в сантиметрах eye_color цвет глаз eye_number количество глаз beard борода: есть/нет soft_drink кола/пепси/нет спасибо cats количество кошек gorgeous степень великолепности от 1 до 10 siblings число братьев и сестер hair_length длина волос (см) shoe_size размер обуви guitar уровень игры на гитаре hot_drink чай/кофе/потанцуем month месяц рождения hogwarts факультет в хогвартсе dream кем мечтали стать в детстве Выбор теста зависит от задачи, от типа данных, которые у вас есть, а также иногда от размера выборки. 5.2 Goodness-of-fit tests Первое, что мы обсудим - это критерии согласованности (goodness-of-fit): биномиальный и хи-квадрат. Они используются, когда у нас есть какая-то выборка и теоретическое предположение о параметрах распределения в генеральной совокупности, и показывают вероятность получить данную выборку из генеральной совокупности с такими параметрами. 5.2.1 Биномиальный критерий Биномиальный критерий используется для выборки из биномиального распределения. Это распределение числа успехов в серии испытаний Бернулли. Самый простой пример – как обычно, подбрасывание монетки :) Мы заранее знаем про монетку, что она выпадает орлом в 50% случаев. Если из 10 подбрасываний 9 раз выпал орёл, мы можем подсчитать в точности, насколько вероятно было такое событие, и решить, кривая ли эта монетка. Возможно, вам знакома формула: \\[P(k) = \\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}\\] Так это вот оно и есть (вероятность получить k орлов из n подбрасываний, при теоретическом предположении, что вероятность орла равна p) В R используется функция binom.test(x,n,p), где x – количество успехов, n – количество испытаний, p – теоретическая вероятность. Давайте сразу попробуем с монеткой: binom.test(9,10,0.5) ## ## Exact binomial test ## ## data: 9 and 10 ## number of successes = 9, number of trials = 10, p-value = 0.02148 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.5549839 0.9974714 ## sample estimates: ## probability of success ## 0.9 Что показывает нам выдача: альтернативную гипотезу теста (истинная вероятность выпадения орла не равна 0.5) sample estimate – вероятность орла на нашей конкретной выборке (0.9) 95%-ный доверительный интервал для выборочной вероятности (который не захватывает теоретическую вероятность 0.5, значит, скорее всего, монетка кривая) p-value (собственно, вероятность получить 9 орлов, если бы монетка было ровная). Считать ли вероятность 0.02 достаточно маленькой для признания монетки кривой – это наш личный выбор, в мире монеток всё возможно. Если обратиться к одному из конвенциональных значений p-value &lt; 0.05, то да, монетка кривая :) Теперь к реальным данным! Давайте посчитаем среди нас число людей с третьим глазом и их долю. # сначала подгрузим данные df &lt;- read.csv(&#39;about_us_eng.csv&#39;) sum(df$eye_number == 3) ## [1] 3 sum(df$eye_number == 3)/nrow(df) ## [1] 0.08571429 nrow() – это число строк в датасете – то есть количество наблюдений Итак, вероятность случайно выбранному человеку иметь третий глаз равна всего 0.086 (или 8.6%). ЗАДАЧКА Отфильтруйте в отдельный датасет всех людей, у который ровно одна кошка. Проверьте гипотезу, что среди них вероятность иметь третий глаз значимо не отличается от 0.086. Какова в точности вероятность третьего глаза у людей с одной кошкой? Отличается ли она от 0.086 на основе p-value? Вероятность = 0.15, но разница с 0.086 не значима (p-value=0.3) Кстати: помимо x, n, p функция binom.test() принимает на вход параметры alternative и conf.level. Первый параметр – это право/лево/сторонняя альтернатива, а второй – уровень значимости. Такие параметры есть во всех или почти всех критериях, и их можно менять. По дефолту альтернатива обычно двусторонняя, уровень значимости: 0.95. 5.2.2 Критерий Хи-квадрат Логика критерия Хи-квадрат в общем такая же, как у биномиального. Если продолжать простые примеры: биномиальный критерий – это про монетку, а Хи-квадрат – про игральный кубик, на котором все числа должны выпадать с вероятностью 1/6. Частота исходов, которые получаются при броске кубика, имеет мультиномиальное распределение, биномиальное – его частный случай. Критерий можно применить к любой категориальной переменной, которая принимает два и более значений: например, наши факультеты Хогвартса – и проверить, соответствует ли распределение участников по факультетам реальному распределению детей в Хогвартсе (на всех факультетах одинаковое количество человек). Единственная проблема: функция chisq.test(), которая для этого предназначена, принимает на вход не исходную переменную с ответами на вопрос. Ей нужно скормить вектор частот каждого факультета (например: c(8,8,9,9), что означает, что в нашей выборке 8 гриффиндорцев, 8 слизеринцев и т.д.). Мы, конечно, можем посчитать эти числа руками и засунуть их в вектор, но, как вы уже возможно догадались, это не наш путь! Чтобы посчитать частоты, можно воспользоваться функцией table() – она делает табличку из всех значений данной переменной и считает количество этих значений. table(df$hogwarts) ## ## Gryffindor Hufflepuff Ravenclaw Slytherin ## 9 6 14 6 Уже можно заметить, что Рейвенкло – более популярный факультет, чем все остальные (чё, самые умные, да?) Кроме того, понадобится вектор теоретических вероятностей каждого исхода (в нашем случае вектор: 4 раза по 0.25, т.к. мы считаем, что все факультеты равновероятны) Тут есть, например, такой способ: буквально “повторить 0.25 4 раза” (rep() – это repeat) rep(0.25, 4) ## [1] 0.25 0.25 0.25 0.25 Ну и теперь попробуем всё это вставить в chisq.test. chisq.test(table(df$hogwarts), p = rep(0.25, 4)) ## ## Chi-squared test for given probabilities ## ## data: table(df$hogwarts) ## X-squared = 4.8857, df = 3, p-value = 0.1804 Внимание! Вставляя ожидаемые вероятности, нужно обязательно ставить перед ними p=, потому что по дефолту chisq.test – это двухвыборочный хи-квадрат, который ждет на вход вектор х и вектор у – две разные выборки по одной переменной. В выдаче, в общем, нет ничего, кроме p-value. Если оно больше 0.05, мы считаем, что да, вероятно наша выборка участников школы взята из генеральной совокупности, где все люди распределены по факультетам равномерно. Ну и для интересующихся формула, которая там используется: \\[ \\chi^2 = \\sum \\frac{(O-E)^2}{E} \\] где O - наблюдаемое число студентов (например, в Гриффиндоре было 9), E - ожидаемое число студентов (размер выборки умножить на 0.25 = \\(35 * 0.25 = 8.75\\)). Подсчитывается для 4 факультетов и суммируется по ним. Получившееся число имеет расперделение хи-квадрат с 3 степенями свободы (число факультетов - 1). p-value - это вероятность, что статистика критерия будет примет более экстремальные значения, чем получившееся: \\(p(\\chi^2 &gt;= 4.88)\\). Вот тут можно поиграться и посмотреть как по значению статистики рассчитывается p-value. МИКРО-ЗАДАЧКА Проверьте, что все цвета глаз встречаются одинаково часто. Микро-подсказка: цветов, как и факультетов 4 (карие, голубые, зеленые, иное). p-value = 0.01739 &lt; 0.05, то есть нулевую гипотезу можно отвергнуть. Правда, по самой выдаче теста мы не сможем узнать, в какую сторону (то есть какой именно цвет глаз преобладает, или какой наоборот встречается редко). Для этого нужно обращаться к таблице частот. Поздравляем, вы теперь знаете, что такое критерии goodness-of-fit 5.3 Тестирование взаимосвязи между двумя категориальными переменными В этом разделе разберём точный тест Фишера и ещё одну разновидность критерия Хи-квадрат. Нам понадобятся: 5.3.1 таблицы сопряжённости Как их получить? Всё та же функция table(), но с двумя переменными. table(df$eye_color, df$hogwarts) ## ## Gryffindor Hufflepuff Ravenclaw Slytherin ## blue 1 0 4 2 ## brown 4 4 5 3 ## green 2 1 5 1 ## other 2 1 0 0 В чём смысл критериев? – В том чтобы проверить, что значения разбросаны по всем ячейкам равномерно. Альтернативная гипотеза: в каких-то ячейках числа экстремально большие или маленькие, и это можно интерпретировать как наличие взаимосвязи между нашими переменными. Так, например, людей с коричневыми глазами на разных факультетах примерно поровну, а вот люди с голубыми почти все попали в Рейвенкло. Здесь мы впервые сталкиваемся с ситуацией, когда число наблюдений имеет значение. Точный тест Фишера применяется, когда ожидаемое количество людей хотя бы в одной ячейке таблицы меньше пяти. Что вообще за ожидаемое количество? Ну, это количество людей в каждой ячейке, если бы переменные были независимы. Считаются эти числа по правилу перемножения вероятностей для независимых событий. По данным мы можем отдельно расчитать вероятность голубых глаз и вероятность Гриффиндора, а потом перемножить их и получить вероятность одновременно голубых глаз и Гриффиндора. Умножим на размер выборки – получим ожидаемое число людей с голубыми глазами в Гриффиндоре. sum(df$eye_color == &#39;blue&#39;)/nrow(df) ## [1] 0.2 sum(df$hogwarts == &#39;Gryffindor&#39;)/nrow(df) ## [1] 0.2571429 sum(df$eye_color == &#39;blue&#39;)/nrow(df) * sum(df$hogwarts == &#39;Gryffindor&#39;)/nrow(df) * nrow(df) ## [1] 1.8 Чтобы узнать ожидаемое количество людей во всех ячейках сразу, а не считать вот это вот 16 раз, можно воспользоваться такой конструкцией: chisq.test(table(df$eye_color, df$hogwarts))$expected ## ## Gryffindor Hufflepuff Ravenclaw Slytherin ## blue 1.8000000 1.2000000 2.8 1.2000000 ## brown 4.1142857 2.7428571 6.4 2.7428571 ## green 2.3142857 1.5428571 3.6 1.5428571 ## other 0.7714286 0.5142857 1.2 0.5142857 Здесь мы просто провели тест хи-квадрат на сопряженность, но не ради результата, а чтобы вытащить из него ожидаемые (expected) значения для таблицы сопряженности. Да, к результатам тестов можно обращаться через знак доллара, как и к датафрейму, чтобы вместо стандартной выдачи получить конкретные числа, которые используются там внутри при расчетах. 5.3.2 Тест Фишера В общем-то, почти во всех ячейках числа меньше пяти, значит тут нам точно нужен критерий Фишера. Руками он считается так, а в R – вот так (просто засовываем в функцию таблицу сопряженности): fisher.test(table(df$eye_color, df$hogwarts)) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: table(df$eye_color, df$hogwarts) ## p-value = 0.5536 ## alternative hypothesis: two.sided Интерпретация: p-value большое, значит нулевая гипотеза не отвергается \\(\\Rightarrow\\) между переменными нет взаимосвязи. Вместо категориальных переменных мы можем вставлять в таблицы сопряженности логические векторы. Давайте посмотрим на совместное распределение людей по выбору горячих напитков и размеру обуви до 39 vs. 40+. table(df$hot_drink, df$shoe_size &gt; 39) ## ## FALSE TRUE ## coffee 4 8 ## shall we dance 6 4 ## tea 8 4 Тут, конечно, нужно держать в голове, что такое TRUE, а что FALSE, это не очень удобно, но уверена, мы справимся. Посмотрим на ожидаемые частоты для этой таблицы, если выбор горячего напитка не связан с размером обуви. chisq.test(table(df$hot_drink, df$shoe_size &gt; 39))$expected ## Warning in chisq.test(table(df$hot_drink, df$shoe_size &gt; 39)): Chi-squared ## approximation may be incorrect ## ## FALSE TRUE ## coffee 6.352941 5.647059 ## shall we dance 5.294118 4.705882 ## tea 6.352941 5.647059 Обратите внимание: R выдал предупреждение, что аппроксимация тестом хи-квадрат может быть неверной. Это как раз потому что у нас тут есть одна ячейка, в которой ожидаемая частота получилась все-таки меньше пяти (в прошлый раз я просто скрыла это предупреждение). Давайте попробуем забить на это и посчитать на этой таблице оба наших критерия. 5.3.3 Добавляем Хи-квадрат Кстати, критерий Хи-квадрат в предыдущем случае назывался “Chi-squared test for given probabilities”, а здесь у нас будет “Pearson’s Chi-squared test”, и в англоязычных источниках иногда встречается просто название Pearson’s test (но чаще chi-squared)). Считается он по той же схеме, что и одновыборочный, вот пример fisher.test(table(df$hot_drink, df$shoe_size &gt; 39)) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: table(df$hot_drink, df$shoe_size &gt; 39) ## p-value = 0.3155 ## alternative hypothesis: two.sided chisq.test(table(df$hot_drink, df$shoe_size &gt; 39)) ## ## Pearson&#39;s Chi-squared test ## ## data: table(df$hot_drink, df$shoe_size &gt; 39) ## X-squared = 2.9593, df = 2, p-value = 0.2277 Можно увидеть, что оба теста выдают большое p-value, и мы не ошиблись бы, выбрав любой из них и сделав вывод что размер обуви больше/меньше 40 не связан с выбором горячего напитка. Однако p-value в хи-квадрате всё же получилось меньше, и если бы ситуация была более спорной, выбрав критерий хи-квадрат, мы могли бы получить достаточно маленькое p-value и, скажем так, найти связь там где её нет – совершить т.н. ошибку первого рода. Ну что ж, и наконец… ЗАДАЧИЩА Для удобства интерпретации создайте переменные very_gorgeous, которая равна “very gorgeous”, если gorgeous равно 10, “not very” в остальных случаях cat_owner, которая равна “cat”, если cats != 0, “no cat” в остальных случаях Подсказка: это можно сделать например так df$very_gorgeous &lt;- ifelse(df$gorgeous == 10, “very gorgeous”, “not very”) (внутри функции на первом месте условие; затем присваемое значение, если условие соблюдено; затем присваемое значение в остальных случаях) Но это далеко не единственный способ, и кажется, вы уже должны знать как минимум один иной; если да, можете вспомнить его. Посмотрите на таблицу сопряженности с ожидаемыми значениями и выберите подходящий тест. Сделайте вывод о взаимосвязи переменных. Затем сравните таблицы ожидаемых и реальных значений и предположите, как можно проинтерпретировать такой вывод. Более правильно выбрать тест Фишера, т.к. есть ячейка с ожидаемым значением меньше пяти. Тест показывает очень маленькое p-value (0.009471), и гипотезу о независимости переменных можно уверенно отвергнуть в пользу альтернативы. В реальных данных, по сравнению с ожидаемыми, можно заметить больше людей, одновременно очень великолепных и имеющих кошку (а также не очень великолепных и не имеющих кошку). Возможно, люди с кошками выше оценивают свою великолепность, или, может быть, великолепные люди чаще заводят кошек :) Поздравляем! Вы познакомились с критериями взаимосвязи между двумя категориальными переменными, в которых используются таблицы сопряженности 5.4 Критерии для порядковых или ненормально распределённых переменных В этом разделе мы разберём сравнение порядковых переменных, которые так же используются для количественных с ненормальным распределением. Для примера рассмотрим переменную великолепности, которая, скорее всего, и то, и другое. Про графики интересно и красиво будет на другой паре, но мы можем нарисовать простенькую гистограмму, чтобы узреть ненормальное распределение: hist(df$gorgeous) Про связь великоплености и любви к кошкам мы уже знаем. Теперь допустим, мы хотим сравнить степень великолепности людей, которые никогда не видели гитару, и людей, которые что-то умеют на ней играть. В этом нам поможет ранговый критерий Манна-Уитни, a.k.a. Mann-Whitney U test a.k.a. Wilcoxon rank-sum test 5.4.1 Тест Манна-Уитни Критерием для выбора этого теста, помимо ненормальности или порядкового типа данных является также маленький размер выборки (конвенционально n&lt;30). В нашей выборке 35 наблюдений, но когда мы разделим её на гитаристов и не-гитаристов, в каждой подвыборке будет меньше 20 человек. Здесь формула и пример расчёта статистики этого теста. Ранговым этот критерий называется потому, что для его расчета значения в выборке расставляются по возрастанию, и потом им выставляются ранги (примерно как порядковые номера, но бывают дробными) В R тест рассчитывается с помощью функции wilcox.test(), в которую надо положить переменную интереса (великолепность) и переменную группировки (умение играть на гитаре; мы создадим её прямо внутри функции, но можно, конечно, сделать новую переменную) Между переменными ставится знак тильда (~), он означает, что мы задаём “формулу” взаимосвязи между нашими двумя переменными. wilcox.test(df$gorgeous ~ df$guitar != &#39;What is a guitar? A giant ukulele?&#39;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: df$gorgeous by df$guitar != &quot;What is a guitar? A giant ukulele?&quot; ## W = 159, p-value = 0.5694 ## alternative hypothesis: true location shift is not equal to 0 К этому моменту вы, думаю, уже на автомате можете сделать вывод из этой выдачи: p-value большое, нулевая гипотеза не отвергается, связи между переменными нет. Другими словами, распределение великолепности гитаристов не “сдвинуто” относительно распределения не-гитаристов. 5.4.2 T-критерий Вилкоксона для зависимых выборок a.k.a. Two-sample paired signed-rank test Что ещё за зависимые выборки? Это выборки парных наблюдений – чаще всего до/после. В них нам важно не то, какая “в среднем” есть разница между выборкой А и выборкой В, а то, какое изменение произошло с каждым наблюдением. Например, динамика анализов пациентов в результате действия лекарства, или результаты одних и тех же учеников в начале и в середине года. При этом здесь мы всё ещё работаем с ненормальными данными и/или маленькими выборками. В наших данных нет никаких парных измерений, но они упорядочены по времени прохождения. Давайте для простоты представим, что первая половина наблюдений это “до”, а вторая половина - “после”. Создадим для этого переменную time. df$time &lt;- &quot;before&quot; df$index &lt;- c(1:35) df$time[df$index&gt;17] &lt;- &quot;after&quot; Здесь я создаю переменную индекса от 1 до 35, и наблюдениям с индексом больше 17 присваиваю значение “after”. Теперь давайте проверим гипотезу, что наши гипотетические люди, проходившие тест “два раза” успели за это время постричься или нарастить волосы (то есть, что между двумя измерениями произошло какое-то изменение длины волос). Используется всё тот же wilcox.test, но с параметром paired = TRUE (Процедура расчёта критерия руками здесь) Можно использовать альтернативную запись: сначала отдельно указывать используемые данные (data=df), а потом прописывать формулу – чтобы не писать лишний раз доллары. wilcox.test(data = df, hair_length ~ time, paired = TRUE) ## Error in wilcox.test.default(x = c(5L, 5L, 21L, 5L, 30L, 25L, 11L, 40L, : &#39;x&#39; and &#39;y&#39; must have the same length Ошибка… Дело в том, что тест-то у нас парный, а наблюдений в “до” и “после” разное количество. Мы присвоили значение “до” семнадцати наблюдениям, а “после” - восемнадцати. Давайте просто выкинем последнее)))) wilcox.test(data = df[1:34,], hair_length ~ time, paired = TRUE) ## ## Wilcoxon signed rank test with continuity correction ## ## data: hair_length by time ## V = 45.5, p-value = 0.2547 ## alternative hypothesis: true location shift is not equal to 0 Итак, p-value большое; распределение длины волос не изменилось за время между “первым” и “вторым” измерениями. Поздравляю! Мы смогли разобраться, что делать для сравнения всяких там ненормальных выборок, и даже неподходящие данные не смогли нам помешать! (На самом деле не надо так…) 5.5 Сравнение средних В этом разделе мы рассмотрим критерий, который используется для сравнения средних в нормально распределённых количественных данных – t-test. Порядковые переменные при нормальности распределения и достаточно большой выборке тоже можно :) Здесь всё будет в общем так же, как и с Вилкоксоном: независимые vs. парные выборки и снова проблемы с данными)))) 5.5.1 t-критерий Стьюдента для независимых выборок Подробно можно почитать здесь. А вкратце этот критерий сравнивает средние арифметические значения в двух выборках. Статистика теста имеет распределение Стьюдента – колокольчик, но чуть более приплюснутый, чем Гаусс. В статистику теста входит разность между двумя выборочными средними, а также учитывается дисперсия каждой выборки. В связи с этим возникает определённая развилка: статистика различается для выборок с одинаковыми и разными дисперсиями. Можно выбрать статистику, предполагающую разность или одинаковость дисперсий, исходя из теории (просто предположить, что обе выборки взяты из одной генеральной совокупности или из разных). Можно, с другой стороны, провести ещё и тест на равенство дисперсий. Допустим, мы хотим сравнить средний рост участников, которые любят колу, с ростом всех остальных. Мы знаем, что это две подвыборки из одной и той же большой выборки, но можем заодно и сравнить дисперсии. Схема записи такая же, как и в большинстве предыдущих тестов: var.test(df$height ~ df$soft_drink == &#39;coke&#39;) ## ## F test to compare two variances ## ## data: df$height by df$soft_drink == &quot;coke&quot; ## F = 0.71214, num df = 15, denom df = 17, p-value = 0.5139 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.2615258 2.0031133 ## sample estimates: ## ratio of variances ## 0.7121431 Интерпретация тоже: p-value велико \\(\\Rightarrow\\) дисперсии не различаются. Теперь к t-тесту! Синтаксис снова тот же. Но добавляем параметр var.equal=TRUE. По дефолту этот параметр включается со значением FALSE. t.test(df$height ~ df$soft_drink == &#39;coke&#39;, var.equal=TRUE) ## ## Two Sample t-test ## ## data: df$height by df$soft_drink == &quot;coke&quot; ## t = -1.7149, df = 32, p-value = 0.09603 ## alternative hypothesis: true difference in means between group FALSE and group TRUE is not equal to 0 ## 95 percent confidence interval: ## -9.3739450 0.8045005 ## sample estimates: ## mean in group FALSE mean in group TRUE ## 168.9375 173.2222 Здесь в выдаче уже достаточно много информации. Во-первых, можно посмотреть на сами средние значения: любители колы в среднем примерно на 4 сантиметра выше))) Однако на наших данных эта разница незначима (p-value &gt; 0.05). Есть также доверительный интервал для разницы средних. Если многократно брать и сравнивать такие же, как у нас тут, подвыборки, разница средних в 95% случаев будет лежать в интервале от -9.3 до 0.8 сантиметров. 5.5.2 t-критерий Стьюдента для зависимых выборок По аналогии с ранговыми критериями можно догадаться, что тут нам опять нужны парные наблюдения. Давайте не будем больше насиловать наши данные и возьмём небольшой пример из интернета. example_data &lt;- read.csv(&#39;https://github.com/Opensourcefordatascience/Data-sets/raw/master/blood_pressure.csv&#39;) str(example_data) ## &#39;data.frame&#39;: 120 obs. of 5 variables: ## $ patient : int 1 2 3 4 5 6 7 8 9 10 ... ## $ sex : chr &quot;Male&quot; &quot;Male&quot; &quot;Male&quot; &quot;Male&quot; ... ## $ agegrp : chr &quot;30-45&quot; &quot;30-45&quot; &quot;30-45&quot; &quot;30-45&quot; ... ## $ bp_before: int 143 163 153 153 146 150 148 153 153 158 ... ## $ bp_after : int 153 170 168 142 141 147 133 141 131 125 ... Это просто какие-то непонятные пациенты, у которых измерено давление до и после какого-то воздействия (наверное, после лечения), для примера подойдёт))) Сам критерий, в отличие от предыдущего, считается по другому алгоритму. Для независимых выборок просто берутся два средних арифметических, а потом их разница сравнивается с нулём. В этом критерии для каждого пациента будет считаться разница между “до” и “после”, а уже потом эти разницы будут усредняться. Мотематика тут Если помните, в прошлый раз мы создали новую переменную “до/после”, а в этих данных измерения “до” и “после” – это две разные переменные. Мы гипотетически можем изменить формат данных на длинный и создать новую переменную, чтобы пользоваться известным нам синтаксисом. Но давайте просто включим данные в функцию по-другому: не через формулу с тильдой, а как две разных переменных x и y. Ну и не забываем параметр paired=TRUE t.test(x=example_data$bp_before, y=example_data$bp_after, paired = TRUE) ## ## Paired t-test ## ## data: example_data$bp_before and example_data$bp_after ## t = 3.3372, df = 119, p-value = 0.00113 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 2.070557 8.112776 ## sample estimates: ## mean of the differences ## 5.091667 Видим, что p-value маленькое, то есть разница между двумя стадиями измерения статистически значима. Сама эта разница у нас получилась положительная. Чтобы правильно это интерпретировать, нужно помнить, что в этом тесте из значений x (то есть “до”) вычитаются значения y. А значит положительная разница означает, что давление “после” у пациентов в среднем стало ниже. А теперь плот-твист! Внимательный читатель мог заметить, что мы не проверили наши непонятные данные из интернета на нормальность, а стоило бы… Вот, например, распределение давления до тритмента. hist(example_data$bp_before) Можно увидеть, что оно вообще-то не очень нормальное, и по-хорошему в этой ситуации стоило бы воспользоваться ранговым критерием. Вернёмся снова к нашим данным. Мы уже израсходовали почти все количественные переменные, но всё-таки осталась одна на ЗАДАЧКУ ЗАДАЧКА Попробуем исследовать связь размера обуви с месяцем рождения. Проверьте, отличается ли размер обуви в подвыборке родившихся весной и летом от размера всех остальных (да, придется немного повозиться с фильтрацией..) Для этого вспомните последние 4 теста (на самом деле, конечно, два из них) и подумайте, какой из них подходит для этой задачи. На что тут можно обратить внимание: во-первых переменная интереса – идельно количественная, и её “природное” распредление, вероятнее всего, нормальное. Однако если посмотреть на гистограммы распределений по подвыборкам, то в осени-зиме распределение может сойти за нормальное, а вот в весне-лете оно похоже то ли на равномерное, то ли на бимодальное. При этом дисперсии на подвыборках значимо не различаются. Поэтому итоговый выбор, на мой взгляд, лежит между Манном-Уитни и t-тестом с равными дисперсиями, и в целом можно использовать их оба, но более безопасный с точки зрения ошибки 1 рода – Манн-Уитни. т-тест показывает значимые различия (размер обуви у родившихся весной и летом больше), а статистика Манна-Уитни практически на границе значимости, чуть больше 0.05. Примите мои поздравления! Вы осилили t-тесты и ощутили тяготы выбора между разными критериями. Впереди последний раздел! 5.6 Коэффициенты корреляции Коэффициенты корреляции используются для изучения взаимосвязи между количественными или порядковыми переменными. Они позволяют оценивать как направление, так и силу этой взаимосвязи. Основных коэффициентов три: Пирсона, Спирмена и Кендалла. Корреляция Пирсона – для количественных переменных, другие два критерия ранговые и подходят для порядковых. 5.6.1 Корреляция Пирсона Это мера линейной связи между двумя количественными переменными. Она принимает значения от -1 до 1, где единица означает идеальную положительную линейную связь, функциональную зависимость между переменными. Формула и пошаговый расчет с объяснением на картинках здесь Обозначается этот критерий буквой R (иногда r) А ещё есть несколько ресурсов, где можно поиграть в игру “угадай корреляцию по картинке”, и это забавно. Например, вот Вообще, разные корреляции выглядят примерно так: Рассчитаем корреляцию Пирсона на примере роста и размера обуви. Для этого используется функция cor(), которая предназначена для всех трёх методов, а Пирсон в ней дефолтный. Есть нюанс: она ломается на пропущенных значениях, а чтобы игнорировать их, в ней есть аргумент use = \"complete.obs\" cor(df$height, df$shoe_size, use=&quot;complete.obs&quot;) ## [1] 0.798224 Для корреляций есть конвенциональные значения силы, причем, классификации встречаются разные. Мы возьмём такую: 00-.19 – очень слабая .20-.39 – слабая .40-.59 – средняя .60-.79 – сильная .80-1.0 – очень сильная Наша корреляция роста с размером обуви на границе между сильной и очень сильной, что, в общем, логично :) Можем ещё проверить значимость коэффициента корреляции. Для этой функции не нужно бороться с NA, оно само. cor.test(df$height, df$shoe_size) ## ## Pearson&#39;s product-moment correlation ## ## data: df$height and df$shoe_size ## t = 7.4962, df = 32, p-value = 1.557e-08 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.6301581 0.8948430 ## sample estimates: ## cor ## 0.798224 Нулевая гипотеза: коэффициент корреляции равен нулю. Для проверки используется знакомая т-статистика. p-value здесь у нас очень мало, корреляция значимая (неудивительно). В этой выдаче тоже приводится само значение коэффициента, так что функцией cor() вообще можно особо не пользоваться :) Можем также визуализировать это дело (не вдавайтесь в этот код, про ggplot расскажет лучше кто-то, кто не я)): # install.packages(&quot;ggplot2&quot;) library(ggplot2) ggplot(data=df,aes(y=height,x=shoe_size)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se=FALSE) Ну и напоследок подборка бредовых корреляций, чтобы никогда не забывать, что даже самые сильные и значимые корреляции бывают случайными :) 5.6.2 Ранговые коэффициенты: Спирман и Кендалл Эти два чувака нужны, когда хотя бы одна из переменных не количественная, а порядковая. Преимущество этих коэффициентов в том, что они схватывают и нелинейные взаимосвязи: Главное, чтобы возрастание/убывание были монотонными. Как выбирать между ними, честно говоря, мне не очень ясно. Я, пожалуй, не буду рекомендовать ничего конкретного, лучше при желании почитать внимательно и подробно. Единственное, насколько я понимаю, Кендалл лучше работает, когда в переменных много повторяющихся значений. Давайте посмотрим на корреляцию великолепности с количеством братьев и сестёр (обоими способами). Использовать будем известный нам cor.test(), только пропишем внутри него методы. Для начала Спирмана. cor.test(df$gorgeous, df$siblings, method = &#39;spearman&#39;) ## Warning in cor.test.default(df$gorgeous, df$siblings, method = &quot;spearman&quot;): ## Cannot compute exact p-value with ties ## ## Spearman&#39;s rank correlation rho ## ## data: df$gorgeous and df$siblings ## S = 6658.3, p-value = 0.7002 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## 0.06746409 Тест выдал предупреждение, что p-value не может быть рассчитано точно из-за “ties” – это как раз те самые посторяющиеся значения, которых крайне много в переменной “siblings”, да и в переменной “gorgeous” тоже немало. Что касается интерпретации, сама корреляция крайне слабая и статистически не отличается от нуля (незначима). Совсем даже не задачка Самостоятельно прогоните на тех же переменных Кендалла (kendall), сравните выводы Ну вот, оказывается Кендалл выдаёт то же самое предупреждение про ties… При этом коэффициент оказался ещё чуть меньше, а p-value почти такое же. Что тут еще сказать, не знаю :) 5.7 Бонус: визуализация корреляционной матрицы Когда нужно (или просто почему-то очень хочется) одновременно посмотреть на корреляцию всего со всем, можно создать корреляционную матрицу и визуализировать её. Для этого удобно использовать пакет corrplot, хотя этот способ не единственный. Его нужно будет установить и подключить. #install.packages(&quot;corrplot&quot;) library(corrplot) Чтобы всё работало, нужно отобрать только числовые переменные. У нас это рост, размер обуви, длина волос, число родственников, количество глаз и степень великолепности. df_cor &lt;- df[ , c(&quot;height&quot;, &quot;shoe_size&quot;,&quot;hair_length&quot;,&quot;siblings&quot;,&quot;eye_number&quot;,&quot;gorgeous&quot;)] Чтобы создать матрицу корреляций, нужно этот новый датасет засунуть в cor (помним про complete.obs) M&lt;-cor(df_cor, use=&quot;complete.obs&quot;) head(round(M,2)) ## height shoe_size hair_length siblings eye_number gorgeous ## height 1.00 0.80 -0.43 -0.09 -0.11 -0.15 ## shoe_size 0.80 1.00 -0.53 -0.03 -0.06 -0.37 ## hair_length -0.43 -0.53 1.00 0.15 -0.12 0.22 ## siblings -0.09 -0.03 0.15 1.00 0.53 0.08 ## eye_number -0.11 -0.06 -0.12 0.53 1.00 -0.05 ## gorgeous -0.15 -0.37 0.22 0.08 -0.05 1.00 А эту матрицу, в свою очередь, можно уже засунуть в функцию для рисования картинок – corrplot(). У неё есть аргумент method, отвечающий за то, что отображается в ячейках – разноцветные кружочки/квадратики/числа и т.д. Вот, например, два варианта: corrplot(M, method=&quot;color&quot;) corrplot(M, method=&quot;number&quot;) Основная идея такая: сила связи отображается степенью прозрачности, направление – цветом. Справа, как вы видите, легенда. Есть масса способов это дело кастомизировать: поменять цвета, фон, сделать картинку диагональной (убрать повторяющиеся ячейки), настроить шрифты, поменять местами переменные etc. При этом помним, что для создания матрицы корреляций мы использовали функцию cor с дефолтным методом – Пирсоном, и не для всех наших переменных это хорошо. Финал! Поздравляю! И корреляции мы теперь тоже победили Но есть еще кое-что: Задачка “сделай сам” (скорее всего, на дом)) Подумайте, как исследовать взаимосвязь между такими парами переменных: великолепность и размер обуви число родственников и число глаз число котиков и детская мечта любимый горячий напиток и длина волос Помните, что не обязательно мириться с плохим распределением какой-то переменной – можно сделать его еще хуже! (В смысле, стоит подумать о том, чтобы какие-то переменные использовать в изменённом виде: группировать категории, дробить числовые переменные на группы и делать из них порядковые и т.д.) Здесь могла быть ваша реклама Спасибо за вашу работу! Увидимся ещё! "],["визуализация-данных-с-ggplot2.html", "6 Визуализация данных с ggplot2 6.1 Визуализация это зачем? 6.2 Философия A Layered Grammar of Graphics 6.3 Экшон 6.4 Файнал босс 6.5 Конклюжон", " 6 Визуализация данных с ggplot2 6.1 Визуализация это зачем? Вопрос не праздный, ибо что мы зря 100500 видов описательных статистик считали? Однако всё не так просто. Рассмотрим пример. У нас есть датасет Квартет Анскомба1, который выглядит так (первые десять строк): id dataset x y 1 1 10 8.04 1 2 10 9.14 1 3 10 7.46 1 4 8 6.58 2 1 8 6.95 2 2 8 8.14 2 3 8 6.77 2 4 8 5.76 3 1 13 7.58 3 2 13 8.74 Если мы посчитаем описательные статистики в каждом субдатасете, то получим следующее: dataset mean_x mean_y sd_x sd_y cor n_obs 1 9 7.5 3.32 2.03 0.82 11 2 9 7.5 3.32 2.03 0.82 11 3 9 7.5 3.32 2.03 0.82 11 4 9 7.5 3.32 2.03 0.82 11 Ребят, тут всё идентично! Однако давайте нарисуем: Што? Мы обнаружили в явном виде, что несмотря на идентичные значения описательных статистик, паттерны в данных могут быть различны. Чтобы впечатлиться окончательно, посмотрим на Datasaurus2: dataset mean_x mean_y sd_x sd_y cor n_obs away 54.3 47.8 16.8 26.9 -0.1 142 bullseye 54.3 47.8 16.8 26.9 -0.1 142 circle 54.3 47.8 16.8 26.9 -0.1 142 dino 54.3 47.8 16.8 26.9 -0.1 142 dots 54.3 47.8 16.8 26.9 -0.1 142 h_lines 54.3 47.8 16.8 26.9 -0.1 142 high_lines 54.3 47.8 16.8 26.9 -0.1 142 slant_down 54.3 47.8 16.8 26.9 -0.1 142 slant_up 54.3 47.8 16.8 26.9 -0.1 142 star 54.3 47.8 16.8 26.9 -0.1 142 v_lines 54.3 47.8 16.8 26.9 -0.1 142 wide_lines 54.3 47.8 16.8 26.9 -0.1 142 x_shape 54.3 47.8 16.8 26.9 -0.1 142 К чему это всё? К тому, что визуализация данных является жизненно необходимым этапом разведочного анализа. Она позволяет вам глубже и детальнее понять, что происходит в данных, и как это происходящее может отразиться на дальнейшем анализе. 6.2 Философия A Layered Grammar of Graphics Идея, воплолщенная в одном из мощнейших пакетов для визуализации ggplot2, восходит к работе L. Wilkinson «The Grammar of Graphics». Базируясь на идеях, изложенных в этой работе, Hadley Wickham разработал концепцию Layered Grammar of Graphics и создал пакет для визуализации, ради которого мы все здесь собрались. Автором по этому пакету написана целая книга, но мы сосредоточимся на основных смысловых и ключевых моментах, которые необходимы, чтобы сделать что-то крутое. Часто возникает вопрос: почему 2? Ответ примерно такой: был и первый ggplot, но попытка не задалась от слова совсем, и пришлось все переделать. По своей сути график представляет собой сложную аппликацию из нескольких слоев. На каждом слое располагаются сходные по содержанию элементы. Начиная с самого первого — базового — и постепенно добавляя слой за слоем необходимые элементы, можно создавать сложные визуализации для отображения интересных закономерностей в данных. После создания базового графика осуществляется настройка отдельных элементов по необходимости и в зависимости от требований издательства / преподавателя / научника / комиссии и т.д. И поскольку все элементы в определенной степени изолированы друг от друга, это открывает большие возможности кастомизации. Кроме того, чтобы оформить график в соответствии с конкретными требованиями, нет необходимости перерисовывать его целиком, так как содержательная часть графика независима от настроек внешнего облика. Все, что вам нужно — это добавить/удалить пару строк кода. Но — хватит слов! Поехали уже рисовать уже! 6.3 Экшон 6.3.1 Пакеты Для рисования нам понадобится пакет ggplot2. Если вы ранее его никогда не устанавливали, то воспользуйтесь такой командой: install.packages(&quot;ggplot2&quot;) Проверить, установлен пакет или нет, можно так: &quot;ggplot2&quot; %in% installed.packages() ## [1] TRUE После установки пакета его необходимо подключить к текущей сессии, чтобы мы могли пользоваться функциями, которые в нём лежат: library(ggplot2) 6.3.2 Данные Чтобы не ворочаться с загрузкой данных, воспользуемся для освоения мощностей ггплота встроенным в него датасетом diamonds: head(diamonds) Описание датасета примерно такое: Variable Description Values price price in US dollars $326-$18,823 carat weight of the diamond 0.2-5.01 cut quality of the cut Fair, Good, Very Good, Premium, Ideal color diamond color J (worst) to D (best) clarity measurement of how clear the diamond is I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best) x length in mm 0-10.74 y width in mm 0-58.9 z depth in mm 0-31.8 depth total depth percentage 43-79 table width of top of diamond relative to widest point 43-95 Но этот датасет очень большой — 53k наблюдений. Нам для освоения возможностей визуализации пока этого многовато. Давайте сделает случайную подвыборку из 1000 наблюдений: set.seed(34) diamonds1000 &lt;- diamonds %&gt;% slice(sample(1:nrow(diamonds), 1000, replace = FALSE)) 6.3.3 Строим базовый график 6.3.3.1 Базовый слой Первое, что мы делаем, когда собираемся что-либо рисовать — берем холст. Аналогично, когда мы собираем рисовать график с использованием ggplot2, первое, что мы делаем — говорим «Дай мне холст!». На языке ggplot2 это делается с помощью команды ggplot(). ggplot() И, о Боже, ggplot2 дал нам холст! Иначе говоря, мы построили базовый слой, на который в дальнейшем будем набрасывать элементы нашего графика. Следующее, что необходимо сделать — указать данные, на основе которых мы будем строить наш график. Это делается к помощью аргумента data: ggplot(data = diamonds1000) Вроде бы ничего не изменилось, да и собственно, не должно было, ведь мы никак не указали, что мы хотим отобразить. Давайте укажем. 6.3.3.2 Разметка осей и переменные. Эстетики Важнейшие элементы любого графика — это оси. Мы строим двумерные графики, поэтому и оси у нас две — как учили в школе, x (горизонтальная ось, ось абсцисс) и y (вертикальная ось, ось ординат). Чтобы задать оси графика потребуется отдельная функция. Она называется aes(), и в общем задает эстетики графика. Итак, конкретнее об эстетиках. Иначе говоря, это то форматирование, которое связано с данными. Или еще один способ понимания — способы отображения переменных из датасета. У функции aes() есть ряд параметров, они тоже называются эстетики. Вот список эстетик, которые используются чаще всего: x y color fill shape size linetype Несложно догадаться, что переменные по осям задаются параметрами x и y. Что ж, зададим. Давайте визуализируем связь между весом и ценой бриллианта: ggplot(data = diamonds1000, aes(x = carat, y = price)) Так, ну, допустим… Оси разметились. А где картинка? Картинки нет, но ggplot2 честно отработал свою работу. Мы задали только оси — и он нам разметил их в соответствии с имеющимися в векторах значениях. Больше мы ему ничего не написали. Чтобы всё-таки получить картинку, необходимо указать, как мы хотим отборазить наши переменные. 6.3.3.3 Геомы За то, каким образом будут отображены переменными, а конкретно, какими «геометрическими объектами», отвечает семейство функций geom_*. Когда мы переходим к этой функции, мы ступаем на новый слой. Чтобы это обозначить используется «плюсик» (+). ggplot(data = diamonds1000, aes(x = carat, y = price)) + geom_point() Мы выбрали точки для отображения наблюдений, потому что наиболее наглядный вариант отобразить зависимость между двумя переменными. Такой тип графика называется scatterplot, или диаграмма рассеяния. Но, вообще-то, можно и получше отобразить закономерность. Как минимум, добавить линию тренда в помощью специального геома: ggplot(data = diamonds1000, aes(x = carat, y = price)) + geom_point() + geom_smooth() ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; Как видите, при добавлении нового «геометрического» способа отображения данных мы добавляем новый слой. geom_smooth() подразумевает «сглаживание», оно может происходить с помощью разных методов (используемый метод нам написали в консоль). Мы можем эскплицитно указать метод, который хотим использовать. Например, линейную регрессию: ggplot(data = diamonds1000, aes(x = carat, y = price)) + geom_point() + geom_smooth(method = &#39;lm&#39;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Задание Используя тот же датасет diamonds1000, визуализируйте связь между длиной и шириной бриллиантов. Референс В случае, если нас интересует распределение нашей переменной, мы можем использовать geom_histogram() или geom_density(): ggplot(data = diamonds1000, aes(x = price)) + geom_density() Кстати, аргументы функции можно передавать и без указания их имён — R будет ориентироваться по их порядку: ggplot(diamonds1000, aes(price)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. При рисовании гистограммы для обнаружения деталей в распределении можно задать ширину столбика — например, сделать её более мелкой: ggplot(diamonds1000, aes(price)) + geom_histogram(binwidth = 100) Для отображения распределений мы также можем использовать боксплот — это отдельный геом: ggplot(diamonds1000, aes(y = price)) + geom_boxplot() Чуть позже мы столкнемся ещё c некоторыми геомами, но вот вам сразу список самых полезных для старта: geom_histogram() geom_density() geom_boxplot() geom_point() geom_errorbar() geom_pointrage() geom_line() geom_vline() geom_hline() geom_smooth() Вопрос График плотности вероятности, гистограмма и боксплот — все три визуализации отображают распределение. Для чего каждая из них может быть полезна? В помощь картинка ниже. Задание Визуализируйте распределение веса бриллиантов (переменная carat). Выберите один из возможных способов визуализации распределения. Можете визуализировать несколькими способами и сравните результаты. 6.3.4 Ищем более сложные закономерности Пока что мы работали только с одной-двумя переменными, однако на практике нас могут интересовать более сложные взаимосвязи. Например, в случае с бриллиантами распределение цены по всему датасету даёт нам весьма мало информации, поскольку есть много факторов, которые на неё могут влиять — размер бриллианта, качество огранки и др. Пропробуем их отобразить. 6.3.4.1 Группировка по переменной Один из вариантов того, что мы можем сделать, это сгруппировать наши наблюдения по какой-либо из переменных. Как группировка будет выражена в коде сильно зависит от типа визуализации. Разберем на двух примерах. Выше мы рисовали вот такой боксплот, который отображает распределение цены: ggplot(diamonds1000, aes(y = price)) + geom_boxplot() Однако вполне ожидаемо, что цена может быть по-разному распределена в зависимости от качества огранки. В нашем датасете есть переменна cut, и нам было бы хорошо отобразить её на графике. Так как боксплоты требуют по оси x категориальную переменную, то сделать это достаточно просто: ggplot(diamonds1000, aes(x = cut, y = price)) + geom_boxplot() Вот мы уже видим много чего: в группах Good и Premium распределение симметричное, а во всех остальных скошенное. Также мы наблюдаем, что чем выше качество огранки, тем больше выбросов в группе. Если мы визуализируем распределение в помошью, например, графика плотности вероятности, то задание группировки в помощью эстетики x нам не подойдёт: она уже занята нашей переменной price. Эстетика y в этой визуализации рассчитывается автоматически, поэтому её мы тоже не можем использовать — да и как мы по не вообще смогли бы задать группировку? Значит нам необходимо использовать какую-то другую эстетику. Пусть это будет fill: ggplot(diamonds1000, aes(x = price, fill = cut)) + geom_density() Обратите внимание, что теперь у нас справа появилась легенда, которая позволяет понять, что отображено тем или иным цветом. Однако пока визуализация не очень хороша, так как распределения перекрывают друг друга. Чтобы это поправить, нужно задать позрачность с помощью аргумента alpha в функции geom_density(): ggplot(diamonds1000, aes(x = price, fill = cut)) + geom_density(alpha = .5) Теперь мы видим все распределения на одном графике. Классно? Классно! Задание В нашем датасете есть переменная depth, которая обозначает total depth percentage3. Каково распределение этой величины у бриллиантов разного цвета (переменная color)? 6.3.4.2 Больше переменных Это всё, конечно, хорошо, но мы пока что не вышли за пределы двух переменных на одном графике. Вспомним нашу диаграмму рассенияния «Вес — Цена»: ggplot(data = diamonds1000, aes(x = carat, y = price)) + geom_point() Уберём линию тренда, она нам будет мешать. Как бы нам сделать так, чтобы на этот график добавить переменную depth? Вопрос Вернитесь к списку эстетик. x и y у нас заняты. Предложите, какую эстетику мы могли бы использовать для отображения переменной depth? Возможно несколько вариантов — я предлагаю использовать size: ggplot(data = diamonds1000, aes(x = carat, y = price, size = depth)) + geom_point() В целом, получилось неплохо, но сейчас на графике происходит небольшой флекс. Надо немножко поправить, чтобы происходил чилл. Точки и раньше накладывались друг на друга, однако теперь в силу того, что размер точки для нас информативен, наложение стало критично. С наложением элементов друг на друга мы боролись чуть выше. Можем попробовать аналогичный способ: ggplot(data = diamonds1000, aes(x = carat, y = price, size = depth)) + geom_point(alpha = .3) Получилась пузырькая диаграмма. Ну, неплохо. Задание Выше мы рисовали диаграмму рассеяния, которая отображала связь между длиной (x) и шириной (y) бриллианта. Возьмите за основу получившийся график и превратите его в пузырьковую диаграмму, которая будет отображать связь между (x), шириной (y) и глубиной (z) бриллианта. Референс На фоне успешной работы с прозрачностью элементов мы словили состояние потока, и хотим добавить ещё переменных! Круто было бы отобразить, как зависит цена от carat и depth у бриллиантов различного качества огранки. Переменную cut мы уже отображали — здесь использованный подход тоже сработает: ggplot(data = diamonds1000, aes(x = carat, y = price, size = depth, color = cut)) + geom_point(alpha = .3) Ммм, красота! 6.3.5 Важное замечание о визуализации Вопрос Как определить, что визуализация хороша? Можно придумать огромное количество критериев. На мой взгляд, критические параметры таковы: Честность график отображает то, что реально поисходит в данных Читаемость выбран корретных способ визуализации график удобно рассматривать и понимать, что происходит Дизайн подобрана корректная палитра, все цвета хорошо видны и отличимы друг от друга подобраны адекватные шрифты Качество картинки график хорошего разрешения Прочекаем наш график по этим параметрам: Честность — ОК мы работаем с теми данными, котрые у нас есть и не модифицируем их в угоду каким-либо нашим целям; да, мы сейчас работаем на части датасета, но делаем это исключительно в учебных целях Читаемость — нутакое способ визуализации мы выбрали корректный — пузырькая диаграмма, которая у нас получилась, вполне подходит для отображения интересующих нас закономерностей но понимать, что происходит в левом нижнем углу сложновато Дизайн — приемлемо хотя есть некоторые вопросы к используемой стандартеной палитре, на данном этапе это окей, кастомизировать график мы научимся далее Качество картинки — приемлемо пока что мы может не задумываться об этом, так как не выгружаем график в файл для публикации или отчёта, однако надо будет не забывать об этом позднее Итого, у нас хромает крайне существенный парамет — читаемость. Когда мы строим визуализацию, мы должны четко понимать, зачем мы это делаем, и в конечном итоге мы рисуем картинки для нашего читателя. Нам важно позабиться о том, чтобы нашу визуализацию было удобно читать и понимать тому, кто с ней сталкивается впервые — то есть сделать её максимально понятной. Давайте поработаем на этим. Вопрос Как можно изменить график, чтобы он был более читаемым и лучше отображал интересующие нас закономерности? 6.3.5.1 Фасетирование Один из способов сделать визуализацию понятнее — использовать фасетирование. Оно позволяет разбить график на несколько субграфиков по некоторой категориальной переменной. Таким образом, на каждом субграфике окажется меньше данных, поэтому каждый из них будет проще читать. Вместе с тем все субграфики будут располагаться рядом друг с другом, поэтому их будет удобно сравнивать. Для фасетирования существует два варианта: facet_grid() и facet_wrap(). Первый удобен, когда у вас две (и более) группирующий переменных, второй — когда такая переменная одна. У нас сейчас группировка по одной переменной cut, поэтому мы будем использовать второй вариант: ggplot(data = diamonds1000, aes(x = carat, y = price, size = depth, color = cut)) + geom_point(alpha = .3) + facet_wrap(~ cut) Отлично, наши наблюдения зазбилить по субграфикам и в целом визуализация стала чуть более читаемой. Хотя, конечно, большие скопления точек слева внизу всё равно остались4. Внимательно посмотрим на получившийся график: переменная cut у нас отображена двумя разными способами — цветом и фасетированием. Это не оч. хор. — возникла избыточность. Когда читатель будет смотреть на этот график, он озадачится, так как, скорее всего, будет ожидать, что каждая переменная отбражена единственным способом. Пока он разберется, что цвет не несет дополнительной информации, он будет тратить время — это нехорошо. Поэтому цвет надо либо убрать вовсе — и это лучший вариант, либо как минимум скрыть цветовую легенду. ggplot(data = diamonds1000, aes(x = carat, y = price, size = depth)) + geom_point(alpha = .3) + facet_wrap(~ cut) Вот так хорошо — дублирования информации теперь нет. Задание Я тут в сносках упоминал, что нам стоило бы внимательнее посмотреть на распределение переменной price. Давайте это сделаем! Визуализируйте распределение этой переменной в зависимости от качества огранки (cut) и цвета (color). Властью данной мне мною налагаю запрет на использование эстетик (кроме обязательной — x)! Подсказка facet_grid Вариант референса Сложное задание Часто нам бывает полезно знать, как расположено распределение по какой-либо группе наблюдений в контексте всего распредления переменной. Доработайте предыдущий график так, чтобы на каждом субграфике распределение цены в каждом из сочетаний условий color x cut лежало поверх распределения всей переменной price. Это должно выглядеть так: diamonds1000 %&gt;% ggplot(aes(price)) + geom_histogram(data = diamonds1000 %&gt;% select(-cut, -color))+ geom_histogram(fill = &quot;white&quot;) + facet_grid(cut ~ color) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Серые гистограммы — распределение по всей переменной price, белые (маленькие внизу) — распределения цены в каждом из сочетаний условий color x cut. 6.3.6 Инструменты встроенной статистической обработки Досих пор мы отображали «сырые данные» — то есть то, что непосредственно есть в данных. Однако часто бывает так, что мы хотим отобразить какие-то посчитанные статистики, или аггрегированные данные. Поэтому необходимо сначала предобработать данные, получить необходимые значения и затем на их основе построить график. Но зачем? Если можно сразу в коде построения графика рассчитать все, что нам нужно! В ggplot2 уже встроены инструменты простейшей статистический обработки! Еще раз посмотрим на датасет. У нас есть переменная price, а также категории качества огранки cut. Наверняка, средняя цена будет различаться в этих категориях. Давайте это проверим! Но сначала нам необходимо познакомиться с новым семейством функций stat_*. 6.3.6.1 Статы Статы и есть те самые встроенные инструенты статистической обработки. Они позволяют прямо в коде графика обсчитать данные и сразу же визуализировать результаты. На самом деле, мы уже сталкивались со встроенными инструментами статистической обработки, ведь что делает geom_smooth(method = 'lm')? Не что иное, как визуализирует линейную регрессию, построенную на выбранных данных! Наиболее популярная функция из рассматриваемого семейста — stat_summary(). С помощью неё мы и будем визуализировать наши средние. Обратите внимание, что теперь мы будем работать с полным датасетом diamonds! Приступим к построению графика. Начнём с базового слоя: ggplot(diamonds, aes(cut, price)) # напоминаю, что аргументы функции можно передавать просто по порядку, не указывая имя самого аргумента Взяли холст, расчертили. По оси x у нас будет идти группирующая переменная. Теперь добавим средние. Как и полагается, на новый слой. ggplot(diamonds, aes(cut, price)) + stat_summary(fun = mean, geom = &#39;point&#39;) Разберемся, что тут написано. Первый аргумент (fun) принимает функцию, результат которой будет отложен по оси y. В нашем случае это среднее (mean). Она будет применена к переменой price, причем наблюдения будут автоматически сгруппированы по интересующим нас группам (cut). Второй аргумент — это уже знакомый нам geom, которые отвечает за то, как «геометрически» будут отрисованы знаечния на графике. Наш выбор — точки. Как результат мы наблюдаем то, что хотели. Однако как мы знаем из статистики, чтобы определить, есть ли различия между группами, нам недостаточно только средних значений — необходимы доверительные интервалы. Что ж, отобразим и их. Добавим новый слой с помощью всё той же функции stat_summary(), но на этот раз она будет выглядеть немного по-другому: ggplot(diamonds, aes(cut, price)) + stat_summary(fun = mean, geom = &#39;point&#39;) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;) Как мы видим, немного изменился первый аргумент. Это связано с изменением геома. Для отображения доверительных интервалов нам нужен геом errorbar, который требует не одно значение, а два — верхнюю и нижнюю границу доверительного интервала. То есть fun.data принимает как аргумент мини-датафрейм — как раз в таком формате и возвращается результат функции mean_cl_boot. Можно посмотреть на её работу отдельно: mean_cl_boot(diamonds$price) Собственно, вот он датафрейм из одной строки. Здесь три значения, но errorbar игронирует первое (само среднее значение) и использует только второе и третье, строя по ним «усы». Задание С ценой разобрались. Теперь давайте сравним вес бриллиантов в разных группах. Визуализируйте средние значения веса бриллиантов (carat) в группах по степени чистоты (clarity). Не забудьте про доверительные интервалы! Однако мы продолжваем гнаться за сложными закономерностями, поэтому добавим ещё одну группирующую переменную. В наших данных есть переменная color, которая задаёт «цвет» бриллианта. Наверное, он тоже может влиять на цену камня. ggplot(diamonds, aes(cut, price, color = color)) + # не путайтесь: первый color --- название аргумента, второй --- имя переменной) stat_summary(fun = mean, geom = &#39;point&#39;) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;) Ёжкины коты, красота-то какая! Только надо как-то это в божеский вид привести… 6.3.7 Настраиваем график ggplot2 имеет широчайшие возможности кастомизации, в нем можно настроить чуть более, чем всё. Сейчас наш график выглядит хотя и содержательно верно, но с точки зрения дизайна (да и общей адекватности) — совершенно дико. Давайте подправим. Первое, что бросается в глаза — точки и «усы» лежат друг на друге, что очень нехорошо и так не надо: крайне трудно понять, что происходит на графике. Давайте их расположим рядом друг с другом, чтобы оставалось видно, что средние сгрупированы по делениям оси x. Это делается с помощью функции position_dodge(), которая создает объект задающий позицию точек. Результат её работы необходимо передать в аргумент position конкретного стата, но так как у нас статов несколько, прописывать 100500 раз одно и то же — неразумно. К тому же, если мы захотим как-то поменять расположение точек (сблизить, раздвинуть сильнее), нам надо будет переписывать каждую строку — всё ещё неразумно. Поэтому мы сделаем отдельный объект, в который рапишем результат работы функции: pd &lt;- position_dodge(0.5) # передаем какое-то число из диапазона [0, 1] И далее будем использовать этот объект: ggplot(diamonds, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd) Ну, вот стало уже поприличней. Второе, что бросается в глаза — слишком широкие errorbar’ы (они касаются усов соседних точек). Значит, надо уменьшить ширину. За их ширину отвечает параметр width. Ширина задается долями единицы. ggplot(diamonds, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) Вот так вроде хорошо, хвосты errorbar’ов ни с чем не пересекаются. Что ты еще хотелось подправить? Наверное, сделать акцент на главных смысловых элементах графика. В нашем случае это точки. Давайте сделаем их побольше. ggplot(diamonds, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) Вот теперь кайф! 6.3.7.1 Темы Но не совсем. Фон какой-то не очень… Дефолтная серая тема в какое-то давнее время была популярна, все выдели что ты крутой и умеешь в ггплот и ваще. Однако со временем это стало #немодно, и лучше серой темы избегать, да и требования журналов обычно более строгие. В ggplot2 есть ряд встроенных тем, которые задаются через функции семейства theme_*(). Наиболее популярные theme_classic() и theme_bw(). Последнюю мы и будем использовать. ggplot(diamonds, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() Ах, красота! Задание Возьмите график из последнего задания. Модифицируйте код так, чтобы он отображал средние значения веса блиллиантов (с доверительными интервалами) для групп бриллиантов по переменным clarity x cut. Можете использовать любые эстетики. Настройте график, так, чтобы он был читаем. За референс возьмите визуализацию выше. Поправьте положение точек и эррорбаров, ширину «усов», измените стандартную тему на любую другую. 6.3.7.2 Кастомизация шкал Мы задали отображение групп цвета бриллиантов цветом5, но дефолтная шкала не совсем хороша, как минимум потому, что в ней есть жёлтый, который на нашем белом фоне будет смотреться не очень. Надо бы это поправить. Для того, чтобы кастомизировать используемые шкалы, есть ряд функций семейства scale_*(). Мы познакомимся с некоторыми из них. Для начала изменим цвета. В R можно задавать цвета через названия или HEX кодировку. Будем использовать названия. ggplot(diamonds, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() + scale_color_manual(values = c(&#39;brown4&#39;, &#39;chocolate4&#39;, &#39;darkgoldenrod4&#39;, &#39;darkolivegreen&#39;, &#39;darkslategray&#39;, &#39;darkslateblue&#39;, &#39;deeppink4&#39;)) Здесь мы используем функцию scale_color_manual(), чтобы задать значения цвета вручную. Используя обязательный аргумент values мы передаем вектор названий цветов, которые хотим использовать. Не то чтобы идеал, но и мы не дизайнеры. Так-то есть готовые палитры, и чё мы тут заморачивались подбирая цвета — не оч понятно: ggplot(diamonds, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() + scale_color_manual(values = colorspace::rainbow_hcl(length(unique(diamonds$color)))) 6.3.7.3 Последние штрихи Но настройка графика на этом не закончена. Раз уж мы в России, то надо и подписи по-русски задать. Для этого также есть отдельная функция. Она называется labs(). Зададим названия осей: ggplot(diamonds1000, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() + scale_color_manual(values = colorspace::rainbow_hcl(length(unique(diamonds$color)))) + labs(x = &quot;Качество огранки&quot;, y = &quot;Цена&quot;) Теперь было бы хорошо добавить название, а то как-то непонятно, что тут вообще нарисовано. Используем аргументы title и subtitle функции labs(). ggplot(diamonds1000, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() + scale_color_manual(values = colorspace::rainbow_hcl(length(unique(diamonds$color)))) + labs(x = &quot;Качество огранки&quot;, y = &quot;Цена&quot;, color = &quot;Цвет бриллианта&quot;, title = &quot;Зависимость цены бриллианта от его характеристик&quot;, subtitle = &quot;Цвет и качество огранки&quot;) Почти идеально! Но осталось пара моментов. Во-первых, непонятно, какая метрика отображена с помощью «усов», а во-вторых, легенда занимает много места. У labs() есть ещё один аргумент — caption, иначе говоря «подпись». В ней и можно указать метрику. ggplot(diamonds1000, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() + scale_color_manual(values = colorspace::rainbow_hcl(length(unique(diamonds$color)))) + labs(x = &quot;Качество огранки&quot;, y = &quot;Цена&quot;, color = &quot;Цвет бриллианта&quot;, title = &quot;Зависимость цены бриллианта от его характеристик&quot;, subtitle = &quot;Цвет и качество огранки&quot;, caption = &quot;отображён 95%-доверительный интервал&quot;) Осталось подвинуть легенду, например, вниз. Вообще положение легенды определяется темой, и мы её уже задали. Однако можно подправить дефолтные параметры с помощью функции theme(). ggplot(diamonds1000, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() + scale_color_manual(values = colorspace::rainbow_hcl(length(unique(diamonds$color)))) + labs(x = &quot;Качество огранки&quot;, y = &quot;Цена&quot;, color = &quot;Цвет бриллианта&quot;, title = &quot;Зависимость цены бриллианта от его характеристик&quot;, subtitle = &quot;Цвет и качество огранки&quot;, caption = &quot;отображён 95%-доверительный интервал&quot;) + theme(legend.position = &#39;bottom&#39;) 6.3.8 Сохранение графиков Для того, чтобы опубликовать график в статье или даже просто вставить в презентацию нужно его как-то выгрузить. Скриншоты нам не подходят, потому что качество их совершенно никуда не годится. На наше счастье есть фукнция для выгрузки картинок из R и называется она ggsave(). Она принимает следующие аргументы: filename — название файла, в которых будет сохранен график path — путь, куда сохранять нашу картинку. plot — график, который необходимо сохранить (по умолчанию, последний построенный) scale — степень масштабирования изображения width — ширина изображения height — высота изображения units — единицы изменения (дюймы, миллиметры, сантиметры) dpi — разрешение изображения (точки на дюйм, стандарт для печати — 300) Функция позволяет сохранить изображения большинства форматов (JPEG, PNG, SVG, TIFF, PDF). ggsave(&#39;graph1.png&#39;, width = 20, height = 20, units = &#39;cm&#39;) Выполнив эту функцию мы получим в рабочей директории файл с графиком, который мы только что нарисовали. 6.4 Файнал босс Чтобы закрепить всё, чему вы научились, вот вам суперзадание. Скорее всего, в ходе его выполнения, вам придется погуглить — это тоже важный навык аналитика. Главное — пробовать и не сдаваться, если с первого раза не всё прошло удачно. У вас обязательно всё получится! Сложное задание Скачайте отсюда реальные данные. Команта для скачивания (с сохранением в объект share): share &lt;- read.csv(&quot;https://raw.githubusercontent.com/angelgardt/mk_ggplot2/master/sharexp_data.csv&quot;) Это данные поведенческого эксперимента, в котором пользователи Android и iOS искали иконки «share» обеих платформ среди универсальных иконок. Короче, зрительный поиск. Нас будут интересовать следующие переменные: trialtype — тип пробы (tray/dots/both) setsize — количество стимулов в пробе (8/12/16) time1 — время первого клика platform — платформа смартфона (Android/iOS) Повторите представленную визуализацию: Подсказка Вам может быть полезен вот такой код: share[share$trialtype != &quot;both&quot;, ] 6.5 Конклюжон Мы с вами быстро пробежались по гглоту, однако за границами данного занятия осталось множество его возможностей. Мы не смотрели специфичные геомы, другие системы координат и интерактивные визуализации. Сложно посоветовать единый всеобъемлющий гайд по этой библиотеке — разве что вот эта книжка. А вообще всегда помните, что есть вот этот сайт, где вы можете найти любую нужную вам информацию — по ggplot2 уж точно. Ну, и конечно, фил фри ту написать автору в телеграм (@angelgardt) или фейсбук. По теореме умножения вероятностей.↩︎ Справедливости ради стоит отметить, что дисперсионный анализ очень часто используется для анализа экспериментальных данных, поэтому поработаем с ними.↩︎ Что бы это ни значило…↩︎ Вообще об этом стоило подумать, когда мы смотрели на распределения переменной price и видели, что у нас очень много «дешёвых» бриллиантов и мало «дорогих». Но это уже следующий этап погружения в анализ картинок. Нам бы пока с возможностями ггплота разобраться…↩︎ Мы такие оригинальные!↩︎ "],["продолжаем-с-data-table.html", "7 Продолжаем с data.table 7.1 Продолжаем с data.table 7.2 Указание имён при создании колонок 7.3 Вечер в хату, вектор в colnames() 7.4 setnames() из библиотеки data.table", " 7 Продолжаем с data.table library(data.table) 7.1 Продолжаем с data.table Вчера мы познакомились с библиотекой data.table и дата.тейблом как структурой данных с расширенным функционалом. Давайте освежим: Внутри квадратных скобок дата.тейбла к колонкам можно обращаться просто по именам, без выражений типа df$column. У дата.тейбла есть три элемента в квадратных скобках, они отделены запятыми: dt[фильтр строк, выражение, параметр]. Первый элемент позволяет выбрать, какие строки отфильтровать. Во втором элементе можно вывести колонку, создать новую колонку или применить к колонке какую-нибудь функцию. В третьем элементе можно сгруппировать наблюдения по значению в колонке. Давайте загрузим наш датасет, чтобы нам было с чем работать: dt &lt;- fread(&quot;about_us_eng.csv&quot;) Вот так я могу посчитать средний размер обуви для всех респондентов в зависимости от того, сколько у них кошек, исключив тех, кто на этот вопрос не ответил: dt[cats != &quot;this is too personal&quot;, mean(shoe_size), by = cats] Задание для разминки: Исключив тех, кто не выбрал ни Пепси, ни Колу, посчитайте, сколько в среднем братьев и сестёр у любителей каждого напитка. 7.1.1 Счёт элементов с помощью .N До этого момента во втором выражении мы всегда считали какую-нибудь статистику - например, среднее или максимум. Но что, если мы хотим просто узнать, сколько у нас людей, так или иначе ответивших на вопрос? Сколько человек, например, любят Пепси, а сколько Колу? Это делается с помощью специального символа: .N. Этот символ считает, сколько в дата.тейбле строк. Если использовать только его, то мы получим просто количество строк во всём нашем дата.тейбле: dt[, .N] ## [1] 35 nrow(dt) ## [1] 35 Но если использовать его вместе с by =, который группирует, то мы узнаем, сколько строк в каждой группе! То есть вот такая строка посчитает, сколько каких ответов на вопрос о любимой газировке: dt[, .N, by = soft_drink] Кола лидирует - у неё 18 фанатов! Задание: Посчитайте, сколько у нас на мастерской людей с разным уровнем игры на гитаре. Кого больше всего? 7.1.2 Несколько группировок Крайне часто мы хотим посчитать какую-нибудь статистику для каждого сочетания двух переменных. Представьте, что вы проводите эксперимент о влиянии кофеина и физической активности на решение задач. У вас есть две независимых переменных - во-первых, вы даёте испытуемым кофе, чай или воду, во-вторых, вы просите их пробежать километр, позаниматься йогой или просто посидеть перед тем, как они приступят к решению задач, и фиксируете, сколько задач решил каждый испытуемый. В итоге вам будет интересно, сколько в среднем задач решили испытуемые, которые пили кофе и бегали, испытуемые, которые пили кофе и занимались йогой, пили кофе и сидели, пили чай и бегали, ну и так далее. Посчитать это в дата.тейбле очень просто: нужно использовать две колонки в третьей части квадратных скобок, там, где by =. Чтобы сгруппировать по двум колонкам сразу, имена колонок нужно объединить с помощью специальной функции, вот так: .(columnName1, columnName2). Вот как посчитать средний размер обуви в зависимости от предпочтений в газировке и месяца рождения: dt[, mean(shoe_size), by = .(soft_drink, month)] Количество группировок, в целом, не ограничено, чисто технически - группируйте хоть по ста колонкам. Но имейте в виду: если у вас в датасете, как у нас сейчас, 35 человек, то очень “детальные” группировки, скорее всего, приведут к тому, что во многих группах просто никого не будет. Например, сколько среди нас тех, кто обожает Пепси, выше 180 сантиметров, имеет двух котов и три глаза? Кстати, хороший вопрос. Задание: Сколько среди нас тех, кто обожает Пепси, выше 180 сантиметров, имеет двух котов и три глаза? Это задание можно выполнить как минимум двумя способами, используя разные части квадратных скобок. Попробуйте найти оба способа. 7.1.3 Несколько выражений Точно так же, как и колонок для группировки, выражений во втором элементе может быть несколько. Например, если нас интересует несколько статистик сразу, скажем, среднее и дисперсия. Для этого нужно объединить нужные нам функции той же самой функцией .(): dt[, .(mean(height), var(height)), by = eye_color] Давайте соберём воедино: dt[, .(.N, mean(hair_length)), by = .(month, soft_drink)] Что делает предыдущая строчка кода? Задание: посчитайте значения квартилей роста для всех респондентов в зависимости от их предпочтений в напитках (Кола или Пепси плюс кофе или чай). 7.1.4 Имена колонок Вы могли заметить, что каждый раз, когда мы группируем дата.тейбл и считаем какие-нибудь аггрегированные значения типа среднего, то колонки с этими посчитанными значениями получают имена типа V1, V2 и т.п. Это не очень удобно - содержательное имя переменной это гарант того, что вы-читающий(-ая)-свой-старый-код-через-год или другие люди, которым вы свой код покажете, поймут, что в нём происходит. Давайте позаботимся о себе из будущего и научимся называть эти колонки содержательно. 7.2 Указание имён при создании колонок Имя колонки можно указать сразу при названии, вот так: dt[, .(mean_hair_length = mean(hair_length), var_hair_length = var(hair_length)), by = eye_color] Обратите внимание, что имена колонок мы указываем внутри .(). То же самое будет верно и для одной колонки - если мы не указываем её имя, то оборачивать в точку её не обязательно (хотя с точкой всё тоже будет работать), а вот если указываем, то надо обязательно использовать .() даже для единственной колонки. Вот так не сработает: dt[, mean_hair_length = mean(hair_length), by = eye_color] Вот так работает: dt[, .(mean_hair_length = mean(hair_length)), by = eye_color] К слову, вот эти две команды делают одно и то же: dt[, .(mean(hair_length)), by = eye_color] dt[, mean(hair_length), by = eye_color] Таким образом мы можем задать имена колонкам при создании. Часто мы хотим переименовать колонки в уже существующем дата.фрейме - например, если вы собираете данные на Гугл.Формах, то именем колонки является текст вопроса, а это ужасно неудобно. 7.3 Вечер в хату, вектор в colnames() Функция colnames() не только возвращает имена колонок, но и может их менять. Это не специфично для дата.тейбла, это метод из base R, то есть, он сработает и с дата.фреймом. Чтобы переименовать колонку, нужно передать функции colnames() вектор с новыми именами колонок. Давайте переименуем колонку cats в meow. colnames(dt) ## [1] &quot;height&quot; &quot;eye_color&quot; &quot;eye_number&quot; &quot;beard&quot; &quot;soft_drink&quot; ## [6] &quot;cats&quot; &quot;gorgeous&quot; &quot;siblings&quot; &quot;hair_length&quot; &quot;shoe_size&quot; ## [11] &quot;guitar&quot; &quot;hot_drink&quot; &quot;month&quot; &quot;hogwarts&quot; &quot;dream&quot; colnames(dt) &lt;- c(&quot;height&quot;,&quot;eye_color&quot;,&quot;eye_number&quot;,&quot;beard&quot;,&quot;soft_drink&quot;,&quot;meow&quot;, &quot;gorgeous&quot;,&quot;siblings&quot;,&quot;hair_length&quot;,&quot;shoe_size&quot;,&quot;guitar&quot;,&quot;hot_drink&quot;,&quot;month&quot;,&quot;hogwarts&quot;,&quot;dream&quot;) colnames(dt) ## [1] &quot;height&quot; &quot;eye_color&quot; &quot;eye_number&quot; &quot;beard&quot; &quot;soft_drink&quot; ## [6] &quot;meow&quot; &quot;gorgeous&quot; &quot;siblings&quot; &quot;hair_length&quot; &quot;shoe_size&quot; ## [11] &quot;guitar&quot; &quot;hot_drink&quot; &quot;month&quot; &quot;hogwarts&quot; &quot;dream&quot; Можно не передавать вектор всех имён, а отфильтровать самую функцию colnames(), используя индекс колонки (cats/meow - шестая): colnames(dt)[6] &lt;- &quot;cats&quot; colnames(dt) #всё вернулось на круги своя ## [1] &quot;height&quot; &quot;eye_color&quot; &quot;eye_number&quot; &quot;beard&quot; &quot;soft_drink&quot; ## [6] &quot;cats&quot; &quot;gorgeous&quot; &quot;siblings&quot; &quot;hair_length&quot; &quot;shoe_size&quot; ## [11] &quot;guitar&quot; &quot;hot_drink&quot; &quot;month&quot; &quot;hogwarts&quot; &quot;dream&quot; Минусы этого метода - тысячи их. А именно: во-первых, скажем так, странный синтаксис (мы присваиваем что-то функции, а меняется дата.тейбл? Почему мы индексируем функцию?). Во-вторых, надо или передавать вектор всех имён, или использовать индекс колонки - вдруг он поменяется… К счастью, есть более удобная альтернатива. 7.4 setnames() из библиотеки data.table Функция setnames() имеет три аргумента: во-первых, собственно, имя дата.тейбла, в котором нужно переименовывать колонки, во-вторых, вектор старых имён, в-третьих, вектор новых имён. Для одной колонки: setnames(dt, old = &quot;cats&quot;, new = &quot;meow&quot;) Для двух колонок: setnames(dt, old = c(&quot;cats&quot;, &quot;hair_length&quot;), new = c(&quot;meow&quot;, &quot;hairlength&quot;)) Эта команда переименует колонку cats в meow, а колонку hair_length в hair_length. Давайте вернём всё обратно: setnames(dt, old = c(&quot;meow&quot;, &quot;hairlength&quot;), new = c(&quot;cats&quot;, &quot;hair_length&quot;)) Новые имена в setnames() можно не указывать вручную, а задавать как преобразование старых. Для этого нужно дать на вход параметру new не вектор имён, а функцию, которую вы хотите применить к старым именам. Например, функция toupper() превращает все строчные буквы в заглавные: toupper(&#39;abcd&#39;) ## [1] &quot;ABCD&quot; А вот что получится, если использовать её для нашего дата.тейбла: setnames(dt, old = &#39;cats&#39;, new = toupper) colnames(dt) ## [1] &quot;height&quot; &quot;eye_color&quot; &quot;eye_number&quot; &quot;beard&quot; &quot;soft_drink&quot; ## [6] &quot;CATS&quot; &quot;gorgeous&quot; &quot;siblings&quot; &quot;hair_length&quot; &quot;shoe_size&quot; ## [11] &quot;guitar&quot; &quot;hot_drink&quot; &quot;month&quot; &quot;hogwarts&quot; &quot;dream&quot; Кстати, если не уточнять, какие колонки переименовываем, то setnames() применит это функцию ко всем. Вот такая команда сделает заглавными буквы во всех именах колонок: setnames(dt, toupper) colnames(dt) ## [1] &quot;HEIGHT&quot; &quot;EYE_COLOR&quot; &quot;EYE_NUMBER&quot; &quot;BEARD&quot; &quot;SOFT_DRINK&quot; ## [6] &quot;CATS&quot; &quot;GORGEOUS&quot; &quot;SIBLINGS&quot; &quot;HAIR_LENGTH&quot; &quot;SHOE_SIZE&quot; ## [11] &quot;GUITAR&quot; &quot;HOT_DRINK&quot; &quot;MONTH&quot; &quot;HOGWARTS&quot; &quot;DREAM&quot; А вот такая вернёт всё обратно как было: setnames(dt, tolower) colnames(dt) ## [1] &quot;height&quot; &quot;eye_color&quot; &quot;eye_number&quot; &quot;beard&quot; &quot;soft_drink&quot; ## [6] &quot;cats&quot; &quot;gorgeous&quot; &quot;siblings&quot; &quot;hair_length&quot; &quot;shoe_size&quot; ## [11] &quot;guitar&quot; &quot;hot_drink&quot; &quot;month&quot; &quot;hogwarts&quot; &quot;dream&quot; 7.4.1 Новый дата.тейбл или колонка в существующем? Напоследок давайте обсудим такую вещь: в этой главе мы всю дорогу использовали = во втором элементе дата.тейбловских квадратных скобок. Но ведь в первый день мы обсудили, что у дата.тейбла есть свой специальный оператор :=. Что будет, если использовать его? Давайте посмотрим. dt[, mean_hair_length := mean(hair_length), by = eye_color] Хммм, что-то ничего не происходит… Или происходит? Посмотрим, как теперь выглядит наш дата.тейбл: head(dt) Опа! Смотрите сами: там появилась новая колонка со средней длиной волос в зависимости от цвета глаз. То есть, теперь в строке у каждого респондента есть не только его индивидуальные данные, но и данные о какой-то группе, к которой она или он относится. Это логично, если вспомнить, что := именно что создаёт новую колонку в существующем дата.тейбле - даже если вы сгруппировали дата.тейбл с помощью by =. То есть, вот такая команда создаст новый дата.тейбл, в котором будет только группирующая переменная (здесь - цвет глаз) и то, что мы для неё посчитали (в данном случае среднюю длину волос): dt[, .(mean_hair_length = mean(hair_length)), by = eye_color] Чтобы этот новый дата.тейбл можно было использовать потом, надо сохранить его в переменную: meanHairLengthByEyeColor &lt;- dt[, .(mean_hair_length = mean(hair_length)), by = eye_color] А вот такая команда добавит в существующий дата.тейбл новую колонку mean_hair_length_by_eye_color: dt[, mean_hair_length_by_eye_color := mean(hair_length), by = eye_color] Никуда дополнительно её сохранять не надо - это делает :=. Задание. Почистите датасет (то есть, уберите все сомнительные ответы - глаза больше 2 и т.п.). Переведите длину волос из сантиметров в дюймы (для этого вам поможет знание, что 1 см = 0.3937 дюйма), а потом создайте новый дата.тейбл, в котором посчитайте среднюю длину волос в зависимости от количества братьев и сестёр, а также предпочтений в вопросах кофе и чая. А затем постройте график всего этого великолепия :) Задание. Скачайте датасет про разные виды мюсли (мюслей?..) на Kaggle, вот тут. Используя всё, что вы узнали про data.table, ggplot2 и всяческие статистические тесты, расскажите и покажите один интересный факт о мюсли (мюслях?..). "],["слияние-и-преобразование-табличных-данных.html", "8 Слияние и преобразование табличных данных 8.1 Слияние и преобразование табличных данных", " 8 Слияние и преобразование табличных данных library(data.table) library(ggplot2) 8.1 Слияние и преобразование табличных данных Один из больших плюсов использования R - то, что с его помощью можно очень гибко менять формат ваших данных - соединять несколько таблиц воедино, считать для них какие-то специфические показатели и преобразовывать. Именно это мы научимся делать в этой главе. 8.1.1 Соединение двух таблиц в одну: простой случай. Самый простой случай, в котором нам нужно соединить две таблицы в одну, выглядит так: у вас есть две таблицы (например, по одному от каждого человека, который прошёл ваш эксперимент), которые вы хотите соединить в одну. У обеих таблиц одинаковые имена колонок, и в итоге вы хотите получить одну таблицу, в которой будет столько же колонок, а строки из первоначальных таблиц “подклеены”. Это делается с помощью функции rbind(). r здесь это указание на склейку по строкам (rows). Давайте посмотрим: dt1 &lt;- data.table(a = 1:3, b = c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)) dt2 &lt;- data.table(a = 4:6, b = c(&#39;d&#39;, &#39;e&#39;, &#39;f&#39;)) rbind(dt1, dt2) И даже если порядок столбцов различается, всё сработает как надо - rbind объединит колонки с одинаковыми именами: dt1 &lt;- data.table(a = 1:3, b = c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)) dt2 &lt;- data.table(b = c(&#39;d&#39;, &#39;e&#39;, &#39;f&#39;), a = 4:6) rbind(dt1, dt2) Кайф. Имейте в виду, что rbind() не знает, что делать, если в одной таблице колонок больше, чем в другой. Если вы запустите вот этот код у себя, он выдаст ошибку: dt1 &lt;- data.table(a = 1:3, b = c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;), c = c(TRUE, FALSE, TRUE)) dt2 &lt;- data.table(b = c(&#39;d&#39;, &#39;e&#39;, &#39;f&#39;), a = 4:6) rbind(dt1, dt2) Неожиданный результат может получиться, и если в колонках, которые надо соединить разные типы данные. Например, здесь в первой таблице числа в колонке a, а во второй - логические переменные в той же таблице a. В результате rbind() постарается привести данные из обеих колонок к одному типу данных. Как превратить 3 или 2 в логическую переменную, непонятно, а вот TRUE можно записать как 1 и FALSE как 0, так что в склеенной таблице в колонке a будут лежать числа даже там, где были тру и фолсы. Обращайте на это внимание, не дайте себя обмануть! dt1 &lt;- data.table(a = 1:3, b = c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)) dt2 &lt;- data.table(b = c(&#39;d&#39;, &#39;e&#39;, &#39;f&#39;), a = c(TRUE, FALSE, TRUE)) rbind(dt1, dt2) Точно так же, как по строкам, мы можем “склеить” таблицы по колонкам - с помощью функции cbind(), где c это column, колонка: dt1 &lt;- data.table(a = 1:3, b = c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)) dt2 &lt;- data.table(c = 4:6, d = c(&#39;d&#39;, &#39;e&#39;, &#39;f&#39;)) cbind(dt1, dt2) Когда нам может пригодиться cbind()? Например, если у вас есть одна таблица, в которой записан возраст всех испытуемых, и вторая, в которой записаны их ответы на вопросы опросника, и вы хотите получить одну таблицу, в которой есть вся информация вместе. Но! Имейте в виду, что cbind() просто склеивает колонки по порядку, никак не проверяя, совпадают ли какие-нибудь значения в строчках. Давайте приведу пример, что это значит. В dt1 я сохраню возраста испытуемых (в колонку age) и их имена (в колонку name). А в dt2 - сколько каждый испытуемый решил задачек в моём эксперименте (в колонку problems_solved. Мария справилась лучше всех, ничего себе! Наверное, все Марии гениальны…) и снова их имена в колонку names. Обратите внимание: в дата.тейбле с возрастами Василий второй и Вольфганг третий, а в дата.тейбле с данными о решении задачек - наоборот. Что будет, если я соединю эти дата.тейблы в один с помощью cbind()? dt1 &lt;- data.table(age = c(18,20,98), name = c(&#39;Maria&#39;, &#39;Vasiliy&#39;, &#39;Wolfgang&#39;)) dt2 &lt;- data.table(problems_solved = c(146, 10, 15), name = c(&#39;Maria&#39;, &#39;Wolfgang&#39;, &#39;Vasiliy&#39;)) cbind(dt1, dt2) А вот что: во второй строке будет лежать возраст Василия, но количество решённых задачек - Вольфганга. А ведь эти два человека явно живут совсем разные жизни! Кроме того, в получившемся дата.тейбле у нас две колонки с одинаковыми именами - тоже проблема. Можно придумать всякие окольные решения (например, сначала отсортировать обе таблицы по колонке имён, а уже потом соединить и удалить дублирующуюся колонку), но есть более простой путь - использовать функцию merge(). 8.1.2 merge() и четыре разных соединения Более умное соединение по столбцам можно выполнять с помощью функции merge(). Давайте для начала посмотрим, что она сделает с нашей проблемой Вольфганга и Василия: dt1 &lt;- data.table(age = c(18,20,98), name = c(&#39;Maria&#39;, &#39;Vasiliy&#39;, &#39;Wolfgang&#39;)) dt2 &lt;- data.table(problems_solved = c(146, 10, 15), name = c(&#39;Maria&#39;, &#39;Wolfgang&#39;, &#39;Vasiliy&#39;)) merge(x = dt1, y = dt2) Воу! Круто, правда? :D merge() совершенно самостоятельно обнаружил, что у в обеих таблицах есть колонка с одинаковым названием - name - и использовал её в качестве колонки ключей, то есть указателя соответствия между таблицей один и таблицей два. Это происходит по умолчанию - merge() находит колонки с одинаковыми именами и соединяет по ним. Но можно задавать колонки ключей и вручную, с помощью аргумента by. Это может пригодиться, например, если в таблице несколько колонок с одинаковыми именами, но “ключом” должна быть только одна из них. Представьте, что наша троица (Мария, Василий и Вольфганг) проходили эксперимент два раза - они пришли в первый раз, сказали нам свой возраст, порешали задачки. Эти данные хранятся в dt1. Через день они пришли ещё раз и снова порешали задачки. Эти данные хранятся в dt2. То есть, в обеих таблицах есть колонка problems_solved, но использовать её как ключ мы совершенно не хотим - более того, мы хотим, чтобы в финальном дата.тейбле осталась и problem_solved из первой таблицы, и problem_solved из второй таблицы. Тут-то нам и пригодится by: dt1 &lt;- data.table(age = c(18,20,98), name = c(&#39;Maria&#39;, &#39;Vasiliy&#39;, &#39;Wolfgang&#39;), problems_solved = c(150, 11, 9)) dt2 &lt;- data.table(problems_solved = c(146, 10, 15), name = c(&#39;Maria&#39;, &#39;Wolfgang&#39;, &#39;Vasiliy&#39;)) merge(x = dt1, y = dt2, by = &#39;name&#39;) Обратите внимание, что колонка problems_solved из dt1 в соединённом дата.тейбле называется problems_solved.x, а problems_solved из dt2 называется problems_solved.y. Здесь x это первая таблица, которую мы даём на вход функции merge(), а y - вторая. То есть, команда merge(dt2, dt1) поменяла бы названия колонок местами: problems_solved из dt1 в соединённом дата.тейбле стала бы problems_solved.y, а problems_solved из dt2 стала бы problems_solved.x. Вопрос на засыпку: проверьте, что будет, если в последнем примере не уточнять by = “name”. Почему? Если вы хотите использовать в качестве ключа несколько колонок сразу, то можно просто передать by вектор их имён на вход: by = c(\"name\", \"ID\"). Вообще лучше всегда эксплицитно уточнять, какую колонку (или какие колонки) надо использовать как ключ - better safe than sorry :) Кроме того, если одна и та же колонка в двух таблицах называется по-разному, это тоже не проблема. Тогда нужно использовать by.x и by.y вместо by. В by.x уточняем, как колонка-ключ называется в первом дата.тейбле, в by.y - как во втором. И никаких проблем. dt1 &lt;- data.table(age = c(18,20,98), name = c(&#39;Maria&#39;, &#39;Vasiliy&#39;, &#39;Wolfgang&#39;), problems_solved = c(150, 11, 9)) dt2 &lt;- data.table(problems_solved = c(146, 10, 15), imena = c(&#39;Maria&#39;, &#39;Wolfgang&#39;, &#39;Vasiliy&#39;)) merge(x = dt1, y = dt2, by.x = &#39;name&#39;, by.y = &#39;imena&#39;) В примере, который мы рассматривали до сих пор, в обеих таблицах были одни и те же испытуемые, или, более глобально, одинаковое количество одних и тех же наблюдений. Это далеко не всегда так. Давайте рассмотрим новый пример: у нас всё ещё эксперимент с решением задач. В первый день мы записываем возраст испытуемых и сколько задач они решили. Это dt1. Во второй мы тоже записываем, сколько задач решил каждый испытуемый, но ещё спрашиваем их рост. Это dt2. Кроме того, часть испытуемых пришла только в первый день, часть - только во второй, и часть в оба дня. Давайте сделаем такие дата.тейблы: dt1 &lt;- data.table(age = c(18, 20, 98, 40, 19), names = c(&#39;Maria&#39;, &#39;Vasiliy&#39;, &#39;Wolfgang&#39;, &#39;Dana&#39;, &#39;Boris&#39;), problems_solved = c(150, 11, 9, 20, 15)) dt1 dt2 &lt;- data.table(names = c(&#39;Maria&#39;, &#39;Vasiliy&#39;, &#39;Wolfgang&#39;, &#39;Katerina&#39;, &#39;Vladimir&#39;), problems_solved = c(150, 11, 9, 11, 40), height = c(160, 180, 173, 167, 178)) dt2 Что мы видим? Мария, Василий и Вольфганг пришли в оба дня. Дана и Борис - только в первый. А Катерина и Владимир - только во второй. Две таких таблицы можно соединить четырьмя разными способами. Я не могу найти для них никаких симпатичных названий на русском, так что буду использовать англоязычные названия. 8.1.3 Inner join Inner join Итак, первый способ соединить две таблицы из нашего примера это inner join (внутреннее слияние?..) - когда мы оставляем только те наблюдения, которые есть в обеих таблицах. То есть, на всех испытуемых, которые пришли только в один из дней, мы забиваем, нам необязательные не нужны, зато склеиваем воедино все данные о троице пришедших в оба дня. По умолчанию merge() делает именно inner join: merge(dt1, dt2, by = &#39;names&#39;) 8.1.4 Outer join Outer join, наоборот, оставит в смёрдженной таблице только те наблюдения, которые уникальны или для первой, или для второй таблицы - то есть, в нашем примере, всех, кроме Марии, Василия и Вольфганга. Чтобы выполнить такое соединение в функции merge(), надо уточнить внутри функции all = TRUE, вот так: merge(dt1, dt2, all = TRUE, by = &#39;names&#39;) Обратите внимание: во-первых, problems_solved из обеих таблиц помечены как problems_solved.x и problems_solved.y. Во-вторых, мы записывали возраст только в первый день, а рост только во второй. То есть, если испытуемый приходил только в первый день (как Дана и Борис), то про их рост мы ничего не знаем, и в этой колонке у них NA. То же самое с возрастом у Катерины и Владимира, которые приходили только во второй день. 8.1.5 Left join Left join Left join оставит только те наблюдения, которые есть в первой таблице, и добавит для них информацию из второй таблицы. Для этого надо уточнить в merge(), что all.x = TRUE - то есть, мы хотим все наблюдения из x, из первой таблицы: merge(dt1, dt2, all.x = TRUE, by = &#39;names&#39;) 8.1.6 Right join Right join Правый джоин - противоположность левого: он оставляет только наблюдения (= испытуемых) из второй таблицы, добавляя для них информацию из первой. Чтобы соединить так, надо в merge() уточнить, что all.y = TRUE: dt1 &lt;- data.table(age = c(18,20,98), name = c(&#39;Maria&#39;, &#39;Vasiliy&#39;, &#39;Wolfgang&#39;), problems_solved = c(150, 11, 9)) 8.1.7 Широкие или длинные данные Ещё один тип преобразования, который нередко нужно совершать, это превращение данных из длинных в широкие или обратно. Что такое длинные или широкие данные? Мы сейчас всю дорогу работали с широкими данными, в которых каждая строка это наблюдение (например, один испытуемый), а каждая колонка это переменная (например, возраст). wideDt &lt;- data.table(age = c(18,20,98), name = c(&#39;Maria&#39;, &#39;Vasiliy&#39;, &#39;Wolfgang&#39;), problems_solved = c(150, 11, 9)) wideDt В длинном формате данных на каждое наблюдение приходится несколько строчек, потому что вместо того, чтобы хранить каждую переменную в отдельной колонке, мы делаем её отдельной строкой. То есть, если про Василия мы знаем его возраст и сколько задач он решил, то в одной строке мы запишем возраст, а в другой - количество решённых задач. Если мы ещё знаем, например, его рост, то и рост станет отдельной строкой. Для этого мы создадим две колонки: variable и value. В value мы будем хранить, собственно, значения (число лет, число решённых задач и т.п.), а в variable - уточнять, что за значение мы храним в этой строке. Давай разберём на примере: longDt &lt;- melt(wideDt, id.vars = &#39;name&#39;, measure.vars = c(&#39;age&#39;, &#39;problems_solved&#39;)) longDt Сравните wideDt и longDt. Осознайте, что в обоих содержится одна и та же информация. Примите это. Для разных задач вам могут потребоваться как широкий, так и длинный формат данных, так что очень полезно уметь преобразовать один в другой. 8.1.8 Из широких в длинные: melt() Как вы могли заметить, в последнем куске кода я использовала функцию melt(), чтобы перевести данные из широкого формата в длинный. Для этого мне надо указать колонку-идентификатор (то есть ту, которая остаётся в широком формате.Таких колонок может быть несколько) и колонки с измерениями - то есть те, которые мы как раз хотим переформатировать. Колонка-идентификатор указывается в аргументе id.vars с помощью вектора имён колонок, а колонки с измерениями - так же, но в аргументе measure.vars. melt(wideDt, id.vars = &#39;name&#39;, measure.vars = c(&#39;age&#39;, &#39;problems_solved&#39;)) Если я выберу другую колонку в id.vars, то получу совсем другой результат: melt(wideDt, id.vars = &#39;age&#39;, measure.vars = c(&#39;name&#39;, &#39;problems_solved&#39;)) ## Warning in melt.data.table(wideDt, id.vars = &quot;age&quot;, measure.vars = c(&quot;name&quot;, : ## &#39;measure.vars&#39; [name, problems_solved] are not all of the same type. By order of ## hierarchy, the molten data value column will be of type &#39;character&#39;. All measure ## variables not of type &#39;character&#39; will be coerced too. Check DETAILS in ? ## melt.data.table for more on coercion. Так как у нас нет испытуемых с одинаковым возрастом, то для каждого значения возраста мы, по сути, храним информацию об одном испытуемом. Давайте сначала сгруппируем людей по возрасту (старше среднего или младше среднего), а потом трансформируем данные в длинный формат по этой группировке: wideDt[, age_above_mean := age &gt; mean(age)] wideDt Теперь в колонке age_above_mean у нас лежит TRUE, если возраст выше среднего в таблице, и FALSE, если ниже. Давайте используем её как id.vars. melt(wideDt, id.vars = &#39;age_above_mean&#39;, measure.vars = c(&#39;age&#39;, &#39;name&#39;, &#39;problems_solved&#39;)) ## Warning in melt.data.table(wideDt, id.vars = &quot;age_above_mean&quot;, measure.vars ## = c(&quot;age&quot;, : &#39;measure.vars&#39; [age, name, problems_solved] are not all of the ## same type. By order of hierarchy, the molten data value column will be of type ## &#39;character&#39;. All measure variables not of type &#39;character&#39; will be coerced too. ## Check DETAILS in ?melt.data.table for more on coercion. В целом, если указать только id.vars, то melt() автоматически использует все оставшиеся колонки как measure.vars: melt(wideDt, id.vars = &#39;age_above_mean&#39;) ## Warning in melt.data.table(wideDt, id.vars = &quot;age_above_mean&quot;): ## &#39;measure.vars&#39; [age, name, problems_solved] are not all of the same type. By ## order of hierarchy, the molten data value column will be of type &#39;character&#39;. ## All measure variables not of type &#39;character&#39; will be coerced too. Check DETAILS ## in ?melt.data.table for more on coercion. При этом мы можем выбрать только часть колонок как measure.vars, и тогда остальные в трансформированную длинную таблицу не войдут: melt(wideDt, id.vars = &#39;age_above_mean&#39;, measure.vars = &#39;problems_solved&#39;) 8.1.9 Качественные вина ## Warning in melt.data.table(wine, id.vars = &quot;quality_above_mean&quot;): ## &#39;measure.vars&#39; [fixed acidity, volatile acidity, citric acid, residual ## sugar, ...] are not all of the same type. By order of hierarchy, the molten ## data value column will be of type &#39;double&#39;. All measure variables not of type ## &#39;double&#39; will be coerced too. Check DETAILS in ?melt.data.table for more on ## coercion. Скачайте с Каггла датасет о красных винах. Разделите вина на “лучше среднего” и “хуже среднего” по экспертной оценке качества (колонка quality) и постройте такой же график, как сверху. Для этого вам нужно будет перевести дата.тейбл в длинный формат. Подсказка: вам понадобится geom_density() и facet_wrap() с аргументом scales = ‘free’). 8.1.10 Из длинных в широкие: dcast() Конечно же, данные можно преобразовать и обратно из длинного формата в широкий. Это можно сделать с помощью функции dcast(), вот так: dcast(longDt, name ~ variable, value.var = &quot;value&quot;) То, как именно преобразовать данные, в dcast() указывается с помощью формулы, здесь name ~ variable. Формула это особый синтаксис, в котором, если попросту, можно прочитать тильду ~ как “в зависимости от”. Вы ещё столкнётесь с формулами в разделе про линейные регрессии. Конкретно в dcast() слева от тильды мы указываем колонку-идентификатор, а справа - колонку с будущими именами колонок в трансформированной широкой таблице. В аргументе value.var мы указываем колонку со значениями, которые нужно будет положить в свежесозданные колонки. Что, например, можно сделать с dcast()? Ну, например, сделать вот так: dt &lt;- fread(&quot;about_us_eng.csv&quot;) hogwartsByMonth &lt;- dt[, .N, by = .(hogwarts, month)] dcast(hogwartsByMonth, hogwarts ~ month, value.var = &quot;N&quot;) Переменная, которую вы указываете до тильды, так и останется колонкой, а вот значения переменной, указанной после тильды, превратятся в имена новых колонок. Смотрите, что произойдёт, если я поменяю их местами: dcast(hogwartsByMonth, month ~ hogwarts, value.var = &quot;N&quot;) Посчитайте среднюю длину волос в нашем dt в зависимости от того, что они любят, колу или пепси, и того, сколько у них кошек (ответ про “Это личное” уберите). Сделайте табличку, в которой количество кошек меняется по строкам, а любовь к газировке - по столбцам. "],["anova-a-k-a-дисперсионный-анализ.html", "9 ANOVA a.k.a. Дисперсионный анализ 9.1 Зачем нужен дисперсионный анализ? 9.2 Однофакторный дисперсионный анализ 9.3 Многофакторный дисперсионный анализ 9.4 Многофакторный дисперсионный анализ без взаимодействия в R 9.5 Важность аггрегации данных 9.6 Итоги", " 9 ANOVA a.k.a. Дисперсионный анализ 9.1 Зачем нужен дисперсионный анализ? Дисперсионный анализ (ANalysis Of VAriances) нужен, чтобы тестирования гипотзы о влиянии факторов на зависимые переменные. Вернее, более корректно было бы сказать, гипотезы о связях факторов с зависимыми переменными. С точки зрения данных фактор — это категориальная переменная, которая разбивает наши наблюдения на несколько групп. Например, переменная «экспериментальное условие» или «ступень обучения» (бакалавриат, магистратура, аспирантура) и т.д. Итак, мы продолжаем сравнивать группы, однако теперь в отличие, например, от t-теста, у нас их больше, чем две. Казалось бы, ну и пофиг? Просто попарно сравниваем все группы друг с другом и обнаруживаем (или нет) искомые различия. Так-то оно, конечно, так — но ведь это не так… 9.1.1 Проблема множественных сравнений Когда мы сравнивали две группы между собой, всё было хорошо. А если у нас больше двух групп? Если их пять? Десять? В одном сравнении вероятность ошибки первого рода мы задаем как \\(0.05\\). Когда у нас появляется много сравнений, она существенно возрастает. Почему? Мы проводим независимые сравнения, значит вероятности ошибок будут перемножаться6. Если верояность ошибиться в одном сравнении \\(\\alpha\\), то вероятность сделать правильный вывод — \\(1 - \\alpha\\). Тогда вероятность сделать правильный вывод в \\(m\\) сравнениях — \\((1 - \\alpha)^m\\). Отсюда мы можем вывести вероятность ошибиться хотя бы в одном сравнении: \\[ \\mathrm P&#39; = 1 - (1 - \\alpha)^m \\] Пусть у нас есть 3 группы, которые нам надо сравнить друг с другом — получается необходимо провести три сравнения. Итого вероятность ошибиться получается: \\[ \\mathrm P&#39; = 1 - (1 - 0.05)^3 \\approx 0.143 \\] Это значительно больше, чем \\(0.05\\). И дальше хуже. Поэтому нужно либо корректировать уровень значимости, либо использовать более мощные методы. Одним из таких методов и является дисперсионный анализ. 9.1.2 Идея дисперсионного анализа Идея данного метода состоит в том, что мы не тестируем различия между конкретными группами, а смотрим на влияние фактора в целом. Такое влияние будем выражаться в том, что между хотя бы двумя любыми группами будет статистически значимая разница. Математически мы можем это записать следующим образом: \\[ H_0: \\mu_1 = \\mu_2 = \\dots = \\mu_p \\\\ H_1: \\exists \\, i, \\, j: \\mu_i \\neq \\mu_j, \\] где \\(\\mu_1, \\, \\mu_2, \\, \\dots \\, \\mu_p\\) — средние значения в группах. Разберемся на примере. 9.2 Однофакторный дисперсионный анализ Здесь всё просто. У нас один фактор — категориальная переменная с несколькими уровнями — и мы хотим узнать, оказывает ли влияние данный фактор на нашу зависимую переменную. Вернее, конечно, правильнее было бы сказать, связан ли данный фактор в нашей зависимой переменной, как мы уже говорили выше. 9.2.1 Структура изменчивости Основные характеристики статистических данных — неопределённость и вариативность. И эта вариативность, он же изменчивость, имеет определенную структуру. Прежде всего, есть общая изменчивость, которая складывается из сумм квадратов отклонений от общего среднего: \\[ SS_\\mathrm{t} = \\sum_{i=1}^n (\\bar y - y_i)^2, \\, \\mathrm{df_t} = n - 1, \\] \\(SS_\\mathrm{t}\\) — общая сумма квадратов (Total Sum of Squares), \\(y_i\\) — наблюдение, \\(\\bar y\\) — среднее по всей выборке, \\(\\mathrm{df_t}\\) — число степеней свободы для общей суммы квадратов. Часть от неё составляет факторная (межгрупповая) изменчивость — это отклонения внутригрупповых средних от общего среднего: \\[ SS_\\mathrm{x} = \\sum_{j=1}^p (\\bar y - \\bar y_j)^2, \\, \\mathrm{df_x} = p - 1, \\] \\(SS_\\mathrm{x}\\) — факторная сумма квадратов (Factor Sum of Squares), \\(\\bar y_j\\) — среднее в конкретной группе наблюдений, \\(\\bar y\\) — среднее по всей выборке, \\(\\mathrm{df_x}\\) — число степеней свободы для факторной суммы квадратов. Оставшуюся часть составляет случайная (внутригрупповая) изменчивость: \\[ SS_\\mathrm{e} = \\sum_{i=1}^n \\sum_{j=1}^p (\\bar y_j - y_{ij})^2, \\, \\mathrm{df_e} = n - p \\] Таким образом, получаем, что \\[ SS_\\mathrm{t} = SS_\\mathrm{x} + SS_\\mathrm{e} \\] 9.2.2 Тестирование значимости фактора Почему диперсионный анализ называется именно так? Потому что используя суммы квадратов и степени свободы, мы можем перейти к дисперсиям — вернее, к средним квадратам: \\[ MS_{\\mathrm t} = \\frac{SS_\\mathrm{t}}{\\mathrm{df_t}}, \\quad MS_{\\mathrm x} = \\frac{SS_\\mathrm{x}}{\\mathrm{df_x}}, \\quad MS_{\\mathrm e} = \\frac{SS_\\mathrm{e}}{\\mathrm{df_e}} \\] \\(MS_\\mathrm{x}\\) и \\(MS_\\mathrm{e}\\) используются для тестирования значимости фактора. Если зависимости между фактором и целевой переменной нет, то \\(MS_\\mathrm{x} \\approx MS_\\mathrm{e}\\). Ешё раз вспомним, как формулируется статистическая гипотеза: \\[ H_0: \\mu_1 = \\mu_2 = \\dots = \\mu_p \\\\ H_1: \\exists \\, i, \\, j: \\mu_i \\neq \\mu_j, \\] Для тестирования гипотезы используется следующая статисика: \\[ F_{\\mathrm{df_x},\\,\\mathrm{df_e}} = \\frac{MS_\\mathrm{x}}{MS_\\mathrm{e}} \\overset{H_0}{\\thicksim} F(\\mathrm{df_x}, \\, \\mathrm{df_e}) \\] Результаты дисперсионного анализа обычно представляются в виде таблицы: Источник изменчивости \\(SS\\) \\(\\mathrm{df}\\) \\(MS\\) \\(F\\) \\(p\\) Фактор \\(SS_\\mathrm{x}\\) \\(\\mathrm{df_x}\\) \\(MS_\\mathrm{x}\\) \\(F_{\\mathrm{df_x},\\mathrm{df_e}}\\) \\(p\\) Случайная \\(SS_\\mathrm{e}\\) \\(\\mathrm{df_e}\\) \\(MS_\\mathrm{e}\\) Общая \\(SS_\\mathrm{t}\\) \\(\\mathrm{df_t}\\) 9.2.3 Данные Лежат тут. Скачиваются так: share &lt;- read.csv(&quot;https://raw.githubusercontent.com/angelgardt/mk_ggplot2/master/sharexp_data.csv&quot;) Это данные поведенческого эксперимента, в котором пользователи Android и iOS искали иконки «share» обеих платформ среди универсальных иконок. Короче, зрительный поиск. Нас будут интересовать следующие переменные: trialtype — тип пробы (tray/dots/both) setsize — количество стимулов в пробе (8/12/16) time1 — время первого клика platform — платформа смартфона (Android/iOS) Будем пытаться ответить на вопрос, какие факторы влияют на время первого клика. Только первоначально надо предобработать данные, убрав из них пробы типа both, так как это экспериментальное условие было задумано для другого анализа: share &lt;- share[share$trialtype != &quot;both&quot;, ] 9.2.4 Дисперсионный анализ в R Для дисперсионного анализа в R есть функция aov(). Она ожидает на вход формулу и датафрейм. Формула задаёт зависимую перменную (y) и фактор (x). Общий синтаксис будет такой: aov(formula = y ~ x, data) Пусть мы хотим понять, влияет ли тип пробы (trialtype) на время реакции (time1): fit1 &lt;- aov(time1 ~ trialtype, share) Обратите внимание на несколько моментов: переменная, которая задаёт фактор, должна быть факторной (внезапно), то есть данные должны быть приведены к длинному формату; в нашем случае переменная текстовая, поэтому автоматически была приведена к факторному типу результаты работы функции aov() мы записываем в объект, потому что так удобнее, сейчас мы поймём зачем Если мы посмотрим на сам объект fit1, то мы обнаружим не много полезной информации: fit1 ## Call: ## aov(formula = time1 ~ trialtype, data = share) ## ## Terms: ## trialtype Residuals ## Sum of Squares 9.570 9718.307 ## Deg. of Freedom 1 10798 ## ## Residual standard error: 0.9486885 ## Estimated effects may be unbalanced Чтобы получить табличку дисперсионного анализа, надо вызвать функцию summary() от сохраненного объекта: summary(fit1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trialtype 1 10 9.57 10.63 0.00111 ** ## Residuals 10798 9718 0.90 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 На что мы смотрим, чтобы определить значимость фактора? Как и в случае любых статистических методов: на значение статистики, в данном случае \\(F\\), и на p-value. Наблюдаем, что p-value меньше конфенционального 0.05, значит данный фактор статистически значимо связан с зависимой переменной. Однако в факторе trialtype есть только два уровня, и по факту мы сделали что-то сравнимое с t-тестом. Давайте попробуем запилить анову с тремя уровнями фактора. Возьмем переменную setsize. Так как это числовая переменная, чтобы анализ корректно отработал, необходимо перевести её в фактор, так как числа в отличии от строк по умолчанию в фактор не трансформируются: fit2 &lt;- aov(time1 ~ factor(setsize), share) summary(fit2) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## factor(setsize) 2 547 273.70 321.9 &lt;2e-16 *** ## Residuals 10797 9180 0.85 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Логика кода остаётся абсолютно такая же. Теперь обратим внимание на результат. Да, фактор количества стимулов (setsize) значим, но что это значит технически? Что есть хотя бы две группы, которые значимо различаются между собой. Какие — нам не известно. Чтобы это узнать, необходимо провести… 9.2.5 Post hoc тесты Post hoc тесты позволяют выяснить, между какими именно группами есть статисически значимые различия. Это не единственный метод, но самый распространенный, поэтому мы рассмотрим его. Чтобы выяснить, между какими конкретно группами есть различия, нам неизбежно придется выполнить несколько попарных сравнений — поэтому всё-таки придётся принять меры по предотвращению проблемы множественных сравнений, то есть скорректировать уровень значимости. Возникает закономерный вопрос: раз уж мы всё равно сравниваем попарно все группы, зачем вообще нам нужен был дисперсионный анализ? Можно же сразу было попарно сравнить и кайфовать! Так-то оно, конечно, так — но ведь это не так. Post hoc тесты, или попарные сравнения, мы выполняем только в том случае, если обнаружили значимое влияние фактора (предиктора). Напомним себе, что дисперсионный анализ тестирует гипотезу о том, что средние во всех группах равны. Соответственно, если в ходе дисперсионного анализа не обнаруживается значимое влияние фактора на зависимую переменную, у нас нет оснований отклонить эту нулевую гипотезу — следовательно, мы делаем вывод, что между группами нет различий. А раз их нет, то что же тогда тестировать попарными сравнениями? А вот если фактор получился значимым, то тогда хотя бы две из групп различаются — естественно, нам хотелось бы знать, какие конкретно. Тогда мы проводим попарные сравнения. Вообще говоря, попарные сравнения можно проводить любым статистическим тестом, который сравнивает две группы. Просто для именования перечислим следующие возможные варианты: наименьшая значимая разница Фишера (Fisher’s Least Significant Difference) поправка Бонферрони (Bonferroni correction) или Сидака (Sidak’s correction) тест Тьюки (Tuckey’s Honest Significant Difference, HSD) тест Стьюдента-Ньюмена-Кьюлса (Student-Newman-Kewls test, SNK) тест Даннета для сравнения с контрольной группой (Dunnet’s test) критерий Дункана (Dunkan’s test) тест Шеффе (Scheffe’s test) Из всего этого зоопарка мы рассмотрим тест Тьюки, так как он считается разумным компромиссом относительно жёсткости корректировки уровня значимости. Тест Тьюки выполняется с помощью функции TukeyHSD(), которая на вход ожидает объект с результатами дисперсионного анализа: TukeyHSD(fit2) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = time1 ~ factor(setsize), data = share) ## ## $`factor(setsize)` ## diff lwr upr p adj ## 12-8 0.2700864 0.2191407 0.3210320 0 ## 16-8 0.5514225 0.5004769 0.6023681 0 ## 16-12 0.2813361 0.2303905 0.3322818 0 Что мы видим? Табличку попарных сравнений: в первой колонке указано, какие группы сравнивались во второй — разница между средними в группах третья и четверная — нижняя и верхняя границы доверительного интервала для разницы средних пятая — p-value, по которому мы делаем статистический вывод В данном случае все три группы значимо различаются между собой. Задание Загрузите данные эксперимента на зрительный поиск (да, опять7). В эксперименте испытуемые должны были запоминать слова, обозначающие объекты, а затем искать эти объекты среди похожих других. В данных у нас есть следующие переменные: resp — идентификатор респондента group — уровень категории слов для запоминания (base — базовая и super — суперординатная) memory_setsize — количество слов-категорий для запоминания visual_setsize — количество стимулов на экране поиска объектов rt — время реакции / обнаружения стимула Исследуйте, как уровень категории слов для запоминания (group) влияет на скорость обнаружения стимула (rt). 9.3 Многофакторный дисперсионный анализ Чем ещё хорош дисперсионный анализ? Тем, что можно изучать влияние не только одного фактора, но и нескольких! Основной эффект каждого фактора интерпретируется аналогично тому, как это делалось в однофакторном дисперсионном анализе. Если же у нас значимо взаимодействие, то это говорит нам о том, что влияние одного фактора на зависимую переменную различается на разных уровнях другого фактора. Визуализация для понимания того, как оно работает: Вообще значимое взаимодействие факторов — это двоякая штука. С одной стороны, мы обнаружили интересную закономерность — возможно, именно ту, которую искали, и это круто. С другой стороны, взаимодействие, во-первых, может маскировать главные эффекты — если мы смотрим только на главные эффекты, то теряем часть информации о закономерности во-вторых, и это связано с первым пунктом, оно затрудняет интерпретацию основных эффектов. Если взаимодействие не значимо, то с интерпретацией главных эффектов трудностей не возникает. Если взаимодействие значимо, то обсуждать главнные эффекты необходимо аккуратно, или не обсуждать вовсе. В частности, нижний ряд рисунков выше показывает, как эффект фактора A частично маскирует эффект фактора B, что отражается во взаимодействии. Конечно, в модель можно ввести и более двух предикторов, и логика останется та же самая. Но помните, что чем сложнее модель, тем сложнее её интерпретация. А интерпретируя взаимодействие трёх предикторов вовсе можно сойти с ума. В связи с этим, есть следующий момент. Когда вы планируете ваше исследование, сразу подумайте, как вы будете анализировать данные — что будет входить в модель в качестве основных предикторов, что в качестве ковариат, и какие взаимодействия в ней будут. Иначе измерить кучу переменных вы построите модель, результаты которой невозможно будет понять. Дизайн исследования очень тесно связан с аналитикой. 9.4 Многофакторный дисперсионный анализ без взаимодействия в R В наших данных есть две переменные: trialtype и platform, влияние которых на время реакции хотелось бы исследовать. Переменная trialtype содержит два уровня — dots и tray. В факторе platform у нас два уровня — iOS и Android. Итого, у нас два фактора, в каждом из которых два уровня. Отлично! Поехали! Построим сначала модель без взаимодействия. Синтаксически несколько факторов в модель указываются через плюс (+): fit3 &lt;- aov(time1 ~ trialtype + platform, share) summary(fit3) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trialtype 1 10 9.57 10.68 0.00109 ** ## platform 1 41 40.82 45.54 1.57e-11 *** ## Residuals 10797 9677 0.90 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Таблица в аутпуте получается аналогичная, только теперь здесь не один, а два фактора. Для каждого рассчитана F-статистика и p-value. В данном случае оба предиктора оказались статистически значимы. 9.4.0.1 Post hoc тесты Постхоки делаются по той же схеме: TukeyHSD(fit3) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = time1 ~ trialtype + platform, data = share) ## ## $trialtype ## diff lwr upr p adj ## tray-dots 0.0595366 0.0238221 0.0952511 0.0010878 ## ## $platform ## diff lwr upr p adj ## ios-android -0.1229602 -0.1586747 -0.08724568 0 Поскольку у нас в каждом факторе два уровня, мы и видим два попарных уравнения с уже скорректированными p-значениями. Задание Продолжаем работать в данными эксперимента из предыдущего задания. Напоминалка В эксперименте испытуемые должны были запоминать слова, обозначающие объекты, а затем искать эти объекты среди похожих других. В данных у нас есть следующие переменные: resp — идентификатор респондента group — уровень категории слов для запоминания (base — базовая и super — суперординатная) memory_setsize — количество слов-категорий для запоминания visual_setsize — количество стимулов на экране поиска объектов rt — время реакции / обнаружения стимула Как влияют на скорость обнаружения целевого объекта (rt) число стимулов на экране (visual_setsize) поиска и число категорий для запоминания (memory_setsize)? Пока тестируем только основные эффекты, взаимодействие включать в модель не надо. 9.4.1 Многофакторный дисперсионный анализ со взаимодействием в R Чтобы включить в модель взаимодействие, есть два варианта: использовать оператор : использовать оператор * Есть мы используем первый вариант, то синтаксис будет выглядеть так: fit4.1 &lt;- aov(time1 ~ trialtype + platform + trialtype:platform, share) summary(fit4.1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trialtype 1 10 9.57 10.68 0.00109 ** ## platform 1 41 40.82 45.56 1.56e-11 *** ## trialtype:platform 1 4 3.83 4.27 0.03882 * ## Residuals 10796 9674 0.90 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Если мы пользуемся вторым вариантом, то синтаксис будет выглядеть так: fit4.2 &lt;- aov(time1 ~ trialtype * platform, share) summary(fit4.2) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trialtype 1 10 9.57 10.68 0.00109 ** ## platform 1 41 40.82 45.56 1.56e-11 *** ## trialtype:platform 1 4 3.83 4.27 0.03882 * ## Residuals 10796 9674 0.90 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Результаты получаются идентичные. Оператор * просто сокращает строку. 9.4.1.1 Post hoc тесты Удивительно, но в случае попарных сравнений всё ещё ничего не изменяется: TukeyHSD(fit4.1) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = time1 ~ trialtype + platform + trialtype:platform, data = share) ## ## $trialtype ## diff lwr upr p adj ## tray-dots 0.0595366 0.02382751 0.0952457 0.0010859 ## ## $platform ## diff lwr upr p adj ## ios-android -0.1229602 -0.1586693 -0.08725108 0 ## ## $`trialtype:platform` ## diff lwr upr p adj ## tray:android-dots:android 0.02189299 -0.04430338 0.088089361 0.8305483 ## dots:ios-dots:android -0.16060379 -0.22680016 -0.094407418 0.0000000 ## tray:ios-dots:android -0.06342358 -0.12961995 0.002772791 0.0660908 ## dots:ios-tray:android -0.18249678 -0.24869315 -0.116300410 0.0000000 ## tray:ios-tray:android -0.08531657 -0.15151294 -0.019120202 0.0051499 ## tray:ios-dots:ios 0.09718021 0.03098384 0.163376578 0.0009357 Задание Ещё один заход к данными того самого эксперимента. Напоминалка В эксперименте испытуемые должны были запоминать слова, обозначающие объекты, а затем искать эти объекты среди похожих других. В данных у нас есть следующие переменные: resp — идентификатор респондента group — уровень категории слов для запоминания (base — базовая и super — суперординатная) memory_setsize — количество слов-категорий для запоминания visual_setsize — количество стимулов на экране поиска объектов rt — время реакции / обнаружения стимула Возьмите модель из предыдущего задания и дополните её взаимодействием факторов. Итого в модель должны быть включены факторы visual_setsize и memory_setsize, а также из взаимодействие visual_setsize:memory_setsize. В качестве зависимой переменной остаётся rt. Какие выводы можно сделать из полученной модели? 9.5 Важность аггрегации данных А теперь посмотрим на то, что мы наделали. Для этого взглянем на структуру данных: str(share) ## &#39;data.frame&#39;: 10800 obs. of 22 variables: ## $ trialtype: chr &quot;tray&quot; &quot;tray&quot; &quot;tray&quot; &quot;tray&quot; ... ## $ setsize : int 8 8 8 8 8 8 8 8 8 8 ... ## $ time1 : num 1.67 1.13 2.6 2.61 1.59 ... ## $ click1x : int -227 -69 60 199 -241 -51 99 213 -201 -70 ... ## $ click1y : int 202 231 195 213 43 59 62 46 -123 -82 ... ## $ time2 : num 1.28 1.061 0.963 0.863 0.931 ... ## $ click2x : int 14 -44 17 -26 -25 10 -29 -27 -25 -19 ... ## $ click2y : int -351 -392 -361 -356 -397 -383 -372 -353 -385 -394 ... ## $ id : int 1 1 1 1 1 1 1 1 1 1 ... ## $ platform : chr &quot;ios&quot; &quot;ios&quot; &quot;ios&quot; &quot;ios&quot; ... ## $ posx1 : int -238 -63 66 203 -243 -60 73 213 -229 -84 ... ## $ posy1 : int 202 226 217 218 59 90 66 52 -93 -79 ... ## $ posxmin1 : int -313 -138 -9 128 -318 -135 -2 138 -304 -159 ... ## $ posxmax1 : int -163 12 141 278 -168 15 148 288 -154 -9 ... ## $ posymin1 : int 127 151 142 143 -16 15 -9 -23 -168 -154 ... ## $ posymax1 : int 277 301 292 293 134 165 141 127 -18 -4 ... ## $ posx2 : int 450 450 450 450 450 450 450 450 450 450 ... ## $ posy2 : int -350 -350 -350 -350 -350 -350 -350 -350 -350 -350 ... ## $ posxmin2 : int 350 350 350 350 350 350 350 350 350 350 ... ## $ posxmax2 : int 550 550 550 550 550 550 550 550 550 550 ... ## $ posymin2 : int -425 -425 -425 -425 -425 -425 -425 -425 -425 -425 ... ## $ posymax2 : int -275 -275 -275 -275 -275 -275 -275 -275 -275 -275 ... У нас аж 10800 наблюдений, а среди переменных есть id, которая идентификатор испытуемого. unique(share$id) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## [26] 26 27 28 29 30 31 32 33 34 35 36 Наблюдаем, что у нас 36 испытуемых. И если мы напишем немного кода, то посмотрим, сколько у нас было наблюдений на каждое экспериментальное условие: library(data.table) share &lt;- data.table(share) # делаем data.table, чтобы синтаксис работал share[, .N, by=.(id, trialtype, setsize, platform)] Видим, что у нас 50 проб на каждое условие. А содержательно для нас каждый испытуемый — это отдельное наблюдение, а эти 50 проб мы делали для более точных измерений. То есть, наши данные надо аггрегировать, усреднив наблюдения по каждому респонденту. Зачем? Чтобы у нас не случилось косяков с мощностью. R не знает о группировке наших данных, поэтому считает каждую строчку датасета отдельным наблюдением. В результате этого у нас возрастает статистическая мощность теста, но это искусственное увеличение мощности. Усредним данные и сравним результаты: share_aggregated &lt;- share[, .(mean_rt = mean(time1)), by = .(id, trialtype, setsize, platform)] share_aggregated fit5 &lt;- aov(mean_rt ~ trialtype * platform, share_aggregated) summary(fit5) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trialtype 1 0.19 0.1914 0.988 0.3214 ## platform 1 0.82 0.8164 4.213 0.0413 * ## trialtype:platform 1 0.08 0.0765 0.395 0.5304 ## Residuals 212 41.08 0.1938 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Ого! Значимость пропала! Для сравнения вспомним, какие результаты были без усреднения: summary(fit4.1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trialtype 1 10 9.57 10.68 0.00109 ** ## platform 1 41 40.82 45.56 1.56e-11 *** ## trialtype:platform 1 4 3.83 4.27 0.03882 * ## Residuals 10796 9674 0.90 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Наблюдаем, что воистину значимость одного фактора и взаимодействия пропала. Это как раз потому, что у нас упала мощность, но эти результаты корректнее отражают реальное положение дел. 9.6 Итоги Мы с вами познакомились с одним из самых популярных методов анализа данных. Конечно, мы не вникали с его детали и не смогли охватить все возможности. Например, за рамками остались такие темы как контрасты и дисперсионный анализ в повторными измерениями. Однако уверенно разобравшись в рассмотренных моделях, вы сможете погрузить в более сложные методы. Удачи! По теореме умножения вероятностей.↩︎ Справедливости ради стоит отметить, что дисперсионный анализ очень часто используется для анализа экспериментальных данных, поэтому поработаем с ними.↩︎ "]]
