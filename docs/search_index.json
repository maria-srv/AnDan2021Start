[["index.html", "АнДан 2021: стартовая программа 1 О курсе", " АнДан 2021: стартовая программа А. Ангельгардт, М. Серветник, Ю. Мартысенко, А. Котликова 1 О курсе Материалы для курса школы Анализа данных: стартовая. Пакеты: install.packages(c(&quot;data.table&quot;, &quot;ggplot2&quot;, &quot;reshape2&quot;)) "],["введение-в-r.html", "2 Введение в R 2.1 Общее 2.2 Типы данных 2.3 Структуры данных 2.4 Функции и простые действия с данными 2.5 Задания для тренировки", " 2 Введение в R 2.1 Общее R — скриптовый язык. Важно помнить, что код в нем выполняется построчно. Многие функции в нем векторизованы, то есть выполняются ко всему списку объектов, что даются ему на вход. Это вы потом увидите на примерах. В R есть множество пакетов (помните, вы вводили install.packages() при подготовке к школе?), в которых реализованы наиболее эффективные алгоритмы работы с данными, именно поэтому он так удобен для анализа. 2.2 Типы данных С некоторыми типами данных мы уже познакомились выше. Все они, кроме фактора, более-менее стандартны для всех языков программирования. 2.2.1 Целое число — integer 6/3 ## [1] 2 Например, можно что-нибудь посчитать как на калькуляторе. Чтобы определить тип данных есть команда class: b &lt;- 6 ** 2 class(b) ## [1] &quot;numeric&quot; Ой, у нас вышло, что эта переменная не целочисленная, а numeric — число с плавающей запятой. Хранение в памяти такого числа требует больше ресурсов. Можно перевести переменную в integer: b &lt;- 6 ** 2 b &lt;- as.integer(b) class(b) ## [1] &quot;integer&quot; 2.2.2 Число с плавающей запятой — double Этот формат — для всех целочисленных и дробных значений. 2.5 + 3.3 ## [1] 5.8 Результат деления всегда будет числом с плавающей точкой, даже если результат целочисленный: c &lt;- b / 2 paste(c) ## [1] &quot;18&quot; class(c) ## [1] &quot;numeric&quot; Основные операторы для арифметических действий: + — сложить - — вычесть * — умножить ** или ^ — возвести в степень %% — получить остаток от деления %/% — получить целочисленную часть от деления sqrt() — извлечь квадратный корень round() — округлить 2.2.3 Комплексные числа — complex Кто знает, тот поймет. 2.2.4 Символьный тип данных(строки) — character s1 &lt;- &quot;Я строка&quot; s2 &lt;- &#39;И я строка&#39; s1 ## [1] &quot;Я строка&quot; s2 ## [1] &quot;И я строка&quot; В кавычках '' или \"\" заключены символьные данные. Следите за тем, чтобы не пропустить открывающие/закрывающие кавычки. s3 &lt;- &quot;Экранирование \\&quot;лишних\\&quot; кавычек&quot; paste(s3) ## [1] &quot;Экранирование \\&quot;лишних\\&quot; кавычек&quot; R (как и другие языки) может читать текст вместе со специальными управляющими символами (такими, например, являются кавычки ' и \" или бэкслэш \\), а может читать просто как текст. Специальные символы можно экранировать, добавив перед ними бэкслэш. Выполнять мат. операции с символьными значениями нельзя. &#39;a&#39; * 3 ## Error in &quot;a&quot; * 3: non-numeric argument to binary operator Для соединения символьных и числовых данных часто необходимо превратить числовое значение в символьное. У тебя есть переменная: age - с твоим возрастом. Попробуй вывести на экран с помощью функции paste() фразу “Мой возраст:” и свой возраст. Не забудь превратить число возраста в строку с помощью функции as.character(). В paste просто перечисляй строки через запятую. 2.2.5 Факторы Ну а что же такое факторы # ://////////++++++++++++++++++++++++++++++++++//////:::::::::::::/::::: # //////////+++++++++++++++++++++++++++++++ossoo++/////++syyo+//:////::: # ///////////++++++++++++++++++++++++++++//:/+shhhhhhddddddddhyo//////:: # ////////////++++/++++++++////+++ooo+++syyyysssyyyhdmmmdddddhhy+//////: # ////////////////+osyhddho:::osshddddhhysyhhyyyyyhysosydmmmmddhy//////: # //////////////+syhdmmmdh+/oyyhdddhhhhhdddhso+++syhhyo+/+shdmdddo/////: # ///////+oyhhhhdmmmmmmhs//shhdhssssysooooo++/+ss//+oooso/::/+yddh/////: # ///osyhmmmmmmmmmmmmho::/osyhyyssoossyyssssyhhy/:/shhhyysso+/:/shs///:: # /+hmddmmmmmmmmmmmds:-::++oys+//sys+//oyooshyyho+oydmdddddddyo+:+hho/:: # +smdmmmmmmmmmmmmh+---::++//+oydmmddsoohsoyhyyhyyyhdmdhhydddddyo/sso/:: # +ohmmmmmmmmmmmds:---::///shdmmdmmmddhhhssyyhhhhyyyyhdy+hdhddddy+/:::-- # ++odmmmmmmmmmd+------::ohddddddhhdmddhhhdddddddddhsssssydhddddh+/:---- # +++odmmmmmmmd+------:/ohhddddddhyyddhhdmdhdhhhdhdddhyssyhdddddho+:---. # ++++ymmmmmmmh:-.--::+shhddmydhddhhysyhmdhhdmhhhddddddhhyyyddddyoo:.... # ++++odmmmmmdy-----:/shhhhddddddhhssshdmddhhdhdyhhhdddddddhhddhs++/.... # ++++++ydddddy----::+yddhhhhhhyyhsoshmddddhhhdhhhddddddddddddhhyo+/:... # /++++++oshhhs-----:/shhyyhdddddyosdmddddhhhhhddhyyhhhddddddddhyys/:-.. # ++++++++++/o+--.-----/+sssyyyhyoydmmddddhhhhhhdmdddddddddddddddhyo::-. # +++++++++/--:-..-+/..-:+osssyyssdmmdddddhhyhdddhyyhdddddddddddddhs//-- # /++++++++/---...-/:.-:+o++/+ssshmdddddddhhhddhhdddddddmdddddddddho//:- # +++++++++/:::-..-:---/ooo+/+ysydmddddddddddmddddddddddmmmddddddds+/::: # ++++++++:-...-....--:+yysoshhhdmmmmmddddddmdddddddddddmmmmmmmdddoo/::: # +++++++/-..`..-...-:/+syyhdddmmddddddddddmmdddmmmmmdddmmmmmmmmdyo/:::: # ++++++/:-.....--.---:/oyhddddddhhdddddmmmmmddmmmmmmdddmmmmmdddyo//:::/ # /+++++/--.--...------:/ohddmmmdddddmmmmmmdmmmmmmmmmmddmmmmmddys+///:/: # //////:....--...-:::::/+shhdddmmmmmmmmdmmmmmmmmmmmdmmmmmmmdhyo//:/::/: # /////:.......--..-:::::/+shddmddmmmmdmmmmmmmmmmmmmmmmmmddhhso////:///: # :///:.``.....---..-::::/+osyhdmmmmmmmmmmmmmmmmddmmmmmdyyyyo+////::/::: # ::::-.```...--::-.------::/+syhdddddddmdddhyyyyhddmmhso+++/:://::::::: # ::::.``````..-:::--..----::/+oossssyhddyo+:://oyhhys+:::/::::/::::::-- # :::-.```````....-:--...------:::::/oso/-----::/++//:--::::://::::---.. # :::-`````````....----....--....-------......--::::::/::::://::::--.... # -::-.````.......--:---......-......------:::/+++++//////:::::---...... Фактор был придуман для облегчения работы с качественными переменными, он может быть представлен как строка, и как число. Например, возьмем последовательность букв алфавита f &lt;- factor(LETTERS) На них можно посмотреть как на строковые данные: as.character(f) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot; &quot;I&quot; &quot;J&quot; &quot;K&quot; &quot;L&quot; &quot;M&quot; &quot;N&quot; &quot;O&quot; &quot;P&quot; &quot;Q&quot; &quot;R&quot; &quot;S&quot; ## [20] &quot;T&quot; &quot;U&quot; &quot;V&quot; &quot;W&quot; &quot;X&quot; &quot;Y&quot; &quot;Z&quot; И как на числовые: as.numeric(f) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## [26] 26 Если нам нужно каждому варианту ответа присвоить код (номер), то это удобно сделать с помощью фактора: dogs &lt;- c(&quot;мопс&quot;, &quot;пудель&quot;, &quot;овчарка&quot;, &quot;йорк&quot;, &quot;мопс&quot;, &quot;мопс&quot;) f_dogs &lt;- factor(dogs) f_dogs ## [1] мопс пудель овчарка йорк мопс мопс ## Levels: йорк мопс овчарка пудель as.numeric(f_dogs) ## [1] 2 4 3 1 2 2 У факторов есть уровни и они сортируются по алфавиту levels(f_dogs) ## [1] &quot;йорк&quot; &quot;мопс&quot; &quot;овчарка&quot; &quot;пудель&quot; str(f_dogs) ## Factor w/ 4 levels &quot;йорк&quot;,&quot;мопс&quot;,..: 2 4 3 1 2 2 Допустим, мы хотим отсортировать уровни по-своему f_dogs2 &lt;- factor(dogs, levels=c(&quot;овчарка&quot;, &quot;мопс&quot;, &quot;йорк&quot;, &quot;пудель&quot;)) f_dogs2 ## [1] мопс пудель овчарка йорк мопс мопс ## Levels: овчарка мопс йорк пудель str(f_dogs2) ## Factor w/ 4 levels &quot;овчарка&quot;,&quot;мопс&quot;,..: 2 4 1 3 2 2 str(f_dogs) ## Factor w/ 4 levels &quot;йорк&quot;,&quot;мопс&quot;,..: 2 4 3 1 2 2 Изменение уровней фактора levels(f_dogs) &lt;- c(&quot;йорк&quot;, &quot;шарпей&quot;, &quot;овчарка&quot;, &quot;пудель&quot;) #меняем мопсов на шарпеев f_dogs ## [1] шарпей пудель овчарка йорк шарпей шарпей ## Levels: йорк шарпей овчарка пудель 2.2.6 Ordered factor (упорядоченный) Допустим мы хотим знать, какая собака больше (чуть более реальный пример: размер одежды S-M-L и т.д. как фактор) f_dogs[1] &lt; f_dogs[2] ## Warning in Ops.factor(f_dogs[1], f_dogs[2]): &#39;&lt;&#39; not meaningful for factors ## [1] NA o_f_dogs &lt;- factor(f_dogs, ordered = TRUE, levels = c(&quot;йорк&quot;, &quot;пудель&quot;, &quot;шарпей&quot;, &quot;овчарка&quot;)) o_f_dogs ## [1] шарпей пудель овчарка йорк шарпей шарпей ## Levels: йорк &lt; пудель &lt; шарпей &lt; овчарка o_f_dogs[1] &lt; o_f_dogs[2] ## [1] FALSE При неупорядоченных факторах мы получили NA, при упорядочивании мы получили возможность сравнивать разные уровни. В нашей таблице у нас есть возможность представить строковые значения как факторы с помощью флажка stringsAsFactors = TRUE (по умолчанию он равен FALSE) data &lt;- read.table(file = &quot;about_us_eng.csv&quot;, sep=&quot;,&quot;,header=TRUE, stringsAsFactors = TRUE) data$beard ## [1] no no no no no no yes no no no no no no no no no no no no ## [20] yes no no no no no no no no no no no no no yes no ## Levels: no yes 2.2.7 Логические - boolean Логические данные имеют всего два вида: TRUE либо FALSE. Они часто возникают, когда мы хотим проверить какое-то условие: a == b ## Error in eval(expr, envir, enclos): object &#39;a&#39; not found Операторы сравнения будут те же, что ф вормальной логике: == - равно != - не равно &gt; , &lt; - больше, меньше &gt;= - больше или равно &lt;= - меньше или равно Для объединения условий также есть специальные символы: &amp;&amp; или &amp; - и, ответ правда если оба условия правда ||' или|- или, ответ правда если хотя бы одно условие правда!` - не, отрицание выражения, смена правды на ложь и наоборот У тебя есть две переменных: d &lt;- 24, e &lt;- 41. Проверьте условие: остаток от деление нацело этих двух переменных больше 0. Кстати, остаток от деления на 2 помогает проверить число на четное или нечетное. С логическими данными можно выполнять мат. операции, тогда TRUE — это 1, FALSE — это 0: c + TRUE ## [1] 19 2.2.8 Есть еще такой тип данных, как даты. В R есть отдельные функции для облегчения работы с датами. Например, можно посчитать сколько дней прошло между двумя заданными датами. Как же их задавать? date1 &lt;- as.Date(&quot;2019-07-24&quot;) date1 ## [1] &quot;2019-07-24&quot; Можно писать другие форматы, но к ним нужны пояснения date2 &lt;- as.Date(&quot;07/24/2019&quot;, format = &quot;%m/%d/%Y&quot;) date2 ## [1] &quot;2019-07-24&quot; date1 ## [1] &quot;2019-07-24&quot; date3 &lt;- as.Date(&quot;24.07.2019&quot;, format = &quot;%d.%m.%Y&quot;) date3 ## [1] &quot;2019-07-24&quot; date1 ## [1] &quot;2019-07-24&quot; date4 &lt;- as.Date(&quot;07/24/19&quot;, format = &quot;%m/%d/%y&quot;) date4 ## [1] &quot;2019-07-24&quot; date1 ## [1] &quot;2019-07-24&quot; Вот так можно посмотреть список всех этих сокращений от даты и от времени (например, большая M — это минуты) `?`(strptime) Мы можем узнать системное время (определяется по твоему компу) и сравнить его с переменной Sys.Date() ## [1] &quot;2021-08-01&quot; date1&lt;Sys.Date() ## [1] TRUE 2.3 Структуры данных 2.3.1 Вектор Это самая базовая, простая структура. Вектор — это последовательность элементов одного и того же типа. Вектор можно создать командой конкатенации с(): a&lt;-c(1,2,3,3,2,1) a ## [1] 1 2 3 3 2 1 С числовыми векторами можно осуществлять самые разные преобразования. Благодаря векторизованности языка R, нам нет необходимости писать цикл, который будет применять операции к каждому елементу вектора. R это сделает сам. арифметические операции a*2 ## [1] 2 4 6 6 4 2 a*c(1,2,3,4) ## Warning in a * c(1, 2, 3, 4): longer object length is not a multiple of shorter ## object length ## [1] 1 4 9 12 2 2 a-5 ## [1] -4 -3 -2 -2 -3 -4 a^2 ## [1] 1 4 9 9 4 1 a/2 ## [1] 0.5 1.0 1.5 1.5 1.0 0.5 Как видите, чтобы перемножить вектора, они должны быть одинаковой длины: a*c(1,2,3,4,5,6) ## [1] 1 4 9 12 10 6 операции сравнения (важно! = — оператор присваивания! для сравнения используйте ==) a&lt;=1 ## [1] TRUE FALSE FALSE FALSE FALSE TRUE a!=1 ## [1] FALSE TRUE TRUE TRUE TRUE FALSE a==1 ## [1] TRUE FALSE FALSE FALSE FALSE TRUE В результате мы получаем вектор логических значений. Запомним, это пригодится нам далее. Вспомним, что в логических переменных TRUE — это 1, FALSE — это 0 tf = c(TRUE,TRUE,FALSE,TRUE) tf == 1 ## [1] TRUE TRUE FALSE TRUE tf == 0 ## [1] FALSE FALSE TRUE FALSE sum(tf) ## [1] 3 sum(tf == 0) ## [1] 1 Наш датасет, хранящийся в data, имеет 15 столбиков. Каждый столбик — это вектор. Мы можем извлекать их оттуда через знак $: data$height ## [1] 165 180 161 164 180 170 170 173 163 168 165 164 166 NA 173 173 183 170 185 ## [20] 169 185 172 158 185 168 175 162 182 164 167 175 167 168 179 172 NA — это пропущенное значение: data$height[1:10]==164 ## [1] FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE data$height[1:10] — это выбор первых десяти значений из вектора, которые мы протом проверяем на равенство 164 Мы можем посчитать частоту каждого значения с помощью функции table() table(data$height) ## ## 158 161 162 163 164 165 166 167 168 169 170 172 173 175 179 180 182 183 185 ## 1 1 1 1 3 2 1 2 3 1 3 2 3 2 1 2 1 1 3 Вспомним, что мы можем совершать арифметические действия с логическими переменными и посчитаем, сколько человек выше 175см: sum(c(TRUE,TRUE,FALSE,TRUE)) ## [1] 3 sum(data$height&gt;175) ## [1] NA Опа, посчитать не получилось. Это потому что каждый элемент вектора нужно сравнить с 175, а для пропущенного значения это невозможно. давайте просто не будем его учитывать: sum(data$height&gt;175, na.rm=TRUE) ## [1] 8 Посчитаем среднее количество глаз на каждого из нас: mean(data$eye_number) ## [1] 5.057143 Все понятно, мы — ангелы Гистограмма распределения размеров обуви и самый большой размер: shoes&lt;-data$shoe_size hist(shoes) max(shoes) ## [1] 45 Вектор может быть именованным и к каждому элементу тогда можно обратиться по имени: b&lt;-c(&quot;e&quot;=1,&quot;f&quot;=2,&quot;g&quot;=3) b ## e f g ## 1 2 3 b[&#39;f&#39;] ## f ## 2 names(b) ## [1] &quot;e&quot; &quot;f&quot; &quot;g&quot; А если имени нет? Тогда можно по номеру в последовательности: b[2] ## f ## 2 Или сразу по вектору номеров! NB! В R нумерация элементов начинается с 1, но не в каждом языке программирования так. b[c(1,3)] ## e g ## 1 3 Или по логическому вектору отфильтровать другой вектор: b[c(TRUE,FALSE,TRUE)] ## e g ## 1 3 Мы можем выбрать не одну, а несколько колонок из таблицы с помощью вектора: data[c(&quot;eye_color&quot;,&quot;gorgeous&quot;)] 2.3.2 Матрицы Матрица - такая структура данных, где есть столбики и строки. Вектор может быть превращён в матрицу. Для этого надо сказать, сколько в нём строчек или столбиков. a ## [1] 1 2 3 3 2 1 matrix(a[1:2],nrow=3) ## Warning in matrix(a[1:2], nrow = 3): data length [2] is not a sub-multiple or ## multiple of the number of rows [3] ## [,1] ## [1,] 1 ## [2,] 2 ## [3,] 1 R выдает предупреждение. Видишь, что случилось? Из нашего вектора из двух элементов a[1:2] мы создали матрицу с тремя строками. Что будет, если сделать больше строк? matrix(a[1:2],nrow=6) ## [,1] ## [1,] 1 ## [2,] 2 ## [3,] 1 ## [4,] 2 ## [5,] 1 ## [6,] 2 Никакой ругани)) В матрице из раза в раз повторяются 1 и 2 элементы вектора. Не ругается R потому что 6 рядок кратно 2. Так как 3 строки не кратны 2, то ровненько повторить элементы не получилось, о чем R нас предупредил. Кстати, это была одночастная матрица. Она бывает такой или такой matrix(a,nrow=2,byrow=TRUE) ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 3 2 1 А это уже многочастная матрица. Спасибо, Икеа! matrix(a,nrow=2,byrow=FALSE) #что будет? ## [,1] [,2] [,3] ## [1,] 1 3 2 ## [2,] 2 3 1 Как видите, можно заполнять матрицу элементами построчно или по столбцам. Пустую матрицу тоже можно создать matrix() ## [,1] ## [1,] NA Тебе, наверняка, известна корреляционная матрица ddd &lt;- data[c(&quot;height&quot;,&quot;eye_number&quot;,&quot;gorgeous&quot;)] cor1&lt;-round(cor(ddd, use=&quot;pairwise.complete.obs&quot;),3) cor1 ## height eye_number gorgeous ## height 1.000 -0.105 -0.153 ## eye_number -0.105 1.000 -0.046 ## gorgeous -0.153 -0.046 1.000 К элементам матрицы можно обращаться по координатам: cor1[1,] ## height eye_number gorgeous ## 1.000 -0.105 -0.153 cor1[1,1] ## [1] 1 или опять-таки - по именам! cor1[c(&quot;AGE&quot;,&quot;APPEAL1&quot;)] ## [1] NA NA dimnames(cor1) ## [[1]] ## [1] &quot;height&quot; &quot;eye_number&quot; &quot;gorgeous&quot; ## ## [[2]] ## [1] &quot;height&quot; &quot;eye_number&quot; &quot;gorgeous&quot; 2.3.3 Списки Список (list) - структура данных, которая может включать в себя набор из данных разного формата, например, вектор и строку, число и матрицу и пр. u0 &lt;- list(&#39;A&#39;, 1) u0 ## [[1]] ## [1] &quot;A&quot; ## ## [[2]] ## [1] 1 Мы можем посмотреть структуру объекта: u &lt;- list(&quot;A&quot;, 1, list (&quot;A&quot;, T)) str(u) ## List of 3 ## $ : chr &quot;A&quot; ## $ : num 1 ## $ :List of 2 ## ..$ : chr &quot;A&quot; ## ..$ : logi TRUE Представим, что список — это мешочек. Функция unlist() вытаскивает предметы из мешочка и просто выставляет их на стол uu &lt;- c(list(&quot;a&quot;,5),list(list(5))) str(uu) ## List of 3 ## $ : chr &quot;a&quot; ## $ : num 5 ## $ :List of 1 ## ..$ : num 5 unlist(u) ## [1] &quot;A&quot; &quot;1&quot; &quot;A&quot; &quot;TRUE&quot; Можно превратить список в другие структуры данных, например, таблицу или матрицу. u &lt;- list(&quot;a&quot;=c(1,2),&quot;b&quot;=c(3,4)) str(u) ## List of 2 ## $ a: num [1:2] 1 2 ## $ b: num [1:2] 3 4 u2 &lt;- as.data.frame(u) u3 &lt;- as.matrix(u2) u4 &lt;- as.matrix(u) Найдите эти переменные в глобальном окружении. Выглядят они похоже, но описания у них в глобальном окружении разные, как и принципы работы с ними. Элементам списка также можно давать имена, а не обращаться к ним по номерам: u &lt;- list(&#39;a&#39;, matrix(c(1, 2))) names(u) &lt;- c(&#39;meow&#39;, &#39;meow_num&#39;) u ## $meow ## [1] &quot;a&quot; ## ## $meow_num ## [,1] ## [1,] 1 ## [2,] 2 Выведем второй элемент списка и посмотрим, какой тип данных он имеет: u[2] ## $meow_num ## [,1] ## [1,] 1 ## [2,] 2 class(u[2]) ## [1] &quot;list&quot; Второй элемент этого списка был превращен из матрицы с одной колонкой в вертикальный список с именем meow_num, состоящий из одного элемента - матрицы. Чтобы нам добраться до самого второго элемента именнованного списка - матрицы - нужно использовать двойные скобки [[x]]. Это особенность синтаксиса. u[[2]] ## [,1] ## [1,] 1 ## [2,] 2 class(u[[2]]) ## [1] &quot;matrix&quot; &quot;array&quot; Либо обратиться не по индексу, а по имени: u$meow ## [1] &quot;a&quot; 2.3.4 Дата фреймы Это наши любимые таблицы. В каждом столбце находятся элементы одного типа. В переменной data находится наш датафрейм. Как и с векторами, есть три базовых способа фильтрации датафреймов: с помощью вектора с адресами (номерами строк) data10_1&lt;-data[1:10,] с помощью вектора с именами data10_1&lt;-data[c(1:5,7:10),c(&quot;soft_drink&quot;,&quot;hot_drink&quot;)] С помощью логического вектора (rep() - функция, генерирующая повторяющиеся значения) data10_1&lt;-data[c(rep(TRUE,10),rep(FALSE,25)),] Подробнее о логической фильтрации будет в следующем уроке. 2.4 Функции и простые действия с данными Для начала мы можем узнать тип данных, из которых состоит вектор ch &lt;- c(&#39;apple&#39;, &#39;pear&#39;, &#39;banana&#39;, &#39;orange&#39;) ch ## [1] &quot;apple&quot; &quot;pear&quot; &quot;banana&quot; &quot;orange&quot; typeof(ch) ## [1] &quot;character&quot; Сколько уникальных элементов содержится в векторе? ch2 &lt;- c(&#39;apple&#39;, &#39;pear&#39;, &#39;banana&#39;, &#39;orange&#39;, &#39;apple&#39;, &#39;apple&#39;) unique(ch2) ## [1] &quot;apple&quot; &quot;pear&quot; &quot;banana&quot; &quot;orange&quot; sort(ch2) #сортировка объектов ## [1] &quot;apple&quot; &quot;apple&quot; &quot;apple&quot; &quot;banana&quot; &quot;orange&quot; &quot;pear&quot; Фильтруем все, что по алфавиту идет раньше ‘ba’. При этом считается, что ‘ba..’ идет позже просто ‘ba’ ch[ch&gt;&quot;ba&quot;] ## [1] &quot;pear&quot; &quot;banana&quot; &quot;orange&quot; Сколько символов в элементах вектора? length(ch) ## [1] 4 nchar(ch) ## [1] 5 4 6 6 Поиск элементов grep(&#39;b&#39;, ch, value=TRUE) #дает само значение ## [1] &quot;banana&quot; grep(&#39;b&#39;, ch, value=FALSE) #дает порядковый номер элемента ## [1] 3 ch[grep(&#39;b&#39;, ch, value=FALSE)] #определяет значение по порядковому номеру элемента ## [1] &quot;banana&quot; Bывод элемента по номеру ch2[1] ## [1] &quot;apple&quot; Исключение элемента по номеру ch2[-4] ## [1] &quot;apple&quot; &quot;pear&quot; &quot;banana&quot; &quot;apple&quot; &quot;apple&quot; ch[-1] ## [1] &quot;pear&quot; &quot;banana&quot; &quot;orange&quot; ch2[-c(1, 2)] ## [1] &quot;banana&quot; &quot;orange&quot; &quot;apple&quot; &quot;apple&quot; Разбиение по разделителю (пробел) text &lt;- &#39;Ну-ка фрукты встаньте в ряд&#39; strsplit(text, &#39; &#39;) ## [[1]] ## [1] &quot;Ну-ка&quot; &quot;фрукты&quot; &quot;встаньте&quot; &quot;в&quot; &quot;ряд&quot; a &lt;- strsplit(text, &#39; &#39;) typeof(a) ## [1] &quot;list&quot; typeof(a[1]) ## [1] &quot;list&quot; Строка с пропусками вида character и digit sprintf(&quot;%s отправляется в %d часов&quot;, &quot;Электричка&quot;, 12) ## [1] &quot;Электричка отправляется в 12 часов&quot; sprintf(&quot;%s отправляется в %d часов&quot;, rep(&quot;Электричка&quot;, 2), c(12, 13)) ## [1] &quot;Электричка отправляется в 12 часов&quot; &quot;Электричка отправляется в 13 часов&quot; Вытащить кусок строки substr(&quot;Я маленькая лошадка&quot;, start=3, stop=12) ## [1] &quot;маленькая &quot; Заменить кусок внутри строки sub(&quot;маленькая&quot;, &quot;большая&quot;, &quot;Я маленькая лошадка&quot;) ## [1] &quot;Я большая лошадка&quot; sub(&quot;маленькая&quot;, &quot;большая&quot;, &quot;Я маленькая маленькая лошадка&quot;) #заменяет только первое появление подстроки ## [1] &quot;Я большая маленькая лошадка&quot; gsub(&quot;маленькая&quot;, &quot;большая&quot;, &quot;Я маленькая маленькая лошадка&quot;) ## [1] &quot;Я большая большая лошадка&quot; Отбор элементов по номеру позиции (индекс) и по его значению d &lt;- c(1,2,6,4) d&gt;2 ## [1] FALSE FALSE TRUE TRUE d[d&gt;2] #сами элементы ## [1] 6 4 which(d&gt;2) #номера их позиций ## [1] 3 4 Можно проверить, принадлежат ли элементы вектора определенному типу данных int_num&lt;-c(1,2,3,4000) is.integer(int_num) ## [1] FALSE typeof(int_num) ## [1] &quot;double&quot; К целочисленному выражению элементы вектора можно привести несколькими способами: int_num&lt;-as.integer(c(1,2,3,4000)) int_num&lt;-c(1L,2L,3L,4000L) #сохраняет как целые as.integer(214748364.7) ## [1] 214748364 as.integer(2147483648) #слишком большое число, не может хранить ## Warning: NAs introduced by coercion to integer range ## [1] NA as.integer(-2147483647) ## [1] -2147483647 as.integer(-2147483648) ## Warning: NAs introduced by coercion to integer range ## [1] NA Для больших чисел мы вынуждены использовать формат с плавающей точкой, он может хранить больше информации as.double(&quot;10000998843483274893274892374238947273&quot;) ## [1] 1.0001e+37 Включение scientific notation options(scipen=999) 2^64 ## [1] 18446744073709551616 90071992547409923 ## [1] 90071992547409920 options(scipen=0) 2^64 ## [1] 1.844674e+19 90071992547409923 ## [1] 9.007199e+16 Numeric - общее название для числовых данных, включает в себя и double, и integer. Подробнее о форматах можно посмотреть в справке ?double и ?integer. numeric_num&lt;-c(1,2,2.5) is.integer(numeric_num) ## [1] FALSE is.integer(int_num) ## [1] TRUE is.numeric(int_num) ## [1] TRUE is.numeric(numeric_num) ## [1] TRUE str(numeric_num) ## num [1:3] 1 2 2.5 is.double(numeric_num) ## [1] TRUE typeof(numeric_num) ## [1] &quot;double&quot; Объединение векторов с разнымм типами значений n &lt;- c(1,2,3) s &lt;- c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) c(n,s) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;a&quot; &quot;b&quot; &quot;c&quot; Как видите, при объединении числовой формат был переделан в строковый. Как мы узнали ранее, разные форматы можно хранить только в списках и таблицах. 2.5 Задания для тренировки Соедини значение 1 и TRUE в вектор. Что получилось? У тебя есть вектор a &lt;-c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10). Создай из него матрицу с заполнением по строкам. Выбери первый столбец. Помни, что при фильтрации в формате vec[x, y], x— это строка, y — это столбец. Список со вложенными списками subjects &lt;- list(list(‘Masha’, 18, list(39, 40)), list(‘Nastya’, 22, 41), list(‘Mitya’, 25, 46)). Выведи второй элемент третьего элемента первого списка. Что это за число? Поэкспериментируй. Не забудь про двойные кавычки [[]]. Определи среднее, сумму, максимальное и минимальное значение в векторе data$hair_length. Нарисуй гистограмму. Выведи вектор, получившийся в результате проверки каждого элемента из data$hair_length на четность/нечетность (используй остаток от целочисленного деления) Из нашей таблицы data выбери элемент, находящийся на 18 строке в 6 столбце и выведи на экран с помощью функции paste() "],["фильтрация-строк-и-столбцов-в-base-r-введение-в-data-table.html", "3 Фильтрация строк и столбцов в base R. Введение в data.table 3.1 Фильтрация строк и столбцов в base R", " 3 Фильтрация строк и столбцов в base R. Введение в data.table library(data.table) 3.1 Фильтрация строк и столбцов в base R Из прошлой главы вы узнали, как вообще выглядит RStudio, какие звери (в смысле, типы и структуры данных) в нём обитают, и даже научились фильтровать элементы векторов и дата.фреймов по индексам и по именам. Но есть ещё один очень важный способ фильтрации - это фильтрация по условию. 3.1.1 Фильтрация вектора по условию Фильтрация по условию нужна, когда вы хотите выбрать только ту часть данных, которая удовлетворяет какое-нибудь (вы не поверите) условие. Например: ваш коллега провёл эксперимент и записал возраста всех ваших испытуемых в вектор. Теперь вы хотите посчитать средний возраст испытуемых, чтобы описать его в методах будущей великой статьи, но вот незадача для исследовательского вопроса вам подходят только те, кому больше 18 и меньше 45, а ваш коллега записывал возраста всех, кто пришёл. Так что надо найти в этом векторе тех, кто слишком млад или слишком стар, и исключить их, а уж потом считать хоть среднее, хоть медиану, хоть дисперсию. Давайте для начала создадим вектор возрастов (я придумала их из головы). ages &lt;- c(25, 69, 23, 27, 32, 45, 21, 16, 19, 17, 20, 55, 27, 18, 16, 39, 14) Чтобы найти, где в нашем векторе люди, которым больше 45, мы можем воспользоваться логическим оператором “больше”: ages &gt; 45 ## [1] FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE ## [13] FALSE FALSE FALSE FALSE FALSE Первый TRUE находится на 2 месте в получившемся логическом векторе, так что мы знаем, что седьмой человек в векторе возрастов старше 45. И правда, ему (или ей) 69 лет: ages[2] ## [1] 69 Но мы же не будем каждый раз вручную искать, где в нашем логическом векторе TRUE? Конечно, не будем! Потому что этот логический вектор можно использовать для фильтрации! Фильтрация с помощью логического вектора работает просто: если на месте элемента в логическом векторе стоит TRUE, мы его включаем, а если FALSE, то не включаем. Если мы используем логический вектор, который получается в результате команды ages &gt; 45, для фильтрации нашего вектора ages, то получим следующий вектор: ages[ages &gt; 45] ## [1] 69 55 Упс, кажется, это не то, чего мы хотели! Мы включили все элементы, которые удовлетворяют нашему условию - то есть те, которые больше 45. А нам-то надо, наоборот, оставить тех, кому меньше 45! Давайте это сделаем: ages[ages &lt; 45] ## [1] 25 23 27 32 21 16 19 17 20 27 18 16 39 14 Ура! Но подростки всё ещё остались. Что делать с ними? Мы можем соединить сочетание двух логических условий с помощью логического оператора “и” - &amp;. Для начала давайте посмотрим на сам логический вектор, который у нас получается: ages &lt; 45 &amp; ages &gt; 18 ## [1] TRUE FALSE TRUE TRUE TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE ## [13] TRUE FALSE FALSE TRUE FALSE Логический оператор &amp; возвращает TRUE, только если удовлетворены оба условия - так что теперь в нашем векторе TRUE получили только те испытуемые, возраст которых нам подходит, так что именно их мы и отберём, если используем этот вектор для фильтрации. Вот так счастье! Вот так радость! Давайте же, наконец-то, узнаем средний возраст наших корректных испытуемых: correctAges &lt;- ages[ages &lt; 45 &amp; ages &gt; 18] mean(correctAges) ## [1] 25.88889 Ура! 3.1.2 Фильтрация дата.фрейма по условию Такую логику фильтрации можно применять не только к векторам, но и к любым табличным данным - например, к матрицам или дата.фреймам. Давайте загрузим наш дата.фрейм в переменную df (не забудьте указать правильную рабочую директорию - папку, в которой лежит файл у вас на компьютере) и посмотрим, как он выглядит: df &lt;- read.csv(&quot;about_us_eng.csv&quot;) str(df) ## &#39;data.frame&#39;: 35 obs. of 15 variables: ## $ height : int 165 180 161 164 180 170 170 173 163 168 ... ## $ eye_color : chr &quot;green&quot; &quot;brown&quot; &quot;blue&quot; &quot;brown&quot; ... ## $ eye_number : int 2 2 2 2 2 2 2 2 2 3 ... ## $ beard : chr &quot;no&quot; &quot;no&quot; &quot;no&quot; &quot;no&quot; ... ## $ soft_drink : chr &quot;coke&quot; &quot;coke&quot; &quot;no, thanks&quot; &quot;coke&quot; ... ## $ cats : chr &quot;this is too personal&quot; &quot;1&quot; &quot;0&quot; &quot;0&quot; ... ## $ gorgeous : int 10 10 7 10 6 10 8 8 7 9 ... ## $ siblings : int 1 2 1 0 1 3 2 1 2 0 ... ## $ hair_length: int 25 7 20 20 10 20 30 40 30 30 ... ## $ shoe_size : num 38 43 38 38 42 39 42 41 38 38 ... ## $ guitar : chr &quot;What is a guitar? A giant ukulele?&quot; &quot;I am a portable speaker with an expanded repertoire of Nashe radio&quot; &quot;I can play one song of Tsoy. The one with the four chords.&quot; &quot;I am a portable speaker with an expanded repertoire of Nashe radio&quot; ... ## $ hot_drink : chr &quot;tea&quot; &quot;shall we dance&quot; &quot;shall we dance&quot; &quot;shall we dance&quot; ... ## $ month : chr &quot;February&quot; &quot;June&quot; &quot;July&quot; &quot;November&quot; ... ## $ hogwarts : chr &quot;Hufflepuff&quot; &quot;Gryffindor&quot; &quot;Slytherin&quot; &quot;Slytherin&quot; ... ## $ dream : chr &quot;rock star&quot; &quot;rock star&quot; &quot;Rick from Rick and Morty&quot; &quot;astronaut&quot; ... Ага, прекрасно. Например, у нас в датасете есть колонка eye_number - там был вопрос “Сколько у вас глаз?”. Скорее всего, люди, которые ответили, что у них больше двух глаз, или шутники, или шестикрылые серафимы - так или иначе, давайте исключим их из нашего очень серьёзного опроса. Как мы можем это сделать? Логика здесь совершенно та же, что и в прошлом примере - мы воспользуемся логическим вектором. Для этого нам нужно вспомнить ещё два факта: во-первых, фильтровать дата.фрейм мы можем и по строкам, и по столбцам. Например, вот такая команда выберет только строки с индексами от 1 до 5 (то есть первые пять) и столбцы с индексами от 1 до 10 (то есть первые десять): df[1:5,1:10] Во-вторых, мы можем “вытащить” колонку дата.фрейма и обращаться с ней, как с вектором, с помощью знака доллара, $. Вот такая команда сохранит в переменную eyeNumberVec колонку eye_number наше дата.фрейма df: eyeNumberVec &lt;- df$eye_number eyeNumberVec ## [1] 2 2 2 2 2 2 2 2 2 3 2 2 3 2 2 2 2 2 2 ## [20] 3 2 2 2 2 2 2 2 2 4 104 2 2 2 2 2 Эту вытащенную колонку мы можем проверить на соответствие нашему условию (не больше двух глаз): eyeNumber2Below &lt;- eyeNumberVec &lt;= 2 eyeNumber2Below ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE ## [13] FALSE TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE ## [25] TRUE TRUE TRUE TRUE FALSE FALSE TRUE TRUE TRUE TRUE TRUE Каждая строка нашего дата.фрейма этот ответ одного респондента на все вопросы. Так что, если мы используем этот вектор, чтобы оставить в нашем дата.фрейме только строки, в которых у респондента не больше двух глаз, то и многоглазых респондентов в нашем дата.фрейме не останется. Это может немного запутать в самом начале: условие у нас для колонки (не больше 2 в колонке eye_number), а убираем мы строки. Раз убираем строки, то и используем наше условие в той части квадратных скобок, где строки. То есть - до запятой. dfOnly2Eyes &lt;- df[eyeNumber2Below,] Всё то же самое можно сделать, не создавая промежуточные вектора eyeNumberVec и eyeNumberVecBelow2: dfOnly2Eyes &lt;- df[df$eye_number &lt;= 2,] Часто мы хотим фильтровать данные по нескольким условиям сразу, зачастую достаточно сложным - например, давайте оставим только гриффиндорцев, у которых или очень короткие волосы (короче 10 см) или очень маленький размер ноги (меньше 38). Конечно, это всегда можно сделать в два этапа - сначала выбрать гриффиндорцев, а потом из них выбрать коротковолосых или мелконогих: dfOnlyGr &lt;- df[df$hogwarts == &quot;Gryffindor&quot;,] dfOnlySmallGr &lt;- dfOnlyGr[dfOnlyGr$hair_length &lt; 10 | dfOnlyGr$shoe_size &lt; 38] Но у нас в среде останется этот вспомогательный дата.фрейм dfOnlyGr… Давайте лучше соединим оба условия воедино - а чтобы указать, как они между собой соотносятся, воспользуемся круглыми скобкам: dfOnlySmallGr &lt;- df[df$hogwarts == &quot;Gryffindor&quot; &amp; (dfOnlyGr$hair_length &lt; 10 | dfOnlyGr$shoe_size &lt; 38),] ## Warning in df$hogwarts == &quot;Gryffindor&quot; &amp; (dfOnlyGr$hair_length &lt; 10 | ## dfOnlyGr$shoe_size &lt; : longer object length is not a multiple of shorter object ## length Красота! Задание: Уберите из дата.фрейма всех подозрительных респондентов - и тех, у кого больше двух глаз, и тех, у кого нереалистичный рост (скажем, меньше, чем 140 см, или больше, чем 220 см), если такие есть, и тех, кто ответил, что они не рождались в вопросе про месяц рождения. Задание: Создайте отдельный дата.фрейм, в котором у нас будут только люди, которые родились зимой или осенью, и попали бы в Хогвартсе или в Слизерин, или в Рейвенкло. 3.1.3 Фильтрация по результату функции Иногда мы хотим отфильтровать значения не по абсолютному условию (все респонденты, у которых больше 1 сиблинга), а по относительному (все респонденты, у которых больше сиблингов, чем в среднем в выборке). Чтобы это сделать, мы можем сравнивать значения вектора или колонки дата.фрейма с результатом какой-нибудь функции, например, mean(). Это можно сделать в две строки, сначала посчитав среднее, а потом использовав его в сравнении: meanSibs &lt;- mean(df$siblings) dfAboveMeanSibs &lt;- df[df$siblings &gt; meanSibs,] dfAboveMeanSibs &lt;- df[df$siblings &gt; mean(df$siblings),] 3.1.4 Фильтрация для группировки Часто мы хотим узнать что-нибудь про разные группы людей, которые есть в наших данных. Например, может быть, мы напоили испытуемых кофе, чаем или водой и ожидаем, что в зависимости от напитка они будут хуже или лучше решать задачи - тогда мы хотим посчитать, сколько задач в среднем решили испытуемые из каждой группы. Здесь нам тоже может пригодиться фильтрация. Давайте узнаем, сколько в средним братьев и сестёр у наших респондентов, которые в Хогвартсе попали бы на разные факультеты. Для этого мы произведём четыре отдельных фильтрации (по одной на каждый факультет), а из колонок выберем только siblings. (Если вы не помните, как пишутся факультеты, то всегда можно проверить с помощью unique(df$hogwarts) - эта команда вернёт все уникальные значения в векторе). siblingsGr &lt;- df[df$hogwarts == &quot;Gryffindor&quot;, &quot;siblings&quot;] siblingsRav &lt;- df[df$hogwarts == &quot;Ravenclaw&quot;, &quot;siblings&quot;] siblingsSl &lt;- df[df$hogwarts == &quot;Slytherin&quot;, &quot;siblings&quot;] siblingsHuff &lt;- df[df$hogwarts == &quot;Hufflepuff&quot;, &quot;siblings&quot;] И теперь можно воспользоваться функцией mean(), чтобы посчитать среднее значение каждого вектора: mean(siblingsGr) ## [1] 1.333333 mean(siblingsRav) ## [1] 1.214286 mean(siblingsSl) ## [1] 0.8333333 mean(siblingsHuff) ## [1] 0.6666667 Задание: Воспользуйтесь функцией max(), чтобы найти самого высокого человека для каждого уровня игры на гитаре. Такой подход, конечно, не самый эффективный - если у вас всего четыре категории, то ничего страшного, но что если у вас их, например, сто? Сразу хочется как-то это дело автоматизировать, и сейчас мы научимся это делать. Но перед этим я хочу дать вам совет: иногда вы не будете помнить, как что-то сделать эффективно (может быть, на хакатоне в субботу у вас будет такая проблема) - и тогда нет никакого зашквара в том, чтобы сделать, как можете. Эффективный код это прекрасно, но самое прекрасное это код, который работает и делает то, что вам нужно :) Эффективность приходит с опытом, так что пока я бы не советовала переживать о ней слишком сильно. 3.1.5 Введение в data.table Дата.фрейм это структура данных, которая по умолчанию встроена в R. Но большинство людей в своей реальной работе с данными используют одну из двух внешних библиотек: или data.table, или dplyr. Обе этих библиотеки имеют свою структуру для табличных данных (собственно, data.table в первой, tibble во второй) с расширенным функционалом. Ходят слухи, что если зайти в чат про R в пятницу вечером, там будут спорить или про R vs. Python, или про data.table vs. dplyr. У каждой библиотеки есть свои сильные и слабые стороны (data.table быстрее и лаконичнее, с dplyr получается более “читаемый” код). Среди организаторов АнДана есть сторонники обеих библиотек (и на Питоне многие из нас тоже пишут, кстати :D). Лично я (Маша) считаю, что важно хорошо знать хотя бы одну - в целом, любую, а со второй, если надо, дальше можно разобраться. В этом курсе мы с вами будем пользоваться data.table. Итак, как же воспользоваться внешней библиотекой? Для этого вам нужно будет выполнить две команды. Во-первых, библиотеку нужно установить с помощью команды install.packages(). Обратите внимание, что имя библиотеки пишется в кавычках: install.packages(&#39;data.table&#39;) Устанавливать библиотеку нужно один раз, и если вы молодечик, то сделали это до школы :) Во-вторых, библиотеку нужно подгрузить (другими словами, активировать) с помощью команды library(). Это нужно делать в начале каждой рабочей сессии - то есть, каждый раз, когда вы открываете RStudio. Обычно принято декларировать все библиотеки, которые вы используете в скрипте, в самом верху скрипта (если вы проскроллите наверх, то увидите, что я так и сделала). Здесь имя библиотеки пишется без кавычек: library(data.table) Создать дата.тейбл с нуля можно так же, как и дата.фрейм, только используя функцию data.table(): dt &lt;- data.table(number = 1:5, name = c(&quot;Masha&quot;, &quot;Sasha&quot;, &quot;Pet&#39;ka&quot;, &quot;Dasha&quot;, &quot;Vladimir Petrovich&quot;)) Превратить имеющийся дата.фрейм в дата.тейбл - с помощью функции as.data.table(): dt &lt;- as.data.table(df) А загрузить csv-документ сразу в дата.тейбл можно с помощью функции fread(): dt &lt;- fread(&quot;about_us_eng.csv&quot;) str(dt) ## Classes &#39;data.table&#39; and &#39;data.frame&#39;: 35 obs. of 15 variables: ## $ height : int 165 180 161 164 180 170 170 173 163 168 ... ## $ eye_color : chr &quot;green&quot; &quot;brown&quot; &quot;blue&quot; &quot;brown&quot; ... ## $ eye_number : int 2 2 2 2 2 2 2 2 2 3 ... ## $ beard : chr &quot;no&quot; &quot;no&quot; &quot;no&quot; &quot;no&quot; ... ## $ soft_drink : chr &quot;coke&quot; &quot;coke&quot; &quot;no, thanks&quot; &quot;coke&quot; ... ## $ cats : chr &quot;this is too personal&quot; &quot;1&quot; &quot;0&quot; &quot;0&quot; ... ## $ gorgeous : int 10 10 7 10 6 10 8 8 7 9 ... ## $ siblings : int 1 2 1 0 1 3 2 1 2 0 ... ## $ hair_length: int 25 7 20 20 10 20 30 40 30 30 ... ## $ shoe_size : num 38 43 38 38 42 39 42 41 38 38 ... ## $ guitar : chr &quot;What is a guitar? A giant ukulele?&quot; &quot;I am a portable speaker with an expanded repertoire of Nashe radio&quot; &quot;I can play one song of Tsoy. The one with the four chords.&quot; &quot;I am a portable speaker with an expanded repertoire of Nashe radio&quot; ... ## $ hot_drink : chr &quot;tea&quot; &quot;shall we dance&quot; &quot;shall we dance&quot; &quot;shall we dance&quot; ... ## $ month : chr &quot;February&quot; &quot;June&quot; &quot;July&quot; &quot;November&quot; ... ## $ hogwarts : chr &quot;Hufflepuff&quot; &quot;Gryffindor&quot; &quot;Slytherin&quot; &quot;Slytherin&quot; ... ## $ dream : chr &quot;rock star&quot; &quot;rock star&quot; &quot;Rick from Rick and Morty&quot; &quot;astronaut&quot; ... ## - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; На первый взгляд наш дата.тейбл выглядит совершенно так же, как дата.фрейм. Больше скажу - с ним можно делать всё то же самое, что с дата.фреймом - фильтровать строки и колонки по индексам и обращаться к колонкам с помощью $: dt[1,1] dt[1,] dt[,1] dt[1:3,] dt$height ## [1] 165 180 161 164 180 170 170 173 163 168 165 164 166 NA 173 173 183 170 185 ## [20] 169 185 172 158 185 168 175 162 182 164 167 175 167 168 179 172 Но помимо этого у дата.тейблов есть очень крутой дополнительный функционал со своим специфическим синтаксисом. У дата.фрейма в квадратных скобках две части: df[фильтрация строк, фильтрация столбцов]. У дата.тейбла - три, да ещё и смысл второй поменялся: dt[фильтрация строк, выражение, параметр]. Перед первой запятой мы выбираем, какие строки мы хотим оставить в дата.тейбле - и теперь мы можем обращаться к колонкам напрямую, не используя конструкцию типа df$height, дата.тейбл по умолчанию считает, что внутри квадратных скобок вы можете обращаться к колонкам: dt[height &gt; 165, ] Между первой и второй запятой мы уточняем, что мы хотим сделать с колонками. Мы можем просто выбрать одну колонку и “достать” только её: dt[height &gt; 165, eye_number] ## [1] 2 2 2 2 2 3 3 2 2 2 2 2 3 2 2 2 2 2 2 ## [20] 104 2 2 2 2 2 Можем выбрать колонку и произвести над ней какую-нибудь операцию: dt[height &gt; 165, max(eye_number)] ## [1] 104 В предыдущей команде мы сначала выбрали только те строки (= респондентов), которые выше 165 см, а потом узнали, какое среди них максимальное число глаз. А можем создать новую колонку внутри нашего дата.тейбла. Для этого мы будем использовать новый оператор, := (Владимир Львович Волохонский называет его “приписька”. Живите теперь тоже с этим знанием): dt[, height_meters := height/100] Теперь у нас в дата.тейбле есть колонка height_meters, в которой хранится рост каждого испытуемого в метрах (то есть, 165 см превращается в 1.65 м). Обратите внимание - я не фильтровала строки, перед первой запятой ничего нет. Но поставить её надо, чтобы дата.тейбл понял, что вы пишете код height_meters := height/100 во втором компоненте. Но и это не самое клёвое! Ведь у нас есть третья часть (следите за руками - это часть после двух запятых). В третьей части мы можем указать, по какой колонке сгруппировать данные. Следующая строчка исключит всех респондентов, у которых больше двух глаз, и посчитает среднюю длину волос для каждого факультета: dt[eye_number &lt;= 2, mean(hair_length), by = hogwarts] Задание: Найдите самого высокого человека, родившегося в каждый из месяцев. Тех, кто в вопросе про месяцы указал “Я не рождался(-лась)”, исключите из подсчётов. Подсказка: функция max() выдаст NA для одного из месяцев, потому что кто-то не ответил на вопрос о росте. Исключите NA из подсчётов: max(height, na.rm = TRUE). na.rm значит NA remove - то бишь, убирать ли NA при поиске максимального значения. Задание: С помощью функции sum() узнайте, сколько суммарно братьев и сестёр у всех голубоглазых. А сколько у всех зеленоглазых? Найдите оба ответа одной строчкой кода :) Задание: Какой средний размер обуви у тех, кто выбрал чай (а не кофе или потанцевать)? Если у вас есть вопросы про эту главу, скорее задайте их в канале #day1-afternoon-filter. Если после выполнения заданий у вас остались время и силы, вы можете воспользоваться тем, что мы сегодня прошли, чтобы постараться и найти самые интересные факты о нашем датасете. А если вы устали - идите отдыхать! :) Завтра - больше. "],["продолжаем-с-data-table.html", "4 Продолжаем с data.table 4.1 Продолжаем с data.table 4.2 Указание имён при создании колонок 4.3 Вечер в хату, вектор в colnames() 4.4 setnames() из библиотеки data.table", " 4 Продолжаем с data.table library(data.table) 4.1 Продолжаем с data.table Вчера мы познакомились с библиотекой data.table и дата.тейблом как структурой данных с расширенным функционалом. Давайте освежим: Внутри квадратных скобок дата.тейбла к колонкам можно обращаться просто по именам, без выражений типа df$column. У дата.тейбла есть три элемента в квадратных скобках, они отделены запятыми: dt[фильтр строк, выражение, параметр]. Первый элемент позволяет выбрать, какие строки отфильтровать. Во втором элементе можно вывести колонку, создать новую колонку или применить к колонке какую-нибудь функцию. В третьем элементе можно сгруппировать наблюдения по значению в колонке. Давайте загрузим наш датасет, чтобы нам было с чем работать: dt &lt;- fread(&quot;about_us_eng.csv&quot;) Вот так я могу посчитать средний размер обуви для всех респондентов в зависимости от того, сколько у них кошек, исключив тех, кто на этот вопрос не ответил: dt[cats != &quot;this is too personal&quot;, mean(shoe_size), by = cats] Задание для разминки: Исключив тех, кто не выбрал ни Пепси, ни Колу, посчитайте, сколько в среднем братьев и сестёр у любителей каждого напитка. 4.1.1 Счёт элементов с помощью .N До этого момента во втором выражении мы всегда считали какую-нибудь статистику - например, среднее или максимум. Но что, если мы хотим просто узнать, сколько у нас людей, так или иначе ответивших на вопрос? Сколько человек, например, любят Пепси, а сколько Колу? Это делается с помощью специального символа: .N. Этот символ считает, сколько в дата.тейбле строк. Если использовать только его, то мы получим просто количество строк во всём нашем дата.тейбле: dt[, .N] ## [1] 35 nrow(dt) ## [1] 35 Но если использовать его вместе с by =, который группирует, то мы узнаем, сколько строк в каждой группе! То есть вот такая строка посчитает, сколько каких ответов на вопрос о любимой газировке: dt[, .N, by = soft_drink] Кола лидирует - у неё 18 фанатов! Задание: Посчитайте, сколько у нас на мастерской людей с разным уровнем игры на гитаре. Кого больше всего? 4.1.2 Несколько группировок Крайне часто мы хотим посчитать какую-нибудь статистику для каждого сочетания двух переменных. Представьте, что вы проводите эксперимент о влиянии кофеина и физической активности на решение задач. У вас есть две независимых переменных - во-первых, вы даёте испытуемым кофе, чай или воду, во-вторых, вы просите их пробежать километр, позаниматься йогой или просто посидеть перед тем, как они приступят к решению задач, и фиксируете, сколько задач решил каждый испытуемый. В итоге вам будет интересно, сколько в среднем задач решили испытуемые, которые пили кофе и бегали, испытуемые, которые пили кофе и занимались йогой, пили кофе и сидели, пили чай и бегали, ну и так далее. Посчитать это в дата.тейбле очень просто: нужно использовать две колонки в третьей части квадратных скобок, там, где by =. Чтобы сгруппировать по двум колонкам сразу, имена колонок нужно объединить с помощью специальной функции, вот так: .(columnName1, columnName2). Вот как посчитать средний размер обуви в зависимости от предпочтений в газировке и месяца рождения: dt[, mean(shoe_size), by = .(soft_drink, month)] Количество группировок, в целом, не ограничено, чисто технически - группируйте хоть по ста колонкам. Но имейте в виду: если у вас в датасете, как у нас сейчас, 35 человек, то очень “детальные” группировки, скорее всего, приведут к тому, что во многих группах просто никого не будет. Например, сколько среди нас тех, кто обожает Пепси, выше 180 сантиметров, имеет двух котов и три глаза? Кстати, хороший вопрос. Задание: Сколько среди нас тех, кто обожает Пепси, выше 180 сантиметров, имеет двух котов и три глаза? Это задание можно выполнить как минимум двумя способами, используя разные части квадратных скобок. Попробуйте найти оба способа. 4.1.3 Несколько выражений Точно так же, как и колонок для группировки, выражений во втором элементе может быть несколько. Например, если нас интересует несколько статистик сразу, скажем, среднее и дисперсия. Для этого нужно объединить нужные нам функции той же самой функцией .(): dt[, .(mean(height), var(height)), by = eye_color] Давайте соберём воедино: dt[, .(.N, mean(hair_length)), by = .(month, soft_drink)] Что делает предыдущая строчка кода? Задание: посчитайте значения квартилей роста для всех респондентов в зависимости от их предпочтений в напитках (Кола или Пепси плюс кофе или чай). 4.1.4 Имена колонок Вы могли заметить, что каждый раз, когда мы группируем дата.тейбл и считаем какие-нибудь аггрегированные значения типа среднего, то колонки с этими посчитанными значениями получают имена типа V1, V2 и т.п. Это не очень удобно - содержательное имя переменной это гарант того, что вы-читающий(-ая)-свой-старый-код-через-год или другие люди, которым вы свой код покажете, поймут, что в нём происходит. Давайте позаботимся о себе из будущего и научимся называть эти колонки содержательно. 4.2 Указание имён при создании колонок Имя колонки можно указать сразу при названии, вот так: dt[, .(mean_hair_length = mean(hair_length), var_hair_length = var(hair_length)), by = eye_color] Обратите внимание, что имена колонок мы указываем внутри .(). То же самое будет верно и для одной колонки - если мы не указываем её имя, то оборачивать в точку её не обязательно (хотя с точкой всё тоже будет работать), а вот если указываем, то надо обязательно использовать .() даже для единственной колонки. Вот так не сработает: dt[, mean_hair_length = mean(hair_length), by = eye_color] Вот так работает: dt[, .(mean_hair_length = mean(hair_length)), by = eye_color] К слову, вот эти две команды делают одно и то же: dt[, .(mean(hair_length)), by = eye_color] dt[, mean(hair_length), by = eye_color] Таким образом мы можем задать имена колонкам при создании. Часто мы хотим переименовать колонки в уже существующем дата.фрейме - например, если вы собираете данные на Гугл.Формах, то именем колонки является текст вопроса, а это ужасно неудобно. 4.3 Вечер в хату, вектор в colnames() Функция colnames() не только возвращает имена колонок, но и может их менять. Это не специфично для дата.тейбла, это метод из base R, то есть, он сработает и с дата.фреймом. Чтобы переименовать колонку, нужно передать функции colnames() вектор с новыми именами колонок. Давайте переименуем колонку cats в meow. colnames(dt) ## [1] &quot;height&quot; &quot;eye_color&quot; &quot;eye_number&quot; &quot;beard&quot; &quot;soft_drink&quot; ## [6] &quot;cats&quot; &quot;gorgeous&quot; &quot;siblings&quot; &quot;hair_length&quot; &quot;shoe_size&quot; ## [11] &quot;guitar&quot; &quot;hot_drink&quot; &quot;month&quot; &quot;hogwarts&quot; &quot;dream&quot; colnames(dt) &lt;- c(&quot;height&quot;,&quot;eye_color&quot;,&quot;eye_number&quot;,&quot;beard&quot;,&quot;soft_drink&quot;,&quot;meow&quot;, &quot;gorgeous&quot;,&quot;siblings&quot;,&quot;hair_length&quot;,&quot;shoe_size&quot;,&quot;guitar&quot;,&quot;hot_drink&quot;,&quot;month&quot;,&quot;hogwarts&quot;,&quot;dream&quot;) colnames(dt) ## [1] &quot;height&quot; &quot;eye_color&quot; &quot;eye_number&quot; &quot;beard&quot; &quot;soft_drink&quot; ## [6] &quot;meow&quot; &quot;gorgeous&quot; &quot;siblings&quot; &quot;hair_length&quot; &quot;shoe_size&quot; ## [11] &quot;guitar&quot; &quot;hot_drink&quot; &quot;month&quot; &quot;hogwarts&quot; &quot;dream&quot; Можно не передавать вектор всех имён, а отфильтровать самую функцию colnames(), используя индекс колонки (cats/meow - шестая): colnames(dt)[6] &lt;- &quot;cats&quot; colnames(dt) #всё вернулось на круги своя ## [1] &quot;height&quot; &quot;eye_color&quot; &quot;eye_number&quot; &quot;beard&quot; &quot;soft_drink&quot; ## [6] &quot;cats&quot; &quot;gorgeous&quot; &quot;siblings&quot; &quot;hair_length&quot; &quot;shoe_size&quot; ## [11] &quot;guitar&quot; &quot;hot_drink&quot; &quot;month&quot; &quot;hogwarts&quot; &quot;dream&quot; Минусы этого метода - тысячи их. А именно: во-первых, скажем так, странный синтаксис (мы присваиваем что-то функции, а меняется дата.тейбл? Почему мы индексируем функцию?). Во-вторых, надо или передавать вектор всех имён, или использовать индекс колонки - вдруг он поменяется… К счастью, есть более удобная альтернатива. 4.4 setnames() из библиотеки data.table Функция setnames() имеет три аргумента: во-первых, собственно, имя дата.тейбла, в котором нужно переименовывать колонки, во-вторых, вектор старых имён, в-третьих, вектор новых имён. Для одной колонки: setnames(dt, old = &quot;cats&quot;, new = &quot;meow&quot;) Для двух колонок: setnames(dt, old = c(&quot;cats&quot;, &quot;hair_length&quot;), new = c(&quot;meow&quot;, &quot;hairlength&quot;)) Эта команда переименует колонку cats в meow, а колонку hair_length в hair_length. Давайте вернём всё обратно: setnames(dt, old = c(&quot;meow&quot;, &quot;hairlength&quot;), new = c(&quot;cats&quot;, &quot;hair_length&quot;)) Новые имена в setnames() можно не указывать вручную, а задавать как преобразование старых. Для этого нужно дать на вход параметру new не вектор имён, а функцию, которую вы хотите применить к старым именам. Например, функция toupper() превращает все строчные буквы в заглавные: toupper(&#39;abcd&#39;) ## [1] &quot;ABCD&quot; А вот что получится, если использовать её для нашего дата.тейбла: setnames(dt, old = &#39;cats&#39;, new = toupper) colnames(dt) ## [1] &quot;height&quot; &quot;eye_color&quot; &quot;eye_number&quot; &quot;beard&quot; &quot;soft_drink&quot; ## [6] &quot;CATS&quot; &quot;gorgeous&quot; &quot;siblings&quot; &quot;hair_length&quot; &quot;shoe_size&quot; ## [11] &quot;guitar&quot; &quot;hot_drink&quot; &quot;month&quot; &quot;hogwarts&quot; &quot;dream&quot; Кстати, если не уточнять, какие колонки переименовываем, то setnames() применит это функцию ко всем. Вот такая команда сделает заглавными буквы во всех именах колонок: setnames(dt, toupper) colnames(dt) ## [1] &quot;HEIGHT&quot; &quot;EYE_COLOR&quot; &quot;EYE_NUMBER&quot; &quot;BEARD&quot; &quot;SOFT_DRINK&quot; ## [6] &quot;CATS&quot; &quot;GORGEOUS&quot; &quot;SIBLINGS&quot; &quot;HAIR_LENGTH&quot; &quot;SHOE_SIZE&quot; ## [11] &quot;GUITAR&quot; &quot;HOT_DRINK&quot; &quot;MONTH&quot; &quot;HOGWARTS&quot; &quot;DREAM&quot; А вот такая вернёт всё обратно как было: setnames(dt, tolower) colnames(dt) ## [1] &quot;height&quot; &quot;eye_color&quot; &quot;eye_number&quot; &quot;beard&quot; &quot;soft_drink&quot; ## [6] &quot;cats&quot; &quot;gorgeous&quot; &quot;siblings&quot; &quot;hair_length&quot; &quot;shoe_size&quot; ## [11] &quot;guitar&quot; &quot;hot_drink&quot; &quot;month&quot; &quot;hogwarts&quot; &quot;dream&quot; 4.4.1 Новый дата.тейбл или колонка в существующем? Напоследок давайте обсудим такую вещь: в этой главе мы всю дорогу использовали = во втором элементе дата.тейбловских квадратных скобок. Но ведь в первый день мы обсудили, что у дата.тейбла есть свой специальный оператор :=. Что будет, если использовать его? Давайте посмотрим. dt[, mean_hair_length := mean(hair_length), by = eye_color] Хммм, что-то ничего не происходит… Или происходит? Посмотрим, как теперь выглядит наш дата.тейбл: head(dt) Опа! Смотрите сами: там появилась новая колонка со средней длиной волос в зависимости от цвета глаз. То есть, теперь в строке у каждого респондента есть не только его индивидуальные данные, но и данные о какой-то группе, к которой она или он относится. Это логично, если вспомнить, что := именно что создаёт новую колонку в существующем дата.тейбле - даже если вы сгруппировали дата.тейбл с помощью by =. То есть, вот такая команда создаст новый дата.тейбл, в котором будет только группирующая переменная (здесь - цвет глаз) и то, что мы для неё посчитали (в данном случае среднюю длину волос): dt[, .(mean_hair_length = mean(hair_length)), by = eye_color] Чтобы этот новый дата.тейбл можно было использовать потом, надо сохранить его в переменную: meanHairLengthByEyeColor &lt;- dt[, .(mean_hair_length = mean(hair_length)), by = eye_color] А вот такая команда добавит в существующий дата.тейбл новую колонку mean_hair_length_by_eye_color: dt[, mean_hair_length_by_eye_color := mean(hair_length), by = eye_color] Никуда дополнительно её сохранять не надо - это делает :=. Задание. Почистите датасет (то есть, уберите все сомнительные ответы - глаза больше 2 и т.п.). Переведите длину волос из сантиметров в дюймы (для этого вам поможет знание, что 1 см = 0.3937 дюйма), а потом создайте новый дата.тейбл, в котором посчитайте среднюю длину волос в зависимости от количества братьев и сестёр, а также предпочтений в вопросах кофе и чая. А затем постройте график всего этого великолепия :) Задание. Скачайте датасет про разные виды мюсли (мюслей?..) на Kaggle, вот тут. Используя всё, что вы узнали про data.table, ggplot2 и всяческие статистические тесты, расскажите и покажите один интересный факт о мюсли (мюслях?..). "],["визуализация-данных-с-ggplot2.html", "5 Визуализация данных с ggplot2 5.1 Визуализация это зачем? 5.2 Философия A Layered Grammar of Graphics 5.3 Экшон 5.4 Файнал босс 5.5 Конклюжон", " 5 Визуализация данных с ggplot2 5.1 Визуализация это зачем? Вопрос не праздный, ибо что мы зря 100500 видов описательных статистик считали? Однако всё не так просто. Рассмотрим пример. У нас есть датасет Квартет Анскомба1, который выглядит так (первые десять строк): id dataset x y 1 1 10 8.04 1 2 10 9.14 1 3 10 7.46 1 4 8 6.58 2 1 8 6.95 2 2 8 8.14 2 3 8 6.77 2 4 8 5.76 3 1 13 7.58 3 2 13 8.74 Если мы посчитаем описательные статистики в каждом субдатасете, то получим следующее: dataset mean_x mean_y sd_x sd_y cor n_obs 1 9 7.5 3.32 2.03 0.82 11 2 9 7.5 3.32 2.03 0.82 11 3 9 7.5 3.32 2.03 0.82 11 4 9 7.5 3.32 2.03 0.82 11 Ребят, тут всё идентично! Однако давайте нарисуем: Што? Мы обнаружили в явном виде, что несмотря на идентичные значения описательных статистик, паттерны в данных могут быть различны. Чтобы впечатлиться окончательно, посмотрим на Datasaurus2: dataset mean_x mean_y sd_x sd_y cor n_obs away 54.3 47.8 16.8 26.9 -0.1 142 bullseye 54.3 47.8 16.8 26.9 -0.1 142 circle 54.3 47.8 16.8 26.9 -0.1 142 dino 54.3 47.8 16.8 26.9 -0.1 142 dots 54.3 47.8 16.8 26.9 -0.1 142 h_lines 54.3 47.8 16.8 26.9 -0.1 142 high_lines 54.3 47.8 16.8 26.9 -0.1 142 slant_down 54.3 47.8 16.8 26.9 -0.1 142 slant_up 54.3 47.8 16.8 26.9 -0.1 142 star 54.3 47.8 16.8 26.9 -0.1 142 v_lines 54.3 47.8 16.8 26.9 -0.1 142 wide_lines 54.3 47.8 16.8 26.9 -0.1 142 x_shape 54.3 47.8 16.8 26.9 -0.1 142 К чему это всё? К тому, что визуализация данных является жизненно необходимым этапом разведочного анализа. Она позволяет вам глубже и детальнее понять, что происходит в данных, и как это происходящее может отразиться на дальнейшем анализе. 5.2 Философия A Layered Grammar of Graphics Идея, воплолщенная в одном из мощнейших пакетов для визуализации ggplot2, восходит к работе L. Wilkinson «The Grammar of Graphics». Базируясь на идеях, изложенных в этой работе, Hadley Wickham разработал концепцию Layered Grammar of Graphics и создал пакет для визуализации, ради которого мы все здесь собрались. Автором по этому пакету написана целая книга, но мы сосредоточимся на основных смысловых и ключевых моментах, которые необходимы, чтобы сделать что-то крутое. Часто возникает вопрос: почему 2? Ответ примерно такой: был и первый ggplot, но попытка не задалась от слова совсем, и пришлось все переделать. По своей сути график представляет собой сложную аппликацию из нескольких слоев. На каждом слое располагаются сходные по содержанию элементы. Начиная с самого первого — базового — и постепенно добавляя слой за слоем необходимые элементы, можно создавать сложные визуализации для отображения интересных закономерностей в данных. После создания базового графика осуществляется настройка отдельных элементов по необходимости и в зависимости от требований издательства / преподавателя / научника / комиссии и т.д. И поскольку все элементы в определенной степени изолированы друг от друга, это открывает большие возможности кастомизации. Кроме того, чтобы оформить график в соответствии с конкретными требованиями, нет необходимости перерисовывать его целиком, так как содержательная часть графика независима от настроек внешнего облика. Все, что вам нужно — это добавить/удалить пару строк кода. Но — хватит слов! Поехали уже рисовать уже! 5.3 Экшон 5.3.1 Пакеты Для рисования нам понадобится пакет ggplot2. Если вы ранее его никогда не устанавливали, то воспользуйтесь такой командой: install.packages(&quot;ggplot2&quot;) Проверить, установлен пакет или нет, можно так: &quot;ggplot2&quot; %in% installed.packages() ## [1] TRUE После установки пакета его необходимо подключить к текущей сессии, чтобы мы могли пользоваться функциями, которые в нём лежат: library(ggplot2) 5.3.2 Данные Чтобы не ворочаться с загрузкой данных, воспользуемся для освоения мощностей ггплота встроенным в него датасетом diamonds: head(diamonds) Описание датасета примерно такое: Variable Description Values price price in US dollars $326-$18,823 carat weight of the diamond 0.2-5.01 cut quality of the cut Fair, Good, Very Good, Premium, Ideal color diamond color J (worst) to D (best) clarity measurement of how clear the diamond is I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best) x length in mm 0-10.74 y width in mm 0-58.9 z depth in mm 0-31.8 depth total depth percentage 43-79 table width of top of diamond relative to widest point 43-95 Но этот датасет очень большой — 53k наблюдений. Нам для освоения возможностей визуализации пока этого многовато. Давайте сделает случайную подвыборку из 1000 наблюдений: set.seed(34) diamonds1000 &lt;- diamonds %&gt;% slice(sample(1:nrow(diamonds), 1000, replace = FALSE)) 5.3.3 Строим базовый график 5.3.3.1 Базовый слой Первое, что мы делаем, когда собираемся что-либо рисовать — берем холст. Аналогично, когда мы собираем рисовать график с использованием ggplot2, первое, что мы делаем — говорим «Дай мне холст!». На языке ggplot2 это делается с помощью команды ggplot(). ggplot() И, о Боже, ggplot2 дал нам холст! Иначе говоря, мы построили базовый слой, на который в дальнейшем будем набрасывать элементы нашего графика. Следующее, что необходимо сделать — указать данные, на основе которых мы будем строить наш график. Это делается к помощью аргумента data: ggplot(data = diamonds1000) Вроде бы ничего не изменилось, да и собственно, не должно было, ведь мы никак не указали, что мы хотим отобразить. Давайте укажем. 5.3.3.2 Разметка осей и переменные. Эстетики Важнейшие элементы любого графика — это оси. Мы строим двумерные графики, поэтому и оси у нас две — как учили в школе, x (горизонтальная ось, ось абсцисс) и y (вертикальная ось, ось ординат). Чтобы задать оси графика потребуется отдельная функция. Она называется aes(), и в общем задает эстетики графика. Итак, конкретнее об эстетиках. Иначе говоря, это то форматирование, которое связано с данными. Или еще один способ понимания — способы отображения переменных из датасета. У функции aes() есть ряд параметров, они тоже называются эстетики. Вот список эстетик, которые используются чаще всего: x y color fill shape size linetype Несложно догадаться, что переменные по осям задаются параметрами x и y. Что ж, зададим. Давайте визуализируем связь между весом и ценой бриллианта: ggplot(data = diamonds1000, aes(x = carat, y = price)) Так, ну, допустим… Оси разметились. А где картинка? Картинки нет, но ggplot2 честно отработал свою работу. Мы задали только оси — и он нам разметил их в соответствии с имеющимися в векторах значениях. Больше мы ему ничего не написали. Чтобы всё-таки получить картинку, необходимо указать, как мы хотим отборазить наши переменные. 5.3.3.3 Геомы За то, каким образом будут отображены переменными, а конкретно, какими «геометрическими объектами», отвечает семейство функций geom_*. Когда мы переходим к этой функции, мы ступаем на новый слой. Чтобы это обозначить используется «плюсик» (+). ggplot(data = diamonds1000, aes(x = carat, y = price)) + geom_point() Мы выбрали точки для отображения наблюдений, потому что наиболее наглядный вариант отобразить зависимость между двумя переменными. Такой тип графика называется scatterplot, или диаграмма рассеяния. Но, вообще-то, можно и получше отобразить закономерность. Как минимум, добавить линию тренда в помощью специального геома: ggplot(data = diamonds1000, aes(x = carat, y = price)) + geom_point() + geom_smooth() ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; Как видите, при добавлении нового «геометрического» способа отображения данных мы добавляем новый слой. geom_smooth() подразумевает «сглаживание», оно может происходить с помощью разных методов (используемый метод нам написали в консоль). Мы можем эскплицитно указать метод, который хотим использовать. Например, линейную регрессию: ggplot(data = diamonds1000, aes(x = carat, y = price)) + geom_point() + geom_smooth(method = &#39;lm&#39;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Задание Используя тот же датасет diamonds1000, визуализируйте связь между длиной и шириной бриллиантов. Референс В случае, если нас интересует распределение нашей переменной, мы можем использовать geom_histogram() или geom_density(): ggplot(data = diamonds1000, aes(x = price)) + geom_density() Кстати, аргументы функции можно передавать и без указания их имён — R будет ориентироваться по их порядку: ggplot(diamonds1000, aes(price)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. При рисовании гистограммы для обнаружения деталей в распределении можно задать ширину столбика — например, сделать её более мелкой: ggplot(diamonds1000, aes(price)) + geom_histogram(binwidth = 100) Для отображения распределений мы также можем использовать боксплот — это отдельный геом: ggplot(diamonds1000, aes(y = price)) + geom_boxplot() Чуть позже мы столкнемся ещё c некоторыми геомами, но вот вам сразу список самых полезных для старта: geom_histogram() geom_density() geom_boxplot() geom_point() geom_errorbar() geom_pointrage() geom_line() geom_vline() geom_hline() geom_smooth() Вопрос График плотности вероятности, гистограмма и боксплот — все три визуализации отображают распределение. Для чего каждая из них может быть полезна? В помощь картинка ниже. Задание Визуализируйте распределение веса бриллиантов (переменная carat). Выберите один из возможных способов визуализации распределения. Можете визуализировать несколькими способами и сравните результаты. 5.3.4 Ищем более сложные закономерности Пока что мы работали только с одной-двумя переменными, однако на практике нас могут интересовать более сложные взаимосвязи. Например, в случае с бриллиантами распределение цены по всему датасету даёт нам весьма мало информации, поскольку есть много факторов, которые на неё могут влиять — размер бриллианта, качество огранки и др. Пропробуем их отобразить. 5.3.4.1 Группировка по переменной Один из вариантов того, что мы можем сделать, это сгруппировать наши наблюдения по какой-либо из переменных. Как группировка будет выражена в коде сильно зависит от типа визуализации. Разберем на двух примерах. Выше мы рисовали вот такой боксплот, который отображает распределение цены: ggplot(diamonds1000, aes(y = price)) + geom_boxplot() Однако вполне ожидаемо, что цена может быть по-разному распределена в зависимости от качества огранки. В нашем датасете есть переменна cut, и нам было бы хорошо отобразить её на графике. Так как боксплоты требуют по оси x категориальную переменную, то сделать это достаточно просто: ggplot(diamonds1000, aes(x = cut, y = price)) + geom_boxplot() Вот мы уже видим много чего: в группах Good и Premium распределение симметричное, а во всех остальных скошенное. Также мы наблюдаем, что чем выше качество огранки, тем больше выбросов в группе. Если мы визуализируем распределение в помошью, например, графика плотности вероятности, то задание группировки в помощью эстетики x нам не подойдёт: она уже занята нашей переменной price. Эстетика y в этой визуализации рассчитывается автоматически, поэтому её мы тоже не можем использовать — да и как мы по не вообще смогли бы задать группировку? Значит нам необходимо использовать какую-то другую эстетику. Пусть это будет fill: ggplot(diamonds1000, aes(x = price, fill = cut)) + geom_density() Обратите внимание, что теперь у нас справа появилась легенда, которая позволяет понять, что отображено тем или иным цветом. Однако пока визуализация не очень хороша, так как распределения перекрывают друг друга. Чтобы это поправить, нужно задать позрачность с помощью аргумента alpha в функции geom_density(): ggplot(diamonds1000, aes(x = price, fill = cut)) + geom_density(alpha = .5) Теперь мы видим все распределения на одном графике. Классно? Классно! Задание В нашем датасете есть переменная depth, которая обозначает total depth percentage3. Каково распределение этой величины у бриллиантов разного цвета (переменная color)? 5.3.4.2 Больше переменных Это всё, конечно, хорошо, но мы пока что не вышли за пределы двух переменных на одном графике. Вспомним нашу диаграмму рассенияния «Вес — Цена»: ggplot(data = diamonds1000, aes(x = carat, y = price)) + geom_point() Уберём линию тренда, она нам будет мешать. Как бы нам сделать так, чтобы на этот график добавить переменную depth? Вопрос Вернитесь к списку эстетик. x и y у нас заняты. Предложите, какую эстетику мы могли бы использовать для отображения переменной depth? Возможно несколько вариантов — я предлагаю использовать size: ggplot(data = diamonds1000, aes(x = carat, y = price, size = depth)) + geom_point() В целом, получилось неплохо, но сейчас на графике происходит небольшой флекс. Надо немножко поправить, чтобы происходил чилл. Точки и раньше накладывались друг на друга, однако теперь в силу того, что размер точки для нас информативен, наложение стало критично. С наложением элементов друг на друга мы боролись чуть выше. Можем попробовать аналогичный способ: ggplot(data = diamonds1000, aes(x = carat, y = price, size = depth)) + geom_point(alpha = .3) Получилась пузырькая диаграмма. Ну, неплохо. Задание Выше мы рисовали диаграмму рассеяния, которая отображала связь между длиной (x) и шириной (y) бриллианта. Возьмите за основу получившийся график и превратите его в пузырьковую диаграмму, которая будет отображать связь между (x), шириной (y) и глубиной (z) бриллианта. Референс На фоне успешной работы с прозрачностью элементов мы словили состояние потока, и хотим добавить ещё переменных! Круто было бы отобразить, как зависит цена от carat и depth у бриллиантов различного качества огранки. Переменную cut мы уже отображали — здесь использованный подход тоже сработает: ggplot(data = diamonds1000, aes(x = carat, y = price, size = depth, color = cut)) + geom_point(alpha = .3) Ммм, красота! 5.3.5 Важное замечание о визуализации Вопрос Как определить, что визуализация хороша? Можно придумать огромное количество критериев. На мой взгляд, критические параметры таковы: Честность график отображает то, что реально поисходит в данных Читаемость выбран корретных способ визуализации график удобно рассматривать и понимать, что происходит Дизайн подобрана корректная палитра, все цвета хорошо видны и отличимы друг от друга подобраны адекватные шрифты Качество картинки график хорошего разрешения Прочекаем наш график по этим параметрам: Честность — ОК мы работаем с теми данными, котрые у нас есть и не модифицируем их в угоду каким-либо нашим целям; да, мы сейчас работаем на части датасета, но делаем это исключительно в учебных целях Читаемость — нутакое способ визуализации мы выбрали корректный — пузырькая диаграмма, которая у нас получилась, вполне подходит для отображения интересующих нас закономерностей но понимать, что происходит в левом нижнем углу сложновато Дизайн — приемлемо хотя есть некоторые вопросы к используемой стандартеной палитре, на данном этапе это окей, кастомизировать график мы научимся далее Качество картинки — приемлемо пока что мы может не задумываться об этом, так как не выгружаем график в файл для публикации или отчёта, однако надо будет не забывать об этом позднее Итого, у нас хромает крайне существенный парамет — читаемость. Когда мы строим визуализацию, мы должны четко понимать, зачем мы это делаем, и в конечном итоге мы рисуем картинки для нашего читателя. Нам важно позабиться о том, чтобы нашу визуализацию было удобно читать и понимать тому, кто с ней сталкивается впервые — то есть сделать её максимально понятной. Давайте поработаем на этим. Вопрос Как можно изменить график, чтобы он был более читаемым и лучше отображал интересующие нас закономерности? 5.3.5.1 Фасетирование Один из способов сделать визуализацию понятнее — использовать фасетирование. Оно позволяет разбить график на несколько субграфиков по некоторой категориальной переменной. Таким образом, на каждом субграфике окажется меньше данных, поэтому каждый из них будет проще читать. Вместе с тем все субграфики будут располагаться рядом друг с другом, поэтому их будет удобно сравнивать. Для фасетирования существует два варианта: facet_grid() и facet_wrap(). Первый удобен, когда у вас две (и более) группирующий переменных, второй — когда такая переменная одна. У нас сейчас группировка по одной переменной cut, поэтому мы будем использовать второй вариант: ggplot(data = diamonds1000, aes(x = carat, y = price, size = depth, color = cut)) + geom_point(alpha = .3) + facet_wrap(~ cut) Отлично, наши наблюдения зазбилить по субграфикам и в целом визуализация стала чуть более читаемой. Хотя, конечно, большие скопления точек слева внизу всё равно остались4. Внимательно посмотрим на получившийся график: переменная cut у нас отображена двумя разными способами — цветом и фасетированием. Это не оч. хор. — возникла избыточность. Когда читатель будет смотреть на этот график, он озадачится, так как, скорее всего, будет ожидать, что каждая переменная отбражена единственным способом. Пока он разберется, что цвет не несет дополнительной информации, он будет тратить время — это нехорошо. Поэтому цвет надо либо убрать вовсе — и это лучший вариант, либо как минимум скрыть цветовую легенду. ggplot(data = diamonds1000, aes(x = carat, y = price, size = depth)) + geom_point(alpha = .3) + facet_wrap(~ cut) Вот так хорошо — дублирования информации теперь нет. Задание Я тут в сносках упоминал, что нам стоило бы внимательнее посмотреть на распределение переменной price. Давайте это сделаем! Визуализируйте распределение этой переменной в зависимости от качества огранки (cut) и цвета (color). Властью данной мне мною налагаю запрет на использование эстетик (кроме обязательной — x)! Подсказка facet_grid Вариант референса Сложное задание Часто нам бывает полезно знать, как расположено распределение по какой-либо группе наблюдений в контексте всего распредления переменной. Доработайте предыдущий график так, чтобы на каждом субграфике распределение цены в каждом из сочетаний условий color x cut лежало поверх распределения всей переменной price. Это должно выглядеть так: diamonds1000 %&gt;% ggplot(aes(price)) + geom_histogram(data = diamonds1000 %&gt;% select(-cut, -color))+ geom_histogram(fill = &quot;white&quot;) + facet_grid(cut ~ color) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Серые гистограммы — распределение по всей переменной price, белые (маленькие внизу) — распределения цены в каждом из сочетаний условий color x cut. 5.3.6 Инструменты встроенной статистической обработки Досих пор мы отображали «сырые данные» — то есть то, что непосредственно есть в данных. Однако часто бывает так, что мы хотим отобразить какие-то посчитанные статистики, или аггрегированные данные. Поэтому необходимо сначала предобработать данные, получить необходимые значения и затем на их основе построить график. Но зачем? Если можно сразу в коде построения графика рассчитать все, что нам нужно! В ggplot2 уже встроены инструменты простейшей статистический обработки! Еще раз посмотрим на датасет. У нас есть переменная price, а также категории качества огранки cut. Наверняка, средняя цена будет различаться в этих категориях. Давайте это проверим! Но сначала нам необходимо познакомиться с новым семейством функций stat_*. 5.3.6.1 Статы Статы и есть те самые встроенные инструенты статистической обработки. Они позволяют прямо в коде графика обсчитать данные и сразу же визуализировать результаты. На самом деле, мы уже сталкивались со встроенными инструментами статистической обработки, ведь что делает geom_smooth(method = 'lm')? Не что иное, как визуализирует линейную регрессию, построенную на выбранных данных! Наиболее популярная функция из рассматриваемого семейста — stat_summary(). С помощью неё мы и будем визуализировать наши средние. Обратите внимание, что теперь мы будем работать с полным датасетом diamonds! Приступим к построению графика. Начнём с базового слоя: ggplot(diamonds, aes(cut, price)) # напоминаю, что аргументы функции можно передавать просто по порядку, не указывая имя самого аргумента Взяли холст, расчертили. По оси x у нас будет идти группирующая переменная. Теперь добавим средние. Как и полагается, на новый слой. ggplot(diamonds, aes(cut, price)) + stat_summary(fun = mean, geom = &#39;point&#39;) Разберемся, что тут написано. Первый аргумент (fun) принимает функцию, результат которой будет отложен по оси y. В нашем случае это среднее (mean). Она будет применена к переменой price, причем наблюдения будут автоматически сгруппированы по интересующим нас группам (cut). Второй аргумент — это уже знакомый нам geom, которые отвечает за то, как «геометрически» будут отрисованы знаечния на графике. Наш выбор — точки. Как результат мы наблюдаем то, что хотели. Однако как мы знаем из статистики, чтобы определить, есть ли различия между группами, нам недостаточно только средних значений — необходимы доверительные интервалы. Что ж, отобразим и их. Добавим новый слой с помощью всё той же функции stat_summary(), но на этот раз она будет выглядеть немного по-другому: ggplot(diamonds, aes(cut, price)) + stat_summary(fun = mean, geom = &#39;point&#39;) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;) Как мы видим, немного изменился первый аргумент. Это связано с изменением геома. Для отображения доверительных интервалов нам нужен геом errorbar, который требует не одно значение, а два — верхнюю и нижнюю границу доверительного интервала. То есть fun.data принимает как аргумент мини-датафрейм — как раз в таком формате и возвращается результат функции mean_cl_boot. Можно посмотреть на её работу отдельно: mean_cl_boot(diamonds$price) Собственно, вот он датафрейм из одной строки. Здесь три значения, но errorbar игронирует первое (само среднее значение) и использует только второе и третье, строя по ним «усы». Задание С ценой разобрались. Теперь давайте сравним вес бриллиантов в разных группах. Визуализируйте средние значения веса бриллиантов (carat) в группах по степени чистоты (clarity). Не забудьте про доверительные интервалы! Однако мы продолжваем гнаться за сложными закономерностями, поэтому добавим ещё одну группирующую переменную. В наших данных есть переменная color, которая задаёт «цвет» бриллианта. Наверное, он тоже может влиять на цену камня. ggplot(diamonds, aes(cut, price, color = color)) + # не путайтесь: первый color --- название аргумента, второй --- имя переменной) stat_summary(fun = mean, geom = &#39;point&#39;) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;) Ёжкины коты, красота-то какая! Только надо как-то это в божеский вид привести… 5.3.7 Настраиваем график ggplot2 имеет широчайшие возможности кастомизации, в нем можно настроить чуть более, чем всё. Сейчас наш график выглядит хотя и содержательно верно, но с точки зрения дизайна (да и общей адекватности) — совершенно дико. Давайте подправим. Первое, что бросается в глаза — точки и «усы» лежат друг на друге, что очень нехорошо и так не надо: крайне трудно понять, что происходит на графике. Давайте их расположим рядом друг с другом, чтобы оставалось видно, что средние сгрупированы по делениям оси x. Это делается с помощью функции position_dodge(), которая создает объект задающий позицию точек. Результат её работы необходимо передать в аргумент position конкретного стата, но так как у нас статов несколько, прописывать 100500 раз одно и то же — неразумно. К тому же, если мы захотим как-то поменять расположение точек (сблизить, раздвинуть сильнее), нам надо будет переписывать каждую строку — всё ещё неразумно. Поэтому мы сделаем отдельный объект, в который рапишем результат работы функции: pd &lt;- position_dodge(0.5) # передаем какое-то число из диапазона [0, 1] И далее будем использовать этот объект: ggplot(diamonds, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd) Ну, вот стало уже поприличней. Второе, что бросается в глаза — слишком широкие errorbar’ы (они касаются усов соседних точек). Значит, надо уменьшить ширину. За их ширину отвечает параметр width. Ширина задается долями единицы. ggplot(diamonds, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) Вот так вроде хорошо, хвосты errorbar’ов ни с чем не пересекаются. Что ты еще хотелось подправить? Наверное, сделать акцент на главных смысловых элементах графика. В нашем случае это точки. Давайте сделаем их побольше. ggplot(diamonds, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) Вот теперь кайф! 5.3.7.1 Темы Но не совсем. Фон какой-то не очень… Дефолтная серая тема в какое-то давнее время была популярна, все выдели что ты крутой и умеешь в ггплот и ваще. Однако со временем это стало #немодно, и лучше серой темы избегать, да и требования журналов обычно более строгие. В ggplot2 есть ряд встроенных тем, которые задаются через функции семейства theme_*(). Наиболее популярные theme_classic() и theme_bw(). Последнюю мы и будем использовать. ggplot(diamonds, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() Ах, красота! Задание Возьмите график из последнего задания. Модифицируйте код так, чтобы он отображал средние значения веса блиллиантов (с доверительными интервалами) для групп бриллиантов по переменным clarity x cut. Можете использовать любые эстетики. Настройте график, так, чтобы он был читаем. За референс возьмите визуализацию выше. Поправьте положение точек и эррорбаров, ширину «усов», измените стандартную тему на любую другую. 5.3.7.2 Кастомизация шкал Мы задали отображение групп цвета бриллиантов цветом5, но дефолтная шкала не совсем хороша, как минимум потому, что в ней есть жёлтый, который на нашем белом фоне будет смотреться не очень. Надо бы это поправить. Для того, чтобы кастомизировать используемые шкалы, есть ряд функций семейства scale_*(). Мы познакомимся с некоторыми из них. Для начала изменим цвета. В R можно задавать цвета через названия или HEX кодировку. Будем использовать названия. ggplot(diamonds, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() + scale_color_manual(values = c(&#39;brown4&#39;, &#39;chocolate4&#39;, &#39;darkgoldenrod4&#39;, &#39;darkolivegreen&#39;, &#39;darkslategray&#39;, &#39;darkslateblue&#39;, &#39;deeppink4&#39;)) Здесь мы используем функцию scale_color_manual(), чтобы задать значения цвета вручную. Используя обязательный аргумент values мы передаем вектор названий цветов, которые хотим использовать. Не то чтобы идеал, но и мы не дизайнеры. Так-то есть готовые палитры, и чё мы тут заморачивались подбирая цвета — не оч понятно: ggplot(diamonds, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() + scale_color_manual(values = colorspace::rainbow_hcl(length(unique(diamonds$color)))) 5.3.7.3 Последние штрихи Но настройка графика на этом не закончена. Раз уж мы в России, то надо и подписи по-русски задать. Для этого также есть отдельная функция. Она называется labs(). Зададим названия осей: ggplot(diamonds1000, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() + scale_color_manual(values = colorspace::rainbow_hcl(length(unique(diamonds$color)))) + labs(x = &quot;Качество огранки&quot;, y = &quot;Цена&quot;) Теперь было бы хорошо добавить название, а то как-то непонятно, что тут вообще нарисовано. Используем аргументы title и subtitle функции labs(). ggplot(diamonds1000, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() + scale_color_manual(values = colorspace::rainbow_hcl(length(unique(diamonds$color)))) + labs(x = &quot;Качество огранки&quot;, y = &quot;Цена&quot;, color = &quot;Цвет бриллианта&quot;, title = &quot;Зависимость цены бриллианта от его характеристик&quot;, subtitle = &quot;Цвет и качество огранки&quot;) Почти идеально! Но осталось пара моментов. Во-первых, непонятно, какая метрика отображена с помощью «усов», а во-вторых, легенда занимает много места. У labs() есть ещё один аргумент — caption, иначе говоря «подпись». В ней и можно указать метрику. ggplot(diamonds1000, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() + scale_color_manual(values = colorspace::rainbow_hcl(length(unique(diamonds$color)))) + labs(x = &quot;Качество огранки&quot;, y = &quot;Цена&quot;, color = &quot;Цвет бриллианта&quot;, title = &quot;Зависимость цены бриллианта от его характеристик&quot;, subtitle = &quot;Цвет и качество огранки&quot;, caption = &quot;отображён 95%-доверительный интервал&quot;) Осталось подвинуть легенду, например, вниз. Вообще положение легенды определяется темой, и мы её уже задали. Однако можно подправить дефолтные параметры с помощью функции theme(). ggplot(diamonds1000, aes(cut, price, color = color)) + stat_summary(fun = mean, geom = &#39;point&#39;, position = pd, size = 2) + stat_summary(fun.data = mean_cl_boot, geom = &#39;errorbar&#39;, position = pd, width = .5) + theme_bw() + scale_color_manual(values = colorspace::rainbow_hcl(length(unique(diamonds$color)))) + labs(x = &quot;Качество огранки&quot;, y = &quot;Цена&quot;, color = &quot;Цвет бриллианта&quot;, title = &quot;Зависимость цены бриллианта от его характеристик&quot;, subtitle = &quot;Цвет и качество огранки&quot;, caption = &quot;отображён 95%-доверительный интервал&quot;) + theme(legend.position = &#39;bottom&#39;) 5.3.8 Сохранение графиков Для того, чтобы опубликовать график в статье или даже просто вставить в презентацию нужно его как-то выгрузить. Скриншоты нам не подходят, потому что качество их совершенно никуда не годится. На наше счастье есть фукнция для выгрузки картинок из R и называется она ggsave(). Она принимает следующие аргументы: filename — название файла, в которых будет сохранен график path — путь, куда сохранять нашу картинку. plot — график, который необходимо сохранить (по умолчанию, последний построенный) scale — степень масштабирования изображения width — ширина изображения height — высота изображения units — единицы изменения (дюймы, миллиметры, сантиметры) dpi — разрешение изображения (точки на дюйм, стандарт для печати — 300) Функция позволяет сохранить изображения большинства форматов (JPEG, PNG, SVG, TIFF, PDF). ggsave(&#39;graph1.png&#39;, width = 20, height = 20, units = &#39;cm&#39;) Выполнив эту функцию мы получим в рабочей директории файл с графиком, который мы только что нарисовали. 5.4 Файнал босс Чтобы закрепить всё, чему вы научились, вот вам суперзадание. Скорее всего, в ходе его выполнения, вам придется погуглить — это тоже важный навык аналитика. Главное — пробовать и не сдаваться, если с первого раза не всё прошло удачно. У вас обязательно всё получится! Сложное задание Скачайте отсюда реальные данные. Команта для скачивания (с сохранением в объект share): share &lt;- read.csv(&quot;https://raw.githubusercontent.com/angelgardt/mk_ggplot2/master/sharexp_data.csv&quot;) Это данные поведенческого эксперимента, в котором пользователи Android и iOS искали иконки «share» обеих платформ среди универсальных иконок. Короче, зрительный поиск. Нас будут интересовать следующие переменные: trialtype — тип пробы (tray/dots/both) setsize — количество стимулов в пробе (8/12/16) time1 — время первого клика platform — платформа смартфона (Android/iOS) Повторите представленную визуализацию: Подсказка Вам может быть полезен вот такой код: share[share$trialtype != &quot;both&quot;, ] 5.5 Конклюжон Мы с вами быстро пробежались по гглоту, однако за границами данного занятия осталось множество его возможностей. Мы не смотрели специфичные геомы, другие системы координат и интерактивные визуализации. Сложно посоветовать единый всеобъемлющий гайд по этой библиотеке — разве что вот эта книжка. А вообще всегда помните, что есть вот этот сайт, где вы можете найти любую нужную вам информацию — по ggplot2 уж точно. Ну, и конечно, фил фри ту написать автору в телеграм (@angelgardt) или фейсбук. По теореме умножения вероятностей.↩︎ Справедливости ради стоит отметить, что дисперсионный анализ очень часто используется для анализа экспериментальных данных, поэтому поработаем с ними.↩︎ Что бы это ни значило…↩︎ Вообще об этом стоило подумать, когда мы смотрели на распределения переменной price и видели, что у нас очень много «дешёвых» бриллиантов и мало «дорогих». Но это уже следующий этап погружения в анализ картинок. Нам бы пока с возможностями ггплота разобраться…↩︎ Мы такие оригинальные!↩︎ "],["anova-a-k-a-дисперсионный-анализ.html", "6 ANOVA a.k.a. Дисперсионный анализ 6.1 Зачем нужен дисперсионный анализ? 6.2 Однофакторный дисперсионный анализ 6.3 Многофакторный дисперсионный анализ 6.4 Многофакторный дисперсионный анализ без взаимодействия в R 6.5 Важность аггрегации данных 6.6 Итоги", " 6 ANOVA a.k.a. Дисперсионный анализ 6.1 Зачем нужен дисперсионный анализ? Дисперсионный анализ (ANalysis Of VAriances) нужен, чтобы тестирования гипотзы о влиянии факторов на зависимые переменные. Вернее, более корректно было бы сказать, гипотезы о связях факторов с зависимыми переменными. С точки зрения данных фактор — это категориальная переменная, которая разбивает наши наблюдения на несколько групп. Например, переменная «экспериментальное условие» или «ступень обучения» (бакалавриат, магистратура, аспирантура) и т.д. Итак, мы продолжаем сравнивать группы, однако теперь в отличие, например, от t-теста, у нас их больше, чем две. Казалось бы, ну и пофиг? Просто попарно сравниваем все группы друг с другом и обнаруживаем (или нет) искомые различия. Так-то оно, конечно, так — но ведь это не так… 6.1.1 Проблема множественных сравнений Когда мы сравнивали две группы между собой, всё было хорошо. А если у нас больше двух групп? Если их пять? Десять? В одном сравнении вероятность ошибки первого рода мы задаем как \\(0.05\\). Когда у нас появляется много сравнений, она существенно возрастает. Почему? Мы проводим независимые сравнения, значит вероятности ошибок будут перемножаться6. Если верояность ошибиться в одном сравнении \\(\\alpha\\), то вероятность сделать правильный вывод — \\(1 - \\alpha\\). Тогда вероятность сделать правильный вывод в \\(m\\) сравнениях — \\((1 - \\alpha)^m\\). Отсюда мы можем вывести вероятность ошибиться хотя бы в одном сравнении: \\[ \\mathrm P&#39; = 1 - (1 - \\alpha)^m \\] Пусть у нас есть 3 группы, которые нам надо сравнить друг с другом — получается необходимо провести три сравнения. Итого вероятность ошибиться получается: \\[ \\mathrm P&#39; = 1 - (1 - 0.05)^3 \\approx 0.143 \\] Это значительно больше, чем \\(0.05\\). И дальше хуже. Поэтому нужно либо корректировать уровень значимости, либо использовать более мощные методы. Одним из таких методов и является дисперсионный анализ. 6.1.2 Идея дисперсионного анализа Идея данного метода состоит в том, что мы не тестируем различия между конкретными группами, а смотрим на влияние фактора в целом. Такое влияние будем выражаться в том, что между хотя бы двумя любыми группами будет статистически значимая разница. Математически мы можем это записать следующим образом: \\[ H_0: \\mu_1 = \\mu_2 = \\dots = \\mu_p \\\\ H_1: \\exists \\, i, \\, j: \\mu_i \\neq \\mu_j, \\] где \\(\\mu_1, \\, \\mu_2, \\, \\dots \\, \\mu_p\\) — средние значения в группах. Разберемся на примере. 6.2 Однофакторный дисперсионный анализ Здесь всё просто. У нас один фактор — категориальная переменная с несколькими уровнями — и мы хотим узнать, оказывает ли влияние данный фактор на нашу зависимую переменную. Вернее, конечно, правильнее было бы сказать, связан ли данный фактор в нашей зависимой переменной, как мы уже говорили выше. 6.2.1 Структура изменчивости Основные характеристики статистических данных — неопределённость и вариативность. И эта вариативность, он же изменчивость, имеет определенную структуру. Прежде всего, есть общая изменчивость, которая складывается из сумм квадратов отклонений от общего среднего: \\[ SS_\\mathrm{t} = \\sum_{i=1}^n (\\bar y - y_i)^2, \\, \\mathrm{df_t} = n - 1, \\] \\(SS_\\mathrm{t}\\) — общая сумма квадратов (Total Sum of Squares), \\(y_i\\) — наблюдение, \\(\\bar y\\) — среднее по всей выборке, \\(\\mathrm{df_t}\\) — число степеней свободы для общей суммы квадратов. Часть от неё составляет факторная (межгрупповая) изменчивость — это отклонения внутригрупповых средних от общего среднего: \\[ SS_\\mathrm{x} = \\sum_{j=1}^p (\\bar y - \\bar y_j)^2, \\, \\mathrm{df_x} = p - 1, \\] \\(SS_\\mathrm{x}\\) — факторная сумма квадратов (Factor Sum of Squares), \\(\\bar y_j\\) — среднее в конкретной группе наблюдений, \\(\\bar y\\) — среднее по всей выборке, \\(\\mathrm{df_x}\\) — число степеней свободы для факторной суммы квадратов. Оставшуюся часть составляет случайная (внутригрупповая) изменчивость: \\[ SS_\\mathrm{e} = \\sum_{i=1}^n \\sum_{j=1}^p (\\bar y_j - y_{ij})^2, \\, \\mathrm{df_e} = n - p \\] Таким образом, получаем, что \\[ SS_\\mathrm{t} = SS_\\mathrm{x} + SS_\\mathrm{e} \\] 6.2.2 Тестирование значимости фактора Почему диперсионный анализ называется именно так? Потому что используя суммы квадратов и степени свободы, мы можем перейти к дисперсиям — вернее, к средним квадратам: \\[ MS_{\\mathrm t} = \\frac{SS_\\mathrm{t}}{\\mathrm{df_t}}, \\quad MS_{\\mathrm x} = \\frac{SS_\\mathrm{x}}{\\mathrm{df_x}}, \\quad MS_{\\mathrm e} = \\frac{SS_\\mathrm{e}}{\\mathrm{df_e}} \\] \\(MS_\\mathrm{x}\\) и \\(MS_\\mathrm{e}\\) используются для тестирования значимости фактора. Если зависимости между фактором и целевой переменной нет, то \\(MS_\\mathrm{x} \\approx MS_\\mathrm{e}\\). Ешё раз вспомним, как формулируется статистическая гипотеза: \\[ H_0: \\mu_1 = \\mu_2 = \\dots = \\mu_p \\\\ H_1: \\exists \\, i, \\, j: \\mu_i \\neq \\mu_j, \\] Для тестирования гипотезы используется следующая статисика: \\[ F_{\\mathrm{df_x},\\,\\mathrm{df_e}} = \\frac{MS_\\mathrm{x}}{MS_\\mathrm{e}} \\overset{H_0}{\\thicksim} F(\\mathrm{df_x}, \\, \\mathrm{df_e}) \\] Результаты дисперсионного анализа обычно представляются в виде таблицы: Источник изменчивости \\(SS\\) \\(\\mathrm{df}\\) \\(MS\\) \\(F\\) \\(p\\) Фактор \\(SS_\\mathrm{x}\\) \\(\\mathrm{df_x}\\) \\(MS_\\mathrm{x}\\) \\(F_{\\mathrm{df_x},\\mathrm{df_e}}\\) \\(p\\) Случайная \\(SS_\\mathrm{e}\\) \\(\\mathrm{df_e}\\) \\(MS_\\mathrm{e}\\) Общая \\(SS_\\mathrm{t}\\) \\(\\mathrm{df_t}\\) 6.2.3 Данные Лежат тут. Скачиваются так: share &lt;- read.csv(&quot;https://raw.githubusercontent.com/angelgardt/mk_ggplot2/master/sharexp_data.csv&quot;) Это данные поведенческого эксперимента, в котором пользователи Android и iOS искали иконки «share» обеих платформ среди универсальных иконок. Короче, зрительный поиск. Нас будут интересовать следующие переменные: trialtype — тип пробы (tray/dots/both) setsize — количество стимулов в пробе (8/12/16) time1 — время первого клика platform — платформа смартфона (Android/iOS) Будем пытаться ответить на вопрос, какие факторы влияют на время первого клика. Только первоначально надо предобработать данные, убрав из них пробы типа both, так как это экспериментальное условие было задумано для другого анализа: share &lt;- share[share$trialtype != &quot;both&quot;, ] 6.2.4 Дисперсионный анализ в R Для дисперсионного анализа в R есть функция aov(). Она ожидает на вход формулу и датафрейм. Формула задаёт зависимую перменную (y) и фактор (x). Общий синтаксис будет такой: aov(formula = y ~ x, data) Пусть мы хотим понять, влияет ли тип пробы (trialtype) на время реакции (time1): fit1 &lt;- aov(time1 ~ trialtype, share) Обратите внимание на несколько моментов: переменная, которая задаёт фактор, должна быть факторной (внезапно), то есть данные должны быть приведены к длинному формату; в нашем случае переменная текстовая, поэтому автоматически была приведена к факторному типу результаты работы функции aov() мы записываем в объект, потому что так удобнее, сейчас мы поймём зачем Если мы посмотрим на сам объект fit1, то мы обнаружим не много полезной информации: fit1 ## Call: ## aov(formula = time1 ~ trialtype, data = share) ## ## Terms: ## trialtype Residuals ## Sum of Squares 9.570 9718.307 ## Deg. of Freedom 1 10798 ## ## Residual standard error: 0.9486885 ## Estimated effects may be unbalanced Чтобы получить табличку дисперсионного анализа, надо вызвать функцию summary() от сохраненного объекта: summary(fit1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trialtype 1 10 9.57 10.63 0.00111 ** ## Residuals 10798 9718 0.90 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 На что мы смотрим, чтобы определить значимость фактора? Как и в случае любых статистических методов: на значение статистики, в данном случае \\(F\\), и на p-value. Наблюдаем, что p-value меньше конфенционального 0.05, значит данный фактор статистически значимо связан с зависимой переменной. Однако в факторе trialtype есть только два уровня, и по факту мы сделали что-то сравнимое с t-тестом. Давайте попробуем запилить анову с тремя уровнями фактора. Возьмем переменную setsize. Так как это числовая переменная, чтобы анализ корректно отработал, необходимо перевести её в фактор, так как числа в отличии от строк по умолчанию в фактор не трансформируются: fit2 &lt;- aov(time1 ~ factor(setsize), share) summary(fit2) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## factor(setsize) 2 547 273.70 321.9 &lt;2e-16 *** ## Residuals 10797 9180 0.85 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Логика кода остаётся абсолютно такая же. Теперь обратим внимание на результат. Да, фактор количества стимулов (setsize) значим, но что это значит технически? Что есть хотя бы две группы, которые значимо различаются между собой. Какие — нам не известно. Чтобы это узнать, необходимо провести… 6.2.5 Post hoc тесты Post hoc тесты позволяют выяснить, между какими именно группами есть статисически значимые различия. Это не единственный метод, но самый распространенный, поэтому мы рассмотрим его. Чтобы выяснить, между какими конкретно группами есть различия, нам неизбежно придется выполнить несколько попарных сравнений — поэтому всё-таки придётся принять меры по предотвращению проблемы множественных сравнений, то есть скорректировать уровень значимости. Возникает закономерный вопрос: раз уж мы всё равно сравниваем попарно все группы, зачем вообще нам нужен был дисперсионный анализ? Можно же сразу было попарно сравнить и кайфовать! Так-то оно, конечно, так — но ведь это не так. Post hoc тесты, или попарные сравнения, мы выполняем только в том случае, если обнаружили значимое влияние фактора (предиктора). Напомним себе, что дисперсионный анализ тестирует гипотезу о том, что средние во всех группах равны. Соответственно, если в ходе дисперсионного анализа не обнаруживается значимое влияние фактора на зависимую переменную, у нас нет оснований отклонить эту нулевую гипотезу — следовательно, мы делаем вывод, что между группами нет различий. А раз их нет, то что же тогда тестировать попарными сравнениями? А вот если фактор получился значимым, то тогда хотя бы две из групп различаются — естественно, нам хотелось бы знать, какие конкретно. Тогда мы проводим попарные сравнения. Вообще говоря, попарные сравнения можно проводить любым статистическим тестом, который сравнивает две группы. Просто для именования перечислим следующие возможные варианты: наименьшая значимая разница Фишера (Fisher’s Least Significant Difference) поправка Бонферрони (Bonferroni correction) или Сидака (Sidak’s correction) тест Тьюки (Tuckey’s Honest Significant Difference, HSD) тест Стьюдента-Ньюмена-Кьюлса (Student-Newman-Kewls test, SNK) тест Даннета для сравнения с контрольной группой (Dunnet’s test) критерий Дункана (Dunkan’s test) тест Шеффе (Scheffe’s test) Из всего этого зоопарка мы рассмотрим тест Тьюки, так как он считается разумным компромиссом относительно жёсткости корректировки уровня значимости. Тест Тьюки выполняется с помощью функции TukeyHSD(), которая на вход ожидает объект с результатами дисперсионного анализа: TukeyHSD(fit2) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = time1 ~ factor(setsize), data = share) ## ## $`factor(setsize)` ## diff lwr upr p adj ## 12-8 0.2700864 0.2191407 0.3210320 0 ## 16-8 0.5514225 0.5004769 0.6023681 0 ## 16-12 0.2813361 0.2303905 0.3322818 0 Что мы видим? Табличку попарных сравнений: в первой колонке указано, какие группы сравнивались во второй — разница между средними в группах третья и четверная — нижняя и верхняя границы доверительного интервала для разницы средних пятая — p-value, по которому мы делаем статистический вывод В данном случае все три группы значимо различаются между собой. Задание Загрузите данные эксперимента на зрительный поиск (да, опять7). В эксперименте испытуемые должны были запоминать слова, обозначающие объекты, а затем искать эти объекты среди похожих других. В данных у нас есть следующие переменные: resp — идентификатор респондента group — уровень категории слов для запоминания (base — базовая и super — суперординатная) memory_setsize — количество слов-категорий для запоминания visual_setsize — количество стимулов на экране поиска объектов rt — время реакции / обнаружения стимула Исследуйте, как уровень категории слов для запоминания (group) влияет на скорость обнаружения стимула (rt). 6.3 Многофакторный дисперсионный анализ Чем ещё хорош дисперсионный анализ? Тем, что можно изучать влияние не только одного фактора, но и нескольких! Основной эффект каждого фактора интерпретируется аналогично тому, как это делалось в однофакторном дисперсионном анализе. Если же у нас значимо взаимодействие, то это говорит нам о том, что влияние одного фактора на зависимую переменную различается на разных уровнях другого фактора. Визуализация для понимания того, как оно работает: Вообще значимое взаимодействие факторов — это двоякая штука. С одной стороны, мы обнаружили интересную закономерность — возможно, именно ту, которую искали, и это круто. С другой стороны, взаимодействие, во-первых, может маскировать главные эффекты — если мы смотрим только на главные эффекты, то теряем часть информации о закономерности во-вторых, и это связано с первым пунктом, оно затрудняет интерпретацию основных эффектов. Если взаимодействие не значимо, то с интерпретацией главных эффектов трудностей не возникает. Если взаимодействие значимо, то обсуждать главнные эффекты необходимо аккуратно, или не обсуждать вовсе. В частности, нижний ряд рисунков выше показывает, как эффект фактора A частично маскирует эффект фактора B, что отражается во взаимодействии. Конечно, в модель можно ввести и более двух предикторов, и логика останется та же самая. Но помните, что чем сложнее модель, тем сложнее её интерпретация. А интерпретируя взаимодействие трёх предикторов вовсе можно сойти с ума. В связи с этим, есть следующий момент. Когда вы планируете ваше исследование, сразу подумайте, как вы будете анализировать данные — что будет входить в модель в качестве основных предикторов, что в качестве ковариат, и какие взаимодействия в ней будут. Иначе измерить кучу переменных вы построите модель, результаты которой невозможно будет понять. Дизайн исследования очень тесно связан с аналитикой. 6.4 Многофакторный дисперсионный анализ без взаимодействия в R В наших данных есть две переменные: trialtype и platform, влияние которых на время реакции хотелось бы исследовать. Переменная trialtype содержит два уровня — dots и tray. В факторе platform у нас два уровня — iOS и Android. Итого, у нас два фактора, в каждом из которых два уровня. Отлично! Поехали! Построим сначала модель без взаимодействия. Синтаксически несколько факторов в модель указываются через плюс (+): fit3 &lt;- aov(time1 ~ trialtype + platform, share) summary(fit3) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trialtype 1 10 9.57 10.68 0.00109 ** ## platform 1 41 40.82 45.54 1.57e-11 *** ## Residuals 10797 9677 0.90 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Таблица в аутпуте получается аналогичная, только теперь здесь не один, а два фактора. Для каждого рассчитана F-статистика и p-value. В данном случае оба предиктора оказались статистически значимы. 6.4.0.1 Post hoc тесты Постхоки делаются по той же схеме: TukeyHSD(fit3) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = time1 ~ trialtype + platform, data = share) ## ## $trialtype ## diff lwr upr p adj ## tray-dots 0.0595366 0.0238221 0.0952511 0.0010878 ## ## $platform ## diff lwr upr p adj ## ios-android -0.1229602 -0.1586747 -0.08724568 0 Поскольку у нас в каждом факторе два уровня, мы и видим два попарных уравнения с уже скорректированными p-значениями. Задание Продолжаем работать в данными эксперимента из предыдущего задания. Напоминалка В эксперименте испытуемые должны были запоминать слова, обозначающие объекты, а затем искать эти объекты среди похожих других. В данных у нас есть следующие переменные: resp — идентификатор респондента group — уровень категории слов для запоминания (base — базовая и super — суперординатная) memory_setsize — количество слов-категорий для запоминания visual_setsize — количество стимулов на экране поиска объектов rt — время реакции / обнаружения стимула Как влияют на скорость обнаружения целевого объекта (rt) число стимулов на экране (visual_setsize) поиска и число категорий для запоминания (memory_setsize)? Пока тестируем только основные эффекты, взаимодействие включать в модель не надо. 6.4.1 Многофакторный дисперсионный анализ со взаимодействием в R Чтобы включить в модель взаимодействие, есть два варианта: использовать оператор : использовать оператор * Есть мы используем первый вариант, то синтаксис будет выглядеть так: fit4.1 &lt;- aov(time1 ~ trialtype + platform + trialtype:platform, share) summary(fit4.1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trialtype 1 10 9.57 10.68 0.00109 ** ## platform 1 41 40.82 45.56 1.56e-11 *** ## trialtype:platform 1 4 3.83 4.27 0.03882 * ## Residuals 10796 9674 0.90 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Если мы пользуемся вторым вариантом, то синтаксис будет выглядеть так: fit4.2 &lt;- aov(time1 ~ trialtype * platform, share) summary(fit4.2) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trialtype 1 10 9.57 10.68 0.00109 ** ## platform 1 41 40.82 45.56 1.56e-11 *** ## trialtype:platform 1 4 3.83 4.27 0.03882 * ## Residuals 10796 9674 0.90 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Результаты получаются идентичные. Оператор * просто сокращает строку. 6.4.1.1 Post hoc тесты Удивительно, но в случае попарных сравнений всё ещё ничего не изменяется: TukeyHSD(fit4.1) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = time1 ~ trialtype + platform + trialtype:platform, data = share) ## ## $trialtype ## diff lwr upr p adj ## tray-dots 0.0595366 0.02382751 0.0952457 0.0010859 ## ## $platform ## diff lwr upr p adj ## ios-android -0.1229602 -0.1586693 -0.08725108 0 ## ## $`trialtype:platform` ## diff lwr upr p adj ## tray:android-dots:android 0.02189299 -0.04430338 0.088089361 0.8305483 ## dots:ios-dots:android -0.16060379 -0.22680016 -0.094407418 0.0000000 ## tray:ios-dots:android -0.06342358 -0.12961995 0.002772791 0.0660908 ## dots:ios-tray:android -0.18249678 -0.24869315 -0.116300410 0.0000000 ## tray:ios-tray:android -0.08531657 -0.15151294 -0.019120202 0.0051499 ## tray:ios-dots:ios 0.09718021 0.03098384 0.163376578 0.0009357 Задание Ещё один заход к данными того самого эксперимента. Напоминалка В эксперименте испытуемые должны были запоминать слова, обозначающие объекты, а затем искать эти объекты среди похожих других. В данных у нас есть следующие переменные: resp — идентификатор респондента group — уровень категории слов для запоминания (base — базовая и super — суперординатная) memory_setsize — количество слов-категорий для запоминания visual_setsize — количество стимулов на экране поиска объектов rt — время реакции / обнаружения стимула Возьмите модель из предыдущего задания и дополните её взаимодействием факторов. Итого в модель должны быть включены факторы visual_setsize и memory_setsize, а также из взаимодействие visual_setsize:memory_setsize. В качестве зависимой переменной остаётся rt. Какие выводы можно сделать из полученной модели? 6.5 Важность аггрегации данных А теперь посмотрим на то, что мы наделали. Для этого взглянем на структуру данных: str(share) ## &#39;data.frame&#39;: 10800 obs. of 22 variables: ## $ trialtype: chr &quot;tray&quot; &quot;tray&quot; &quot;tray&quot; &quot;tray&quot; ... ## $ setsize : int 8 8 8 8 8 8 8 8 8 8 ... ## $ time1 : num 1.67 1.13 2.6 2.61 1.59 ... ## $ click1x : int -227 -69 60 199 -241 -51 99 213 -201 -70 ... ## $ click1y : int 202 231 195 213 43 59 62 46 -123 -82 ... ## $ time2 : num 1.28 1.061 0.963 0.863 0.931 ... ## $ click2x : int 14 -44 17 -26 -25 10 -29 -27 -25 -19 ... ## $ click2y : int -351 -392 -361 -356 -397 -383 -372 -353 -385 -394 ... ## $ id : int 1 1 1 1 1 1 1 1 1 1 ... ## $ platform : chr &quot;ios&quot; &quot;ios&quot; &quot;ios&quot; &quot;ios&quot; ... ## $ posx1 : int -238 -63 66 203 -243 -60 73 213 -229 -84 ... ## $ posy1 : int 202 226 217 218 59 90 66 52 -93 -79 ... ## $ posxmin1 : int -313 -138 -9 128 -318 -135 -2 138 -304 -159 ... ## $ posxmax1 : int -163 12 141 278 -168 15 148 288 -154 -9 ... ## $ posymin1 : int 127 151 142 143 -16 15 -9 -23 -168 -154 ... ## $ posymax1 : int 277 301 292 293 134 165 141 127 -18 -4 ... ## $ posx2 : int 450 450 450 450 450 450 450 450 450 450 ... ## $ posy2 : int -350 -350 -350 -350 -350 -350 -350 -350 -350 -350 ... ## $ posxmin2 : int 350 350 350 350 350 350 350 350 350 350 ... ## $ posxmax2 : int 550 550 550 550 550 550 550 550 550 550 ... ## $ posymin2 : int -425 -425 -425 -425 -425 -425 -425 -425 -425 -425 ... ## $ posymax2 : int -275 -275 -275 -275 -275 -275 -275 -275 -275 -275 ... У нас аж 10800 наблюдений, а среди переменных есть id, которая идентификатор испытуемого. unique(share$id) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## [26] 26 27 28 29 30 31 32 33 34 35 36 Наблюдаем, что у нас 36 испытуемых. И если мы напишем немного кода, то посмотрим, сколько у нас было наблюдений на каждое экспериментальное условие: library(data.table) share &lt;- data.table(share) # делаем data.table, чтобы синтаксис работал share[, .N, by=.(id, trialtype, setsize, platform)] Видим, что у нас 50 проб на каждое условие. А содержательно для нас каждый испытуемый — это отдельное наблюдение, а эти 50 проб мы делали для более точных измерений. То есть, наши данные надо аггрегировать, усреднив наблюдения по каждому респонденту. Зачем? Чтобы у нас не случилось косяков с мощностью. R не знает о группировке наших данных, поэтому считает каждую строчку датасета отдельным наблюдением. В результате этого у нас возрастает статистическая мощность теста, но это искусственное увеличение мощности. Усредним данные и сравним результаты: share_aggregated &lt;- share[, .(mean_rt = mean(time1)), by = .(id, trialtype, setsize, platform)] share_aggregated fit5 &lt;- aov(mean_rt ~ trialtype * platform, share_aggregated) summary(fit5) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trialtype 1 0.19 0.1914 0.988 0.3214 ## platform 1 0.82 0.8164 4.213 0.0413 * ## trialtype:platform 1 0.08 0.0765 0.395 0.5304 ## Residuals 212 41.08 0.1938 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Ого! Значимость пропала! Для сравнения вспомним, какие результаты были без усреднения: summary(fit4.1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trialtype 1 10 9.57 10.68 0.00109 ** ## platform 1 41 40.82 45.56 1.56e-11 *** ## trialtype:platform 1 4 3.83 4.27 0.03882 * ## Residuals 10796 9674 0.90 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Наблюдаем, что воистину значимость одного фактора и взаимодействия пропала. Это как раз потому, что у нас упала мощность, но эти результаты корректнее отражают реальное положение дел. 6.6 Итоги Мы с вами познакомились с одним из самых популярных методов анализа данных. Конечно, мы не вникали с его детали и не смогли охватить все возможности. Например, за рамками остались такие темы как контрасты и дисперсионный анализ в повторными измерениями. Однако уверенно разобравшись в рассмотренных моделях, вы сможете погрузить в более сложные методы. Удачи! По теореме умножения вероятностей.↩︎ Справедливости ради стоит отметить, что дисперсионный анализ очень часто используется для анализа экспериментальных данных, поэтому поработаем с ними.↩︎ "]]
